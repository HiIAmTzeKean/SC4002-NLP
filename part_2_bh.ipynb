{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Model Training & Evaluation - RNN   \n",
    "Now with the pretrained word embeddings acquired from Part 1 and the dataset acquired from\n",
    "Part 0, you need to train a deep learning model for sentiment classification using the training set,\n",
    "conforming to these requirements:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Use the pretrained word embeddings from Part 1 as inputs; do not update them during training\n",
    "(they are “frozen”).   \n",
    "\n",
    "• Design a simple recurrent neural network (RNN), taking the input word embeddings, and\n",
    "predicting a sentiment label for each sentence. To do that, you need to consider how to\n",
    "aggregate the word representations to represent a sentence.   \n",
    "\n",
    "• Use the validation set to gauge the performance of the model for each epoch during training.\n",
    "You are required to use accuracy as the performance metric during validation and evaluation. \n",
    "   \n",
    "• Use the mini-batch strategy during training. You may choose any preferred optimizer (e.g.,\n",
    "SGD, Adagrad, Adam, RMSprop). Be careful when you choose your initial learning rate and\n",
    "mini-batch size. (You should use the validation set to determine the optimal configuration.)\n",
    "Train the model until the accuracy score on the validation set is not increasing for a few\n",
    "epochs.\n",
    "   \n",
    "• Evaluate your trained model on the test dataset, observing the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We omit warnings to keep the output clean\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils import load_glove_embeddings, set_seed\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "BATCH_SIZE = 32\n",
    "INPUT_SIZE = 100 # word embedding size \n",
    "HIDDEN_SIZE = 128 # just as a starter to see \n",
    "NUM_EPOCHS = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GloVe words loaded: 400000\n"
     ]
    }
   ],
   "source": [
    "# initialize word embeddings\n",
    "word_embeddings = load_glove_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vanillaRNN(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "    super().__init__()\n",
    "    self.num_layers = num_layers \n",
    "    self.hidden_size = hidden_size \n",
    "    self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True) # this is the num rows of the input matrix \n",
    "    self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "    output, h_t = self.rnn(x, h0) # we can just use the last hidden state output as the \n",
    "    last_hidden = h_t[-1]\n",
    "    logits = self.sigmoid(self.fc(last_hidden))\n",
    "    return logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from huggingface first \n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 8530\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/word2idx.json', \"r\") as file:\n",
    "    word2idx = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validate and test datasets and dataloaders \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "# TODO: change the num_tokens \n",
    "class EmbeddingsDataset(Dataset):\n",
    "  def __init__(self, X, y, num_tokens_per_sentence=12, word_embeddings=word_embeddings):\n",
    "    self.num_tokens_per_sentence = 8\n",
    "    self.word_embeddings = word_embeddings\n",
    "    self.X = X # train_dataset['text']\n",
    "    self.y = y # train_dataset['label']\n",
    "    self.len = len(self.X)\n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    # tokenize the sentence \n",
    "    tokens = self.tokenize_sentence(self.X[index])\n",
    "    # convert each token to embeddings \n",
    "    sentence_tensor = self.convert_sentence_into_embedding_tensor(tokens)\n",
    "    label = torch.tensor(self.y[index], dtype=torch.float)\n",
    "    return sentence_tensor, label \n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len \n",
    "\n",
    "  def tokenize_sentence(self, x): \n",
    "    '''\n",
    "    returns a list containing the embeddings of each token \n",
    "    '''\n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    return tokens \n",
    "\n",
    "  def convert_sentence_into_embedding_tensor(self, tokens):\n",
    "    sentence_embeddings = [] \n",
    "    num_tokens_used = 0\n",
    "    for i, token in enumerate(tokens): \n",
    "      if num_tokens_used == self.num_tokens_per_sentence:\n",
    "        break # we have enough of tokens from the sentence \n",
    "\n",
    "      if token in self.word_embeddings: # only use words that are in the word_embeddings matrix, otherwise skip\n",
    "        embedding_tensor = torch.tensor(self.word_embeddings[token], dtype=torch.float)\n",
    "        sentence_embeddings.append(embedding_tensor)\n",
    "      num_tokens_used += 1 \n",
    "\n",
    "    # if not enough tokens in the sentence, pad with zero tensors \n",
    "    if len(sentence_embeddings) < self.num_tokens_per_sentence:\n",
    "            # Padding with zero vectors if less than 8 embeddings\n",
    "            padding = [torch.zeros(EMBEDDING_DIM) for _ in range(self.num_tokens_per_sentence - len(sentence_embeddings))]\n",
    "            sentence_embeddings.extend(padding)\n",
    "\n",
    "    sentence_tensor = torch.stack(sentence_embeddings)\n",
    "    return sentence_tensor \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_ed = EmbeddingsDataset(train_dataset['text'], train_dataset['label'])\n",
    "validation_dataset_ed = EmbeddingsDataset(validation_dataset['text'], validation_dataset['label'])\n",
    "test_dataset_ed = EmbeddingsDataset(test_dataset['text'], test_dataset['label'])\n",
    "\n",
    "\n",
    "\n",
    "# implement minibatch training \n",
    "train_dataloader = DataLoader(train_dataset_ed, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# prepare validation and test dataloaders \n",
    "validation_dataloader = DataLoader(validation_dataset_ed, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset_ed, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_embeddings['the'].shape # get the size of the embeddings, so that we can use this as input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    num_batches = len(train_dataloader)\n",
    "    size = len(train_dataloader.dataset)\n",
    "    train_loss, train_correct = 0, 0\n",
    "    for batch_no, (X_batch, y_batch) in enumerate(train_dataloader):\n",
    "        X_batch = torch.tensor(X_batch, dtype=torch.float)\n",
    "        y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
    "        # Forward pass\n",
    "        pred = model(X_batch)\n",
    "        pred = pred.squeeze(1)\n",
    "        y_val = y_batch\n",
    "        loss = loss_fn(pred, y_val)\n",
    "        train_loss += loss.item() \n",
    "        train_correct += ((pred >= 0.5).float()==y_batch).sum().item() \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= num_batches \n",
    "    train_correct /= size \n",
    "\n",
    "    return train_loss, train_correct \n",
    "   \n",
    "\n",
    "def test_loop(validate_dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    num_batches = len(validate_dataloader)\n",
    "    size = len(validate_dataloader.dataset)\n",
    "    test_loss, test_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in validate_dataloader:\n",
    "            X_batch = torch.tensor(X_batch, dtype=torch.float)\n",
    "            y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
    "\n",
    "            pred = model(X_batch)\n",
    "            pred = pred.squeeze(1)\n",
    "            pred_binary = (pred >= 0.5).float()\n",
    "            test_loss += loss_fn(pred, y_batch).item()\n",
    "            test_correct += (pred_binary == y_batch).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_correct /= size\n",
    "    return test_loss, test_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vanillaRNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# initialize the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m RNN_model \u001b[38;5;241m=\u001b[39m vanillaRNN(input_size\u001b[38;5;241m=\u001b[39mINPUT_SIZE, hidden_size\u001b[38;5;241m=\u001b[39mHIDDEN_SIZE, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m      3\u001b[0m   \u001b[38;5;66;03m# num_classes==1 because binary classification\u001b[39;00m\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;66;03m# TODO: can try to increase num_layers > 1, that might perform better \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# initialize training params \u001b[39;00m\n\u001b[1;32m      6\u001b[0m optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(RNN_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vanillaRNN' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "RNN_model = vanillaRNN(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers=4, num_classes=1) \n",
    "  # num_classes==1 because binary classification\n",
    "  # TODO: can try to increase num_layers > 1, that might perform better \n",
    "# initialize training params \n",
    "optim = torch.optim.Adam(RNN_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model, just using epoch = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sx/8nz4dts119bfc1svlcbykndr0000gn/T/ipykernel_2892/987989442.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch, dtype=torch.float)\n",
      "/var/folders/sx/8nz4dts119bfc1svlcbykndr0000gn/T/ipykernel_2892/987989442.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "/var/folders/sx/8nz4dts119bfc1svlcbykndr0000gn/T/ipykernel_2892/987989442.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch, dtype=torch.float)\n",
      "/var/folders/sx/8nz4dts119bfc1svlcbykndr0000gn/T/ipykernel_2892/987989442.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 \tValidation Acc:0.6294559099437148 \tTrain Acc:0.6021101992966003\n",
      "Epoch:11 \tValidation Acc:0.6857410881801126 \tTrain Acc:0.7083235638921453\n",
      "Epoch:21 \tValidation Acc:0.6791744840525328 \tTrain Acc:0.8248534583821805\n",
      "Epoch:31 \tValidation Acc:0.6575984990619137 \tTrain Acc:0.9331770222743259\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m----> 4\u001b[0m   train_loss, train_correct \u001b[38;5;241m=\u001b[39m train_loop(train_dataloader, RNN_model, criterion, optim) \n\u001b[1;32m      5\u001b[0m   validate_loss, validate_correct \u001b[38;5;241m=\u001b[39m test_loop(validation_dataloader, RNN_model, criterion)\n\u001b[1;32m      6\u001b[0m   validation_acc\u001b[38;5;241m.\u001b[39mappend(validate_correct)\n",
      "Cell \u001b[0;32mIn[105], line 10\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(train_dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_batch, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[1;32m     11\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m y_val \u001b[38;5;241m=\u001b[39m y_batch\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nn/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nn/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[41], line 12\u001b[0m, in \u001b[0;36mvanillaRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     11\u001b[0m   h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 12\u001b[0m   output, h_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(x, h0) \u001b[38;5;66;03m# we can just use the last hidden state output as the \u001b[39;00m\n\u001b[1;32m     13\u001b[0m   last_hidden \u001b[38;5;241m=\u001b[39m h_t[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m   logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(last_hidden))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nn/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nn/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nn/lib/python3.12/site-packages/torch/nn/modules/rnn.py:586\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 586\u001b[0m         result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mrnn_tanh(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    587\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m    588\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mrnn_relu(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    591\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m    592\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validation_acc = [] \n",
    "train_acc = []\n",
    "for i in range(NUM_EPOCHS):\n",
    "  train_loss, train_correct = train_loop(train_dataloader, RNN_model, criterion, optim) \n",
    "  validate_loss, validate_correct = test_loop(validation_dataloader, RNN_model, criterion)\n",
    "  validation_acc.append(validate_correct)\n",
    "  train_acc.append(train_correct)\n",
    "  if i%10 == 0:\n",
    "    print(f\"Epoch:{i+1} \\tValidation Acc:{validate_correct} \\tTrain Acc:{train_correct}\")\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACYtklEQVR4nOzdeVxUVRsH8N/MMDPsILIKCKi44IIIiuC+YeaSmmlWLqmVWalZWlaWWm+WlamVVuaSVmrmkpqmaGnuK7jivoACIvsOw8x5/zjcgWEdhlmAeb6fz4jcuXPnzGXgPnPOc54jYowxEEIIIYSYEbGpG0AIIYQQYmwUABFCCCHE7FAARAghhBCzQwEQIYQQQswOBUCEEEIIMTsUABFCCCHE7FAARAghhBCzQwEQIYQQQswOBUCEEEIIMTsUABFiIsePH8f8+fORnp5ukONPnDgRvr6+Bjl2fXDv3j2IRCKsW7dOvW3dunUQiUS4d+9etY/v3bs3evfurdNzf/rpp9ixY0e57YcOHYJIJMKhQ4d0Oi4hRH8oACLERI4fP44FCxYYLACaN28etm/fbpBj11eDBw/GiRMn4OHhYdDnqSwA6tSpE06cOIFOnToZ9PkJIdWzMHUDCCHaycvLg5WVldb7N2/e3ICtqZ9cXFzg4uJisue3t7dH165dTfb8hJAS1ANEiAnMnz8fs2fPBgD4+flBJBJpDI34+vpiyJAh2LZtG4KCgmBpaYkFCxYAAL777jv07NkTrq6usLGxQfv27bF48WIoFAqN56hoCEwkEuH111/Hhg0b0KZNG1hbWyMwMBC7d++usr2PHz+GTCbDvHnzyt137do1iEQiLF++HACQm5uLt99+G35+frC0tISTkxNCQkKwcePGSo9/4cIFiEQirF69utx9e/fuhUgkws6dOwEAt27dwosvvgh/f39YW1vD09MTQ4cOxaVLl6p8DUDFQ2CMMSxevBg+Pj6wtLREp06dsHfv3nKPzc/Px1tvvYWOHTvCwcEBTk5OCAsLw59//qmxn0gkQk5ODn7++Wf1z1UYSqtsCGznzp0ICwuDtbU17OzsMGDAAJw4cUJjn/nz50MkEuHKlSsYO3YsHBwc4ObmhkmTJiEjI6Pa1x4ZGYmnnnoKXl5esLS0RIsWLfDKK68gOTm53L7Xrl3D2LFj4ebmBrlcjqZNm2L8+PEoKChQ7/Pw4UO8/PLL8Pb2hkwmQ5MmTTBq1Cg8evQIAKBSqfDJJ5+gVatWsLKygqOjIzp06IBly5ZV21ZCjIF6gAgxgSlTpiA1NRXffPMNtm3bph6SCQgIUO9z/vx5xMTE4IMPPoCfnx9sbGwAALdv38Zzzz0HPz8/yGQyXLhwAf/73/9w7do1rFmzptrn/uuvv3DmzBksXLgQtra2WLx4MUaMGIHr16+jWbNmFT7GxcUFQ4YMwc8//4wFCxZALC757LR27VrIZDI8//zzAIBZs2Zhw4YN+OSTTxAUFIScnBxcvnwZKSkplbYpMDAQQUFBWLt2LSZPnqxx37p16+Dq6oonn3wSABAfH4/GjRvjs88+g4uLC1JTU/Hzzz8jNDQUUVFRaNWqVbXnoLQFCxZgwYIFmDx5MkaNGoW4uDi89NJLUCqVGscqKChAamoq3n77bXh6eqKwsBAHDhzAyJEjsXbtWowfPx4AcOLECfTt2xd9+vRRB4z29vaVPv9vv/2G559/HhEREdi4cSMKCgqwePFi9O7dGwcPHkT37t019n/66acxZswYTJ48GZcuXcLcuXMBoNqf/e3btxEWFoYpU6bAwcEB9+7dw5IlS9C9e3dcunQJUqkUAA9Gu3fvDmdnZyxcuBD+/v5ISEjAzp07UVhYCLlcjocPH6Jz585QKBR477330KFDB6SkpGDfvn1IS0uDm5sbFi9ejPnz5+ODDz5Az549oVAocO3aNYMN+RJSY4wQYhJffPEFA8Du3r1b7j4fHx8mkUjY9evXqzyGUqlkCoWCrV+/nkkkEpaamqq+b8KECczHx0djfwDMzc2NZWZmqrclJiYysVjMFi1aVOVz7dy5kwFg+/fvV28rKipiTZo0YU8//bR6W7t27djw4cOrPFZFli9fzgBovObU1FQml8vZW2+9VenjioqKWGFhIfP392dvvvmmevvdu3cZALZ27Vr1trVr12qc87S0NGZpaclGjBihccxjx44xAKxXr15VPq9CoWCTJ09mQUFBGvfZ2NiwCRMmlHvMv//+ywCwf//9lzHGf35NmjRh7du3Z0qlUr1fVlYWc3V1ZeHh4eptH330EQPAFi9erHHMadOmMUtLS6ZSqSpta1kqlYopFAp2//59BoD9+eef6vv69u3LHB0dWVJSUqWPnzRpEpNKpezq1auV7jNkyBDWsWNHrdtEiLHREBghdVSHDh3QsmXLctujoqIwbNgwNG7cGBKJBFKpFOPHj4dSqcSNGzeqPW6fPn1gZ2en/t7NzQ2urq64f/9+lY8bNGgQ3N3dsXbtWvW2ffv2IT4+HpMmTVJv69KlC/bu3Yt3330Xhw4dQl5enjYvF88//zzkcrnGrC2hR+TFF19UbysqKsKnn36KgIAAyGQyWFhYQCaT4ebNm4iJidHquQQnTpxAfn6+uvdKEB4eDh8fn3L7b9myBd26dYOtrS0sLCwglUqxevXqGj+v4Pr164iPj8e4ceM0etVsbW3x9NNP4+TJk8jNzdV4zLBhwzS+79ChA/Lz85GUlFTlcyUlJWHq1Knw9vZWt114jUL7c3NzcfjwYYwePbrKXKm9e/eiT58+aNOmTaX7dOnSBRcuXMC0adOwb98+ZGZmVtk+QoyNAiBC6qiKZirFxsaiR48eePjwIZYtW4YjR47gzJkz+O677wBAq2CjcePG5bbJ5fJqH2thYYFx48Zh+/bt6mGMdevWwcPDAwMHDlTvt3z5crzzzjvYsWMH+vTpAycnJwwfPhw3b96s8vhOTk4YNmwY1q9fD6VSqT5+ly5d0LZtW/V+s2bNwrx58zB8+HDs2rULp06dwpkzZxAYGKh1sCUQhuXc3d3L3Vd227Zt2zB69Gh4enril19+wYkTJ3DmzBlMmjQJ+fn5NXress9f0c+6SZMmUKlUSEtL09he9ucnl8sBVP2zV6lUiIiIwLZt2zBnzhwcPHgQp0+fxsmTJzUem5aWBqVSCS8vryrb/fjx42r3mTt3Lr788kucPHkSgwYNQuPGjdGvXz+cPXu2yscRYiyUA0RIHSUSicpt27FjB3JycrBt2zaNHoro6GijtOnFF1/EF198gU2bNmHMmDHYuXMnZs6cCYlEot7HxsZGnVfz6NEjdW/Q0KFDce3atWqPv2XLFkRGRqJp06Y4c+YMVq5cqbHPL7/8gvHjx+PTTz/V2J6cnAxHR8cavR4hmEhMTCx3X2JiokYS+S+//AI/Pz9s3rxZ42dTOjG4poTnT0hIKHdffHw8xGIxGjVqpPPxBZcvX8aFCxewbt06TJgwQb391q1bGvs5OTlBIpHgwYMHVR7PxcWl2n0sLCwwa9YszJo1C+np6Thw4ADee+89DBw4EHFxcbC2ttb9BRGiB9QDRIiJaPPJvSzhwis8FuCzmFatWqXfxlWiTZs2CA0Nxdq1a/Hbb7+VG54qy83NDRMnTsTYsWNx/fr1csM5ZUVERMDT0xNr167F2rVrYWlpibFjx2rsIxKJNF4/wBO7Hz58WOPX07VrV1haWuLXX3/V2H78+PFyQ4IikQgymUwj+ElMTCw3CwzQrkcNAFq1agVPT0/89ttvYIypt+fk5GDr1q3qmWG1VdH7BgB++OEHje+trKzQq1cvbNmypcLZYYJBgwbh33//xfXr17V6fkdHR4waNQqvvfYaUlNTtSpESYihUQ8QISbSvn17AMCyZcswYcIESKVStGrVSiM/p6wBAwZAJpNh7NixmDNnDvLz87Fy5cpywySGNGnSJLzyyiuIj49HeHh4uVlXoaGhGDJkCDp06IBGjRohJiYGGzZs0OpiLpFIMH78eCxZsgT29vYYOXIkHBwcNPYZMmQI1q1bh9atW6NDhw44d+4cvvjii2qHZCrSqFEjvP322/jkk08wZcoUPPPMM4iLi8P8+fPLDYEJZQmmTZumni328ccfw8PDo9zwXvv27XHo0CHs2rULHh4esLOzq3B2mlgsxuLFi/H8889jyJAheOWVV1BQUIAvvvgC6enp+Oyzz2r8mirSunVrNG/eHO+++y4YY3BycsKuXbsQGRlZbl9hZlhoaCjeffddtGjRAo8ePcLOnTvxww8/wM7ODgsXLsTevXvRs2dPvPfee2jfvj3S09Px999/Y9asWWjdujWGDh2Kdu3aISQkBC4uLrh//z6WLl0KHx8f+Pv76+V1EVIrJk7CJsSszZ07lzVp0oSJxWKN2UE+Pj5s8ODBFT5m165dLDAwkFlaWjJPT082e/ZstnfvXo3HM1b5LLDXXnut3DF9fHwqnLVUkYyMDGZlZcUAsFWrVpW7/91332UhISGsUaNGTC6Xs2bNmrE333yTJScna3X8GzduMAAMAIuMjCx3f1paGps8eTJzdXVl1tbWrHv37uzIkSOsV69eGrO2tJkFxhifEbVo0SLm7e3NZDIZ69ChA9u1a1e54zHG2GeffcZ8fX2ZXC5nbdq0YatWrVLPziotOjqadevWjVlbW2vMJis7C0ywY8cOFhoayiwtLZmNjQ3r168fO3bsmMY+wvM8fvxYY3tFr6kiV69eZQMGDGB2dnasUaNG7JlnnmGxsbEMAPvoo4/K7fvMM8+wxo0bM5lMxpo2bcomTpzI8vPz1fvExcWxSZMmMXd3dyaVSlmTJk3Y6NGj2aNHjxhjjH311VcsPDycOTs7q48xefJkdu/evSrbSYixiBgr1e9KCCGEEGIGKAeIEEIIIWaHAiBCCCGEmB0KgAghhBBidigAIoQQQojZoQCIEEIIIWaHAiBCCCGEmB0qhFgBlUqF+Ph42NnZVbgcASGEEELqHsYYsrKy0KRJE40FhitCAVAF4uPj4e3tbepmEEIIIUQHcXFx1VaHpwCoAsJSBHFxcbC3tzdxawghhBCijczMTHh7e1e5pJCAAqAKCMNe9vb2FAARQggh9Yw26SuUBE0IIYQQs0MBECGEEELMDgVAhBBCCDE7FAARQgghxOxQAEQIIYQQs0MBECGEEELMDgVAhBBCCDE7FAARQgghxOxQAEQIIYQQs0MBECGEEELMjkkDoP/++w9Dhw5FkyZNIBKJsGPHjmofc/jwYQQHB8PS0hLNmjXD999/X26frVu3IiAgAHK5HAEBAdi+fbsBWk8IIYSQ+sqkAVBOTg4CAwPx7bffarX/3bt38eSTT6JHjx6IiorCe++9h+nTp2Pr1q3qfU6cOIExY8Zg3LhxuHDhAsaNG4fRo0fj1KlThnoZhBBCCKlnRIwxZupGAHzhsu3bt2P48OGV7vPOO+9g586diImJUW+bOnUqLly4gBMnTgAAxowZg8zMTOzdu1e9zxNPPIFGjRph48aNWrUlMzMTDg4OyMjIoMVQCdGRSsUgEmm3KCEAMMaQVVCEzDyFVvvLJGJIJWJILcSQSkSQVPM8DIBSxaBQqlCk5F8lYhEa28q1ej59YYyhoEiFnIIi5CmU5e4Xi0SQSsT89VmIYCEWQ6zdKaz6ecFff6FSBUWRCgolg4oxWMsksJZZQGZR8nlYlzaqj118Ywwa+0glYliIRVq/H/RNqWIoLFJptFGp0u3yZyHm7zmpBX99IhHU76nC4veXSodLq5VUYpT3I2MMKTmFyK/gZ6sLbd4PFZ1rmYUYrnaWemmDoCbX73q1GvyJEycQERGhsW3gwIFYvXo1FAoFpFIpTpw4gTfffLPcPkuXLq30uAUFBSgoKFB/n5mZqdd2E1KfFRQpcSMxGzEJmbhafLufkgOZhRg2MgvYyC1gLZNAqWLIyFMgPVeBjDwFsguKAAiBSsnFQtjfRmYBuVSMzPwiJGcV4HF2AQqLVEZ/fZ+OaI/nQpvq9Zj5CiX+u/EY91JycC8lF7EpubifmoP0HAVyCoug43XXoKQSEaxlFlCpmEHbKJOIYSHhF0w/Zxv8OiUUNnL9X4qyC4pw5l4qTt5OwYk7Kbj8MKNOnveyvnomEE8He+nteIwx/HMtCXsuJSI+PQ/xGXlIyMg3ye9aWZ2aOmLbtG4me/56FQAlJibCzc1NY5ubmxuKioqQnJwMDw+PSvdJTEys9LiLFi3CggULDNJmQkzlQVou3OwtIZXoPtJ953E2nv/pFBIy8nU+RqFShUIlwP8BkFVQ5f4yCzGq6yNgDFCoeC9DbUXHpek1AErPLcRzq07hakL1H6SE3oPSVIxBoTT8lZr3xkD9XAolD2D10UapRKQ+Zlnq9wOUiI5Lx8UHGQhr3ljn11FWWk4hZv9xEf9eT6qyh0cqEUGsQ28UA+/dLNLzsYtUDEoVw7nYNL0FQDceZeHj3Vdx5GZyuftEIv6z1Yfq3g8WYhHEYlG53+va/G3Sh3oVAAHlu9OFEbzS2yvap6pu17lz52LWrFnq7zMzM+Ht7a2P5hJiEqv+u4P/7YnB2C5NsWhke52OkZJdgBfXnUFCRj4crKRo52mPNu72aONhj+autlCqGHILi5BToERuYRHEIhEcraVwsJLC0VoGO0sLHqgUDwkUKlXIVyiRp1Aip6AIuYVK5BYqYWdpARc7OVxs5XCxk8NSKtG6jcKQVkGRCtqM5otEIsgt+NDZ2mN38clfMSjQ4yfhjFwFXljNg59G1lJ093eBb2NrNHWyhk9jG7jYyYuHnPiwk6SSsS3G+AVWoVRBUcTAoJ+AyELojROLIRYLQYqq+GfBf5YSsQg2Mgms5RawkkqqbKNCyVCk4m0UenWkkpJhLuF1FCn58JNCpVK/pkk/n8GtpGwolPo7/7cfZ2PyujO4l5ILAPBqZIWwZo0R1rwxOvs6wclGVq6NulKpWPHr4YGL0LOl6zDfT0fu4JO/YpBT3HNaG+m5hVh64CY2nLyvbtvzXZsi0MsRHg6WaOJoBTd7S41hz9oq+54V3g9C8FMX1asAyN3dvVxPTlJSEiwsLNC4ceMq9ynbK1SaXC6HXG7cPABCDOX3M3H43x6eJ3fqbopOx8hXKDFl/VncT8mFt5MVtk/rBmcj58poQyIWQSKW1ChoEgh//PU1FJCRp8C4Nadw+WEmGtvIsOnlrvB3s9PpWCKRiAcqEjEg00vzKiWViOFgJYaDlbRGjxOJRJBZiCBD5W0seR2AlUzzZyQMe+nr/J+4nYKpv5xDRp4CXo2s8P0LwWjn6aCXY1dELBZBLpZAX6N3wvmobQAUn56HYd8eRXJ2IQBgYFs3vPdkG/g0tql1G6tizPesvtSrOkBhYWGIjIzU2LZ//36EhIRAKpVWuU94eLjR2kmIqey7koh3t11Ufx+bklvjT9gqFcObm6MRFZsOBysp1k7sUieDn9qS6zEAysxXYPya07j4IANONjL89pLuwY+5kElKeqBqa8vZOIxfcwoZeQoENXXE9mndDBr8GIIQAGXXMgDadDoWydmF8GlsjV+nhOKHcSEGD37qK5MGQNnZ2YiOjkZ0dDQAPs09OjoasbGxAPjQ1Pjx49X7T506Fffv38esWbMQExODNWvWYPXq1Xj77bfV+8yYMQP79+/H559/jmvXruHzzz/HgQMHMHPmTGO+NEKM7vjtZLyxMQoqBowO8YK1TIIiFcP94uEAbX329zXsvZwImUSMH8cFo4WrrYFabFpCD1Bth8DyFUpMXHMaF+LS4WgtxS+TQ9HKnYKf6gj5H4W1DIC2nI3D7D8uQqFkGNzBAxtf6goXu/oXsNsU95DlFuo+M4sxht0XEwAAb/ZviW4tnPXStobKpAHQ2bNnERQUhKCgIADArFmzEBQUhA8//BAAkJCQoA6GAMDPzw979uzBoUOH0LFjR3z88cdYvnw5nn76afU+4eHh2LRpE9auXYsOHTpg3bp12Lx5M0JDQ4374ggxoksPMvDy+nMoLFJhYFs3fDqiPZq78MDl9uNsrY/zx7kH+PG/OwCAL57pgNBm+ktOrWtkEn7BqW0P0J/RD3E+Nh32lhb4ZXIoAppQ6Qxt6GsIcv2J+wCAieG++ObZIJ2GQ+sCffQAxSRk4U4yn6HZP6DytA/CmTQHqHfv3lUmLq5bt67ctl69euH8+fNVHnfUqFEYNWpUbZtHSL1wPyUHE9eeRnZBEcKaNcayZ4NgIRGjuYsNLj3MwK2kbAxsq92xNpzkF5M3+rbAUx09Ddhq0xOGwApq2QOx9dxDAMDU3s3r3bCLKQk9QLWZ8ZaUmY9LDzMAAK/1aVFnk221YauHHKDdF+MBAH1auaiPRypXr3KACKnP/r2ehFmbo5GSXfU08JpIyS7AhDWnkZJTiLZN7PHj+GD1J+Ca9gDlK5S4Gs8vJqNDGv4sSPUQWC2Kwd1LzsHpe6kQi4CRQfqr3WIOZOoASPcA9N/rSQCAQC+HejnsVVpJErRu78fSw19DOjTRW7saMgoRCTGCPZcS8MbGKChVDC72cswd1KbWx8wrVGLyz2dxLyUXXo2ssPbFzrCzLJnJ09xVCIBytDrelfgMKJQMzrYyeDWyqnX76jp1EnQtLsDbzj8AAHT3d4G7g34r2jZ0QgBamwDon2s8AOrbuv4P99jI+QeXnMKiaku3VOTSwwzEpubCSipBvzauhmhig0M9QIQY2O6L8ergB+BDJrWd+VKkVOGNjVGILk68/XlSl3Il5YXk5TtJ2VrVyImKTQcABDVtZLLlCoyppAdIt5+FSsWw9Twf/hqlx8q95kIolqhrEnpBkVJd4K9v6/p/wReGrBjTLRH6r+Len75tXGEto74NbVAARIgB7bwQjxmboqFUMYwM8oSzrQzJ2QU4fP2xzsdkjGH+ris4EPMIcgsxfhofoh7uKs2nsTXEIiCroAhJ1VRfBkoHQI46t60+kdWyB+jk3RQ8TM+DnaUFIijhtMaktRwCO303FbmFSrjaydG2ASSeW0kl6orbNc0D0hj+au+h76Y1WBQAEWIgf0Y/xMxNvOfnmWAvfPFMIEYE8cTi38/G6Xzcbecf4peTsRCJgGXPdkSIr1OF+8ktJGjqZA0AuJ1UfR7Q+dg0AECQdyOd21afyC1qNwvsj3N8+GtIhyb1duaRKdU2ADoYw4e/+rRyrdfJzwKRSASb4p6bnBr2AEXFpeNheh5sZBL0aQC9YcZCARAhBnAtMRNvbo6GigFjQrzx+dMdIBGL1MnF/1xLwmMtemXKYoypp6nP6OePJ9pV/WlP20TohOIFEsUiINDbPGYyqWeBFdV8uCG7oAh7L/GK8zT8pZvaFKIUFvgE+JBPQ6HOA6phD9DuC7z3p3+AGwXjNUABECEG8NupWKgYn466aGR79SdUfzc7BDV1RJGKYXvUgxof99TdVFx/lAUrqQQvhvtVu38LLROhheGv1u72ZpM/UJs6NHsvJSBPoUQzZxt0MpMhQ32rzTT4249zEJuaC5lEjO4NqNifLrWAVCqGPZdo9pcuKAAiRM/yCpXYHsWTYyd3b1aue17oBfr97AOtkpNL+/n4PQDA8CBPOFhXv3aT0AN0q5ohsChh+MuMLuZCD4SK8aTymhCGv54O9jKLhHFDqE0l6H+Le39Cmzmpg4aGQJdaQOdi05CYmQ87uQV6tmw4waAxUABEiJ7tvZyArPwieDWyQnjz8pWUh3TwgKVUjFtJ2YiKS9f6uPHpedh/9REAYEK4j1aPae7K1wCqbghM6AHq1NQ88n8AaKyEXZOZSLEpuTh1NxUiEdQ5XaTmpBbFa4Hp0AN38Br/PWgIs79KE3KAatIDtPsCL344oK2bOq+NaIcCIEL0bNMZnuA8JsS7wuRMO0spniyeqfH7Ge2ToX85eR9KFUPXZk5o7a7drBehByghI7/SP6qFRSpcLK6ma049QEIhPqBmw2Bbhdo/LZzRxLHh10syFJmOPUAZeQqcvcd7LBtcAKRDMcT/iksBPFlNPiApjwIgQvTozuNsnL7LKwOPCqk8OXZM8TDYrgvxyC2s/tNevkKpDqwmhvtq3R5HaxmcbWUAgLuV5AHFJGSisEgFR2sp/JzNZ9VoC4kYkuIAtSYX4QMxvPeBen9qR9dCiEduPkaRiqG5i02DW+XctoZJ0IwxJGTkAQD83RrmosWGRAEQIXq0uXh6e+9WrvBwqLx3oIufE3wbWyOnUIk9xbOJqrLrQjxScwrRxMES/dvUrOZMs2pmgqnzf7wdzS6fReiFqEkxRKGmEq34XjvqHKCimuXB/VM8/b1fDX8P6gNroQdIiw9FAK/xlV/83i1bCJVUjwIgQvREoVRha3Fy7JjOVa+lJRKJ8ExxL9AX+65hzh8XsOq/O/j3WhIepOVq7MsYw88n7gEAXgjzgYWkZr+21SVCny9VAdrcyKXCMIx2Qw6MMaTlFAIAnGxkBmuXOdBlLTCliuHQDV5EtE+rhjX8BdQ8CTopkwfjdnILWMko/6emGk76PCEmdjAmCcnZhXC2lWuVm/B0Jy98+88tPMoswO9nNafEB3jY4+lgLzzVsQnup+Ti8sNMyCzEeLZz0xq3q7lL1YnQUXG8B8icEqAFwkU4X8seoKyCIhQVL2nSyJoCoNqQ6lCG4PbjbKTmFMJGJkGIb8N7v5YkQWsXkCdl5QMAXOzr90KwpkIBECF6svlMLABeGE+qRS+Nu4MlDrzVC+fvp+FWUrb6dvtxNq4mZOLq7qv4dE+MOofnqcAmOvU6lNQCKh8APc4qQFxqHkQioIOZFEAsrabLYQi9P1ZSCRWcqyVZ8VpgNekBSi4efvRwtNLqd6y+qWkhRKGYqqsdBUC6oACIED2IT8/D4eKu+eqGv0rzdLSCZ5mZRKk5hdh9MR5bzz/Ehbh0PCru5p5Qg+Tn0oQhsHvJuShSqjSG0IT8H39XW9hbVl9XqKGpaTXiVBr+0htdlsJIy1UAAJwaaO+brkNglP+jGwqACKkCYwwzN0dj7+XyicoOVlK42MrhYidHVr4CKgaE+jnVeiaVk40M48N8MT7MF7eSsrDzQgLc7OVo56lbD42noxXkFmIUFKkQl5an0T6hDpE5Dn8BgKy4boq2dYDSiy/AjWzML1jUN5l6KRLtA6DUXB6AOmpRBLQ+qmklaGEIjHqAdEMBECFV2HMpEX9Gx1d43+OsAt4FnVCy7dku2vf+aKOFqx1mDajdbCOxWIRmLraIScjE7aRsjQDo/H3zqwBdmq49QJT/U3u69AClN/AeOPUQmJazwIQZia6UA6QTCoAIqURuYRE++esqAODV3s3xQteS6ssqFUNGngKPs3kQlJxdAGupBE8F1s3aMC1ciwOgx9noDz59uEipwsUHQgFEc+0BqlkAlJbbsC/AxqTLWmAlPUAN8/wLSdC52iZB0xBYrVAAREglvvv3FhIy8uHVyAoz+vmXS3rVb1+PYVU0E2zLuQfIUyhhJ7dACxfzLKJW0xXhqQdIf+Q6FEIUhiCdGugQJA2BGRcFQIRU4G5yDlb9dxcA8OGQgHo/46d0LSCViuHrAzfwzT+3AADPVLJkhzmo6RAY9QDpT0khxBrkAOU07B6gGidB0xBYrVAAREgZjDHM33kFhUoVerV0wYCA+l9xtnQANH1TFHZf5IlL03o3x9sRrUzZNJOq6TR4dQ8QBUC1JpXUfBmSdCEAbaABkHotsEIlVCpW5QeTfIUSWfk8UHKhITCdUABESBkHYpJw+MZjSCUifDQ0oEEsD9HMxQYiEZCZX4TdFxNgIRbh05HtMTqkPg3k6V9Nl8JIy2nY07CNSZckaCEHqKHOwhN6gAAgV6HU+L4sIf9HbiGGvSVdynXR8CpJEVIL+QolFu6+AgCY0qOZeh2t+s5SKoFXI15vyMFKivWTu5h98AMA8uJp8Fr3ADXwC7Ax1XT4EQDSiwPQhpqDZSkVQ+j0qW4YTJ3/Yy9vEB/STIHCRkLAA58tZ+Pw/eE7eJieB3d7S7zep4Wpm6VXr/VugT2XE/HR0AD1kJi5U9eiUWiXBE3rgOmP0AOkYnyNL0k1eWiFRSpkFQcFDTUAEolEsJFZIKugCNkFRahq8F2d/0PDXzqjAIiYtcx8BX4/E4cf/rujLivvYifHktGB6vH4huLZLk3xbJearyXWkKkDIC16gFQqVpIE3UAvwMYkrAUG8GEwibjqiQbpefzci0WAvVXD7YGzkfMAqLqp8EmZNAOsthrWX3hCqhCfnocf/7uD2NRcxKfnIT49D5n5Jd3MTRwsMbV3c4wO8a73s76IdmoyDJNZXO0baLizkIxJVmpJlkKlqtrfOSH/ysFKWm1vUX0mFEOsbip8Eq0DVmsUABGzsWjvNey6UL6qs5+zDab2aoYRQV7qHgFiHmqyHIMwA8xObkHvEz0QZoEB2gWgabnmMQNP26nwJVPgaQhMVxQAEbOQkafAvit8Pa93nmiNNh52aOJoBQ8HS9iZ4SKghFMnQdMF2OhEIhGkEhEUSqbVTLA0MylCWTIVXrsAyIV6gHRGARAxC39dTEBhkQot3WwxtVczmjVBANRsKYxUYQYSBUB6I5WIoVAqoSiqfjkMYSV4cwmAqh0CoxygWqN+XGIWtp5/AAB4upMXBT9ETVaDpTDUPUANdCVyUygpREnnX2AjK14QtZoA6DHNAqs1CoBIg3c3OQfn7qdBLAKGB9XNxUqJadQkCVo9Bb6B90AYU8lyGFr0AJlJCYKSHqDKg0KFUoWU4vNBy2DojgIg0uBtL+796e7vAjdKGCSlyGuwFEYq5QDpnawG1aAb+krwAiEJOreKHqDkbN77YyEWUUBeCyYPgFasWAE/Pz9YWloiODgYR44cqXL/7777Dm3atIGVlRVatWqF9evXa9y/bt06iESicrf8/HxDvgxSR6lUDFvPPwQAPN2Jen+IpposhWEuPRDGJKvBivANfSV4gTZJ0MIyGM62crNdyFgfTJoEvXnzZsycORMrVqxAt27d8MMPP2DQoEG4evUqmjYtX7Bt5cqVmDt3LlatWoXOnTvj9OnTeOmll9CoUSMMHTpUvZ+9vT2uX7+u8VhLS/rkb45O3U3Fw/Q82MktMLCtu6mbQ+oYubQGPUANfBkGU1AviFqDMgQNvQdImyEwWgVeP0waAC1ZsgSTJ0/GlClTAABLly7Fvn37sHLlSixatKjc/hs2bMArr7yCMWPGAACaNWuGkydP4vPPP9cIgEQiEdzd6WJHSpKfB3fwoOKGpByZhL8ntOoBEqpAN/AeCGNS5wBp1QNkHj1wtvLqk6DV64DRDLBaMdkQWGFhIc6dO4eIiAiN7RERETh+/HiFjykoKCjXk2NlZYXTp09DoVCot2VnZ8PHxwdeXl4YMmQIoqKi9P8CSJ2XW1iEvZcSAABPB3uZuDWkLqpJD5C51KExppIV4atPgk41k/OvzTR4YQjMhWaA1YrJAqDk5GQolUq4uWku9+bm5obExMQKHzNw4ED89NNPOHfuHBhjOHv2LNasWQOFQoHk5GQAQOvWrbFu3Trs3LkTGzduhKWlJbp164abN29W2paCggJkZmZq3Ej99/flROQUKuHT2BohPo1M3RxSB8kkNagDZCY9EMakbR2mIqVKvWxNw58GX30laFoGQz9MngRdtiYLY6zSOi3z5s3DoEGD0LVrV0ilUjz11FOYOHEiAEBS3JXdtWtXvPDCCwgMDESPHj3w+++/o2XLlvjmm28qbcOiRYvg4OCgvnl7e+vnxRGTEoa/RgZR7R9SMW3rABUpVcjIo0KI+qbtLLD04nMvEvG1wBoyGy2WwngsDIFRDlCtmCwAcnZ2hkQiKdfbk5SUVK5XSGBlZYU1a9YgNzcX9+7dQ2xsLHx9fWFnZwdnZ+cKHyMWi9G5c+cqe4Dmzp2LjIwM9S0uLk73F0bqhISMPBy/nQIAGEmzv0gl5FquBZaRpwATFkJt4BdgY1InQVcXABX3vtlbSmEhMfnndoMSFkPNKdQiCZqGwGrFZO8kmUyG4OBgREZGamyPjIxEeHh4lY+VSqXw8vKCRCLBpk2bMGTIEIjFFb8Uxhiio6Ph4eFR6fHkcjns7e01bqR+2xEVD8aALn5O8HayNnVzSB2l7RCMkADtYNXwL8DGpO00eGEGnjkMP2qzGKqQA0RDYLVj0llgs2bNwrhx4xASEoKwsDD8+OOPiI2NxdSpUwHwnpmHDx+qa/3cuHEDp0+fRmhoKNLS0rBkyRJcvnwZP//8s/qYCxYsQNeuXeHv74/MzEwsX74c0dHR+O6770zyGonxMcawPUoY/qLeH1K50qvBVzX8bk4XYGOSapmDlaYugtjwe9+EIbDcQiVUKlauzo9KxdSFEKmwa+2YNAAaM2YMUlJSsHDhQiQkJKBdu3bYs2cPfHx8AAAJCQmIjY1V769UKvHVV1/h+vXrkEql6NOnD44fPw5fX1/1Punp6Xj55ZeRmJgIBwcHBAUF4b///kOXLl2M/fKIiVxNyMSNR9mQWYgxqH3lPX+ECKvBA3wmksyisgDIPNahMjZtc4DMaRkSoQcI4MUQ7Sw133OpuYUoUjGIRICzbcM/H4Zk8tXgp02bhmnTplV437p16zS+b9OmTbVT2r/++mt8/fXX+moeqYd2RPHKz/3buDb4hElSO0IOEMDzUGQWFQ9vpdEMMIPQdhq8sBJ8Qy+CCPD3pEQsglLFkFOgLBcACcNfjW1kNBxbS3T2SIOiVDH8GR0PABjekYa/SNVkpS4gBYrKk07NpQaNscm0TEI3pyKUIpEI1sUrwldUC0gogkg1gGqPAiDSoBy/nYykrAI4WkvRu5WrqZtD6jixWKTVTCRzqUJsbNIaDoGZQw8QUHUiNNUA0h8KgEiDsr144dMhHTwqHc4gpDRtiiEKSdDmcgE2FmlxzpVC6x4g8zj/VS2I+pgCIL2hKwRpMHILi/D3FV5XakQQLX1BtCMvXiOuqmEYcxqCMSZtk6DNLQm9pBhi+WHZpEwqgqgvFACRBmP/lUfILV76olNTR1M3h9QT2vUAUQ6QIci0XAw1vTgJ2lzOf1ULolIRRP2hAIg0GNuLZ38N7+hJS18QrWmzHIa5DcEYi1RdiLLqWWDCOmzmsgyJsB5YxUnQNASmLxQAkQYhKSsfR24+BgCMoOKHpAa0WQ5D3QNkJhdgY9EmCVqpYiXrsJlJD1BV64El0TpgekMBEGkQdkbHQ8WAoKaO8HW2MXVzSD1S3XIYCqUKWcUrkZtDIT5j0mYpDI112MwmB6jiITDGWKllMGgIrLYoACL1Xk5BEX46chcAMLITJT+TmqmuB0gY/hKLAHsqrKlXMqEEgRYJ6HaWFuoeo4ZO6AHKLpMEnZlfpH6futAQWK2Zx7uJNGgrDt1CYmY+vJ2s8EwwBUCkZqrrAUorNQVeIqbcMn2SapEEnWaGCei2MmE9MM0eoMfFw1/2lhawlErKPY7UDAVApF67n5KDVf/x3p8PBgfQHwVSY7Li9cAqC4DMbQq2MWmTAyQsg2FO+VclPUCaAZB6+IsWQdULCoBIvfbx7hgUKlXo4e+MiAA3UzeH1EPaDoHRDDD9q673DSjdA2Q+AWhllaBpBph+UQBE6q1D15NwIOYRLMQifDQ0gKa+E52UXIQrngZPNYAMR6bFYqjqANSMzn9lhRBjU3MBAB4OVkZvU0NEARCplwqLVFi4+yoAYEK4L1q42pm4RaS+kleThyL0QFAPkP5pMwQm1AAyp2VIrOUVL4Z6MykbAODvZmv0NjVEFACReunn4/dw53EOnG1lmNHf39TNIfWYXFo8BKaoJAfIzIrwGZO6962qhWiLk9DNaRkS20rWArv5KAsA0JICIL2gAIjUOynZBVh28CYAYM7A1rC3NJ8/jET/qluOQViGwZyGYIxFqsU0eHMMQIVK0KVzgIqUKtx5nAMA8Kceb72gAIjUO39GxyO7oAhtPOwxiqa9k1qqbjFUqgJtONoMgaXnml8Olm0FOUCxqbkoVKpgJZXA05FygPSBAiBS7/x5IR4AMCbEC2Kqy0JqqbrFUGkleMMpqQRdeRK0OSahC5Wg8xRKKFX83Nx4xPN/Wrja0t89PaEAiNQr95JzcCEuHWIRMLhDE1M3hzQAsmqmwQsXYHNKwjWW6oJPoNRK8GYUgAqzwICSPKBbSTz/x9+V8n/0hQIgUq/sLO796dbCmUrBE72QV7MavHoWGAVAeietJglapWJmOQ1ebiFWVx0X8oCEGWAtKAFabygAIvUGYww7oh8CAIZ3pBXfiX5UVYwvX6FETiEPjCgHSP+EJGiFUgXGyg+DZeUXQaVeCNV8zr9IJIKNTHNBVGEIrCUlQOsNBUCk3rgSn4k7j3MgtxAjoi1VfSb6UVUAJAy/SMQi2FtalLuf1I5cwi/yjEGd61KaMAPMVm6h/jmZC9tSC6IqVQy3H1MNIH0zr3cUqdf+LO796d/GDXY09Z3oidyi8llgpRNwqdK4/kktSs5pRcNgaeoiiOb3+25TajmMuNRcFBapYCkVw6uRtYlb1nBQAETqBaWKqfN/hnWk5GeiP1X1ANEMMMMSpsEDgKKofA+QOVfhLh0A3SgugNjcxVadG0Rqj/p0Sb1w6m4KHmUWwN7SAr1buZi6OaQBkVeRiGuOU7CNyUJcXQ8QH4I0p/wfQelq0PHp+QBoBpi+UQ8QqRd2RvPenyfbe6iHLAjRB1kVs8Ay8vgF2MGKeoAMQSQSVbkcRskMPPM7/zbq9cCUuKVeA4wSoPWJAiBS5xUUKbHnUgIAGv4i+ievohaNsBgl5ZwZjnpF+CqGIM2xB6j0chjCEBj1AOkXBUCkzjt0/TEy84vgbm+JUL/Gpm4OaWDUi6FWFADlCwEQZQsYSump8GWV5GCZYQBUPASWla+gHiADoQCI1HlC8vPQQA9KACR6Jyueil1RD1BWPh8Cs5VTAGQoVQ+BFVeBNsshMP6eu56YhYIiFWQWYjR1ohlg+kQBEKnTlCqG/248BgAMau9h4taQhqiqWWBZBdQDZGjSKoYghRwsezPMwbItzgGKjksHQDPADIECIFKnXY3PRFZ+EWzlFujg6WDq5pAGSF7FWmDCEJgtBUAGo84BqmBB1FwFT0wX8mHMidADlJzNhwEp/0f/KAAiddqJO8kAgFA/J1hI6O1K9K+qHiAhCZqGwAxHqg6Ayp//vOKFQK1l5jfz06bMe64lVYDWO7qikDrtxO0UAEBYc0p+JoZROgel7HpU2TQEZnBVBaA5BbwHyMoMA6CyQXcLWgNM7ygAInWWQqnC6bupACgAIoYjL7XGVNlhsCxhCExufjkoxiLMAqsoCTqveAjM2gyHwMr2elEPkP6ZPABasWIF/Pz8YGlpieDgYBw5cqTK/b/77ju0adMGVlZWaNWqFdavX19un61btyIgIAByuRwBAQHYvn27oZpPDOjSwwzkFCrhaC1FG3d7UzeHNFClF9ksexHOomnwBlfVEFiuGQ+Ble4BkkloBpghmDQA2rx5M2bOnIn3338fUVFR6NGjBwYNGoTY2NgK91+5ciXmzp2L+fPn48qVK1iwYAFee+017Nq1S73PiRMnMGbMGIwbNw4XLlzAuHHjMHr0aJw6dcpYL4voiTD8FernBDHNfiAGIiuVW1Z2GCa7gKbBG5oQgJYNgFQqhnwF32aOQ2Clc4CaudhQDqQBmPSMLlmyBJMnT8aUKVPQpk0bLF26FN7e3li5cmWF+2/YsAGvvPIKxowZg2bNmuHZZ5/F5MmT8fnnn6v3Wbp0KQYMGIC5c+eidevWmDt3Lvr164elS5ca6VURfRECoPDmziZuCWnISi/HUHoITKFUqS/A1ANkOLJKpsELw18A9QBRAUTDMFkAVFhYiHPnziEiIkJje0REBI4fP17hYwoKCmBpaamxzcrKCqdPn4ZCwT+pnThxotwxBw4cWOkxheNmZmZq3IhpFRQpcfY+5f8Q46hoOYyc4gRooPyMHKI/6jpAZabB5xaWBECWZrj+X+n3HE2BNwyTBUDJyclQKpVwc3PT2O7m5obExMQKHzNw4ED89NNPOHfuHBhjOHv2LNasWQOFQoHkZD5dOjExsUbHBIBFixbBwcFBffP29q7lqyO1dSEuA/kKFZxtZfTLTwyuZDmMkouukP9jKRWrL9JE/6TCEFjZHqBCIQFaYpZD4MJiqAAFQIZi8t9qkUjzjc0YK7dNMG/ePAwaNAhdu3aFVCrFU089hYkTJwIAJJKSN0tNjgkAc+fORUZGhvoWFxen46sh+iIMf3Vt1rjKnx0h+lDRMExJAjTNADMk9bkvkwOUqzDfBGiAnxfL4sC8pTsNgRmCyQIgZ2dnSCSScj0zSUlJ5XpwBFZWVlizZg1yc3Nx7949xMbGwtfXF3Z2dnB25nki7u7uNTomAMjlctjb22vciGkdv8179Gj4ixhDRbVo1DWAaPjLoGQWxYuhlukBEobAzDEBGuAf5BcMa4u3BrREcxfqATIEkwVAMpkMwcHBiIyM1NgeGRmJ8PDwKh8rlUrh5eUFiUSCTZs2YciQIRCL+UsJCwsrd8z9+/dXe0xSd+QrlIiKTQcAhDWjAIgYnrw4x6RAIwAqngFGCdAGVdk0ePUQmNR8z/+Yzk3xRj9/UzejwTLpO2vWrFkYN24cQkJCEBYWhh9//BGxsbGYOnUqAD409fDhQ3Wtnxs3buD06dMIDQ1FWloalixZgsuXL+Pnn39WH3PGjBno2bMnPv/8czz11FP4888/ceDAARw9etQkr5HU3Pn7aShUquBubwk/ZxtTN4eYgYp6gEqKIJrvBdgYqkuCNtceIGJ4Jv3NHjNmDFJSUrBw4UIkJCSgXbt22LNnD3x8fAAACQkJGjWBlEolvvrqK1y/fh1SqRR9+vTB8ePH4evrq94nPDwcmzZtwgcffIB58+ahefPm2Lx5M0JDQ4398oiOjpda/oLyf4gxVLQgKgVAxlHZUhjmXASRGIfJf7OnTZuGadOmVXjfunXrNL5v06YNoqKiqj3mqFGjMGrUKH00j5jAiTvFARANfxEjKakDVDILrGQdMEqCNqRqh8AoACIGYvJZYISUllNQhAtx6QAoAZoYT4VJ0LQMhlHIitcCKxsAlQyB0fknhkEBEKlTztxLRZGKwauRFbxp7RtiJHKL8lOxhR4gGgIzLFkF5x4otRCqlHqAiGFQAETqlKM3+fT3cOr9IUYkE2aBKSrIAaIeIIOSVrIUhpADREnQxFAoACJ1ypHiAKhnSxcTt4SYk4qK8WXl00KoxlBZDlAu5QARA6MAiNQZjzLzcf1RFkQioHsLWgCVGI+wFEaFhRCpB8igZOoAqMw0+AIKgIhhUQBE6oz/bjwGAHTwcoSjtczErSHmRLgIVzwLjAIgQ6p0GryCkqCJYVEAROoM9fCXP/X+EOOqsAdIXQeIpsEbkrSStcDyqA4QMTAKgEidoFIxHL1F+T/ENOSS8oUQM6kQolFIq5kGTwEQMRQKgEidcCU+E6k5hbCVW6Cjt6Opm0PMTMWLofIkaBoCMyzh3FdaB4imwRMDoQCI1An/3eT5P2HNG6u7xAkxFmExVCEAUihVyC+eEk8BkGHJKpkGX1IJms4/MQy60pA64UhxAET5P8QUZGXWAsspToAGABsaAjMoqUUls8AUVAeIGBYFQMTkcgqKcO5+GgDK/yGmUTYAEoogWkrF1CNpYJUVQqS1wIih0W82MbmTd1KgUDI0dbKGT2MbUzeHmKGyS2Fk0Qwwo6moCCVASdDE8CgAIiYnTH/vQcNfxETUPUDFtWeoBpDxyCzKzwJjjJWsBUY5QMRAKAAiJickQPfwp+EvYhrqJOjiizDNADMe9VIYpYbA8hUqsOKUIOoBIoZCARAxqQdpubjzOAcSsQjhLWgBVGIaZafBZ1ENIKORVZAELSyECtA0eGI4FAARkxKGv4K8HWFvSfkWxDRkZQohCkNgFAAZXulK0Ky420fI/7GUiiEWi0zWNtKwUQBETOoIDX+ROqDsUhjqHiAaAjO40rPshF4gyv8hxkABEDEZpYrh2K0UAEB3SoAmJlR2MVRhHTA76gEyOJlGAMQDUKoCTYyBAiBiMpcfZiAjTwE7SwsEejmYujnEjMnL5ACVzAKjYVlDE3KAgJLzn0sLoRIjoACImMyx2zz/p2uzxrCgYnPEhMouhUFDYMYjEYsgpPkIPUBUBJEYA111iMkcK179vXsLGv4iplW2ErQwDZ6SoI1DWqYYonoIjAIgYkAUABGTyFcoceYeX/6iGwVAxMSEIbAiFYNKxdQ9QFQHyDjKToUvGQKj808MhwIgYhJn76WhsEgFN3s5mrvQ8hfEtDTyUJQqmgZvZGVXhKceIGIMFAARkxDyf7q1cIZIRHU+iGmVDoAKFKqSWWCUBG0U6mrQZYbArGkWGDEgCoCISVD+D6lLLEol4hYolciiHiCjkhavB1ZISdDEiCgAIkaXnluISw8zAFD+D6kbRCKRxnIY2ZQDZFSVD4HR+SeGQwEQMbqTd1LAGNDC1RZu9pambg4hAEouwrmFSnUlYuoBMo6yQ2B5CqoDRAyPAiBidEdp+IvUQfLifJOU7EL1NqoDZBwls8DK5ABRAEQMiAIgYnTC8hc0/EXqEqEHKCWnAABfiFNKBTqNQl0HqEhzMVSaBUYMiX67iVE9TM/D3eQciEVAaDMnUzeHEDWhFlBqDu8BspXTDDBjkZUphEhJ0MQYKAAiRiXM/gr0doQ9TTEmdYgwDJNcPARGCdDGIxWGwMqsBWYlpZ8BMRwKgIhR0fR3UlcJPUAp2XwIjBKgjUcm4dPgKQeIGBMFQMRoGGPq/J/w5hQAkbpFWBC1ZAiMAiBjKZsELczCs5FTAEQMx+QB0IoVK+Dn5wdLS0sEBwfjyJEjVe7/66+/IjAwENbW1vDw8MCLL76IlJQU9f3r1q2DSCQqd8vPzzf0SyHVuPEoG8nZBbCUitHJx9HUzSFEg3ARTsmhITBjE5KgC8rWAaIhMGJAJg2ANm/ejJkzZ+L9999HVFQUevTogUGDBiE2NrbC/Y8ePYrx48dj8uTJuHLlCrZs2YIzZ85gypQpGvvZ29sjISFB42ZpSfVmTO2/G48BAJ19ndSftgmpK2Rlh8AoADKakjpAfBYYJUETYzBpALRkyRJMnjwZU6ZMQZs2bbB06VJ4e3tj5cqVFe5/8uRJ+Pr6Yvr06fDz80P37t3xyiuv4OzZsxr7iUQiuLu7a9yI6e2/mggA6Nva1cQtIaS8srPA7GgIzGhKF0JkjJVaDZ4CIGI4OgVAeXl5yM3NVX9///59LF26FPv379f6GIWFhTh37hwiIiI0tkdEROD48eMVPiY8PBwPHjzAnj17wBjDo0eP8Mcff2Dw4MEa+2VnZ8PHxwdeXl4YMmQIoqKiqmxLQUEBMjMzNW5Evx5nFeDs/TQAQERbCkhJ3SP0AKXlKgBQD5AxyUstQ1JQpIKKdwRRHSBiUDoFQE899RTWr18PAEhPT0doaCi++uorPPXUU5X23pSVnJwMpVIJNzc3je1ubm5ITEys8DHh4eH49ddfMWbMGMhkMri7u8PR0RHffPONep/WrVtj3bp12LlzJzZu3AhLS0t069YNN2/erLQtixYtgoODg/rm7e2t1Wsg2jsQ8wiMAe09HeDpaGXq5hBSjqxM0UOqA2Q80lKzwIThLwCwprXAiAHpFACdP38ePXr0AAD88ccfcHNzw/3797F+/XosX768RscSiUQa3zPGym0TXL16FdOnT8eHH36Ic+fO4e+//8bdu3cxdepU9T5du3bFCy+8gMDAQPTo0QO///47WrZsqREklTV37lxkZGSob3FxcTV6DaR6+67woHZgW7dq9iTENORSzT+HlARtPNJShRBzi2eAySzEkIgrvhYQog86/Ybn5ubCzs4OALB//36MHDkSYrEYXbt2xf3797U6hrOzMyQSSbnenqSkpHK9QoJFixahW7dumD17NgCgQ4cOsLGxQY8ePfDJJ5/Aw8Oj3GPEYjE6d+5cZQ+QXC6HXC7Xqt2k5rLyFThePP19IA1/kTpKJtEcbqEAyHhKT4PPLaD8H2IcOvUAtWjRAjt27EBcXBz27dunzuNJSkqCvb29VseQyWQIDg5GZGSkxvbIyEiEh4dX+Jjc3FyIxZpNlhT/0WKMVfgYxhiio6MrDI6Icfx7/TEKlSo0c7ZBC1dbUzeHkAqV7QGiOkDGU7IWmKqkCKKUAiBiWDoFQB9++CHefvtt+Pr6okuXLggLCwPAe4OCgoK0Ps6sWbPw008/Yc2aNYiJicGbb76J2NhY9ZDW3LlzMX78ePX+Q4cOxbZt27By5UrcuXMHx44dw/Tp09GlSxc0adIEALBgwQLs27cPd+7cQXR0NCZPnozo6GiNYTJiXMLwV0Rb90qHNwkxtfI5QBQAGYus1DR4WgiVGItOv+GjRo1C9+7dkZCQgMDAQPX2fv36YcSIEVofZ8yYMUhJScHChQuRkJCAdu3aYc+ePfDx8QEAJCQkaNQEmjhxIrKysvDtt9/irbfegqOjI/r27YvPP/9cvU96ejpefvllJCYmwsHBAUFBQfjvv//QpUsXXV4qqaV8hRKHriUBoPwfUrcJwzACmgVmPEISdKFShTyFMARG558Yls7vMHd3d2RnZyMyMhI9e/aElZUVOnfuXONP+NOmTcO0adMqvG/dunXltr3xxht44403Kj3e119/ja+//rpGbSCGc/x2MnIKlXCzlyPQy9HUzSGkUvIyARAt1ms8suLCqKWHwKgHiBiaTkNgKSkp6NevH1q2bIknn3wSCQkJAIApU6bgrbfe0msDSf227/IjADz5WUwzOkgdVjYAoiEw4yk9DZ4WQiXGolMA9Oabb0IqlSI2NhbW1tbq7WPGjMHff/+tt8aR+k2pYjgQUxIAEVKXlR0Cs6EAyGhKzwKjZTCIsej0G75//37s27cPXl5eGtv9/f21ngZPGr6z91KRklMIByspuvg5mbo5hFSp9Pp0cgtxuYCIGI46CbqI0UKoxGh0eofl5ORo9PwIkpOTqZ4OUdt3hff+9Gvjqp7mSkhdVTrgoRpAhqVUKqFQKNTfy0VKeNpJYCtlQFEhPO0kcLUWIT8/34StJHWVTCYrVxJHFzr9lvfs2RPr16/Hxx9/DIBXc1apVPjiiy/Qp0+fWjeK1H+MMfXipzT8ReoDuUYARAnQhsAYQ2JiItLT0zW2N1IpMb+PK2QSEeRSBVr0cYWdJXD37l3TNJTUaWKxGH5+fpDJZLU6jk4B0BdffIHevXvj7NmzKCwsxJw5c3DlyhWkpqbi2LFjtWoQaRjupeTiQVoeZBIxevq7mLo5hFSrdA8QJUAbhhD8uLq6wtraWj1rOKdAAXFaHmQSCaxkYljlKdDYVg5nWxpRIJpUKhXi4+ORkJCApk2b1qq2nE6/5QEBAbh48SJWrlwJiUSCnJwcjBw5Eq+99hpVXCYAgBO3+dIXQU0daTorqRdKF0KkAEj/lEqlOvhp3Lix5n0iC4gslBBZiCGRWkCkEEEul8PS0tJErSV1mYuLC+Lj41FUVASpVPfe2lrVAVqwYIHOT0wathN3eADUtVnjavYkpG6Ql1p6gYog6p+Q81NR/qjwIZ4xQFW8rJGYqsaTSghDX0ql0jgB0MWLF9GuXTuIxWJcvHixyn07dOigc4NI/ccYw8niACisOQVApH4o3QNkRz1ABlPRkIUIfBtjvHwGQAEQqZy+llTS+re8Y8eOSExMhKurKzp27AiRSFThAqQikQhKpVIvjSP10+3HOXicVQCZhRgdvR1N3RxCtEKzwExH3QMEBuGyoodJPoRUSevf8rt378LFxUX9f0IqI/T+BDdtBEta0ZnUE6VngdEQmHGJzWwIzNfXFzNnzsTMmTNN3RSzpvVvubBAadn/E1IW5f+Q+kgjAJLTNHhjKj0EphJ6gOpQANS7d2907NgRS5cu1cvxzpw5AxsbG70ci+hOp07GRYsWYc2aNeW2r1mzRmNldmJ+GGM4Rfk/pB4qXQmaeoCMq/QQmFLdA2TCBumAMYaioiKt9nVxcakwGZwYl04B0A8//IDWrVuX2962bVt8//33tW4Uqb9uJWUjObsQcgsxAr0dTN0cQrSmkQNESdBGVbqzp64lQU+cOBGHDx/GsmXLIBKJIBKJcO/ePRw6dAgikQj79u1DSEgI5HI5jhw5gtu3b+Opp56Cm5sbbG1t0blzZxw4cEDjmL6+vhq9SSKRCD/99BNGjBgBa2tr+Pv7Y+fOnVW265dffkFISAjs7Ozg7u6O5557DklJSRr7XLlyBYMHD4a9vT3s7OzQo0cP3L59W33/mjVr0LZtW8jlcnh4eOD111+v/QmrR3QKgBITEyus9+Pi4qJeGZ6YJ2H4K8S3kcYnakLqOkqCNj7GGHILi5BXqES+gt/yCovU/88tLDLYraJJPBVZtmwZwsLC8NJLLyEhIQEJCQnw9vZW3z9nzhwsWrQIMTEx6NChA7Kzs/Hkk0/iwIEDiIqKwsCBAzF06FDExsZW+TwLFizA6NGjcfHiRTz55JN4/vnnkZqaWun+hYWF+Pjjj3HhwgXs2LEDd+/excSJE9X3P3z4ED179oSlpSX++ecfnDt3DpMmTVL3Uq1cuRKvvfYaXn75ZVy6dAk7d+5EixYttDonDYVOv+Xe3t44duwY/Pz8NLYfO3YMTZo00UvDSP0kJEB39aPhL1K/SMQiWIhFKFIxKoRoJHkKJQI+3GeS5766cCCsZdX/nB0cHCCTyWBtbQ139/LL+ixcuBADBgxQf9+4cWMEBgaqv//kk0+wfft27Ny5s8oelokTJ2Ls2LEAgE8//RTffPMNTp8+jSeeeKLC/SdNmqT+f7NmzbB8+XJ06dIF2dnZsLW1xXfffQcHBwds2rRJXSunZcuWGu166623MGPGDPW2zp07V3c6GhSdfsunTJmCmTNnQqFQoG/fvgCAgwcPYs6cOXjrrbf02kBSf6hUDCfv8E8slP9D6iOZhRhFhUrKASJaCwkJ0fg+JycHCxYswO7du9XVivPy8qrtASpdP8/GxgZ2dnblhrRKi4qKwvz58xEdHY3U1FSoVCoAQGxsLAICAhAdHY0ePXpUWCgwKSkJ8fHx6NevX01eaoOj02/5nDlzkJqaimnTpqGwsBAAYGlpiXfeeQdz587VawNJ/XEzKRupOYWwkkrQwcvR1M0hpMb83exw61EWvJ0oQdUYrKQSXF04EABwNT5TPQVeJBKhbRN7gz+3PpSdzTV79mzs27cPX375JVq0aAErKyuMGjVKfa2sTNlARVhkvCI5OTmIiIhAREQEfvnlF7i4uCA2NhYDBw5UP4+VlVWlz1XVfeZEpwBIJBLh888/x7x58xATEwMrKyv4+/tDLqeF68zZidvJAHj+T+l8CkLqi80vd0VuoRL2tBq8UYhEIvUwlJVMok6AlohFWg1PGYtMJtO6wO+RI0cwceJEjBgxAgCQnZ2Ne/fu6bU9165dQ3JyMj777DN1PtLZs2c19unQoQN+/vlnKBSKcsGVnZ0dfH19cfDgQfTp00evbatPanWVEjLc27VrR8EPofo/pN6zlErgZCMzdTPMklALCKg7M8AEvr6+OHXqFO7du4fk5ORKe2YAoEWLFti2bRuio6Nx4cIFPPfcc1Xur4umTZtCJpPhm2++wZ07d7Bz5058/PHHGvu8/vrryMzMxLPPPouzZ8/i5s2b2LBhA65fvw4AmD9/Pr766issX74cN2/exPnz5/HNN9/otZ11nc4h9pkzZ7BlyxbExsaW69rbtm1brRtG6heViuHUXZ7/QwEQIaSmSsc8dS0AevvttzFhwgQEBAQgLy+vytUQvv76a0yaNAnh4eFwdnbGO++8g8zMTL22x8XFBevWrcN7772H5cuXo1OnTvjyyy8xbNgw9T6NGzfGP//8g9mzZ6NXr16QSCTo2LEjunXrBgCYMGEC8vPz8fXXX+Ptt9+Gs7MzRo0apdd21nUipu1cwFI2bdqE8ePHIyIiApGRkYiIiMDNmzeRmJiIESNGYO3atYZoq9FkZmbCwcEBGRkZsLc37Dh0Q3E1PhNPLj8Ca5kEFz6KgFRCQ2CEkBL5+fm4e/cu/Pz8YGlpWe7+a4mZKCziPSVWUgn83eyM3URST1T1XqrJ9Vunq9Snn36Kr7/+Grt374ZMJsOyZcsQExOD0aNHo2nTprocktRzJ9X1f5wo+CGE1FhdHgIjDZNOV6rbt29j8ODBAAC5XI6cnByIRCK8+eab+PHHH/XaQFI/nC4e/gr1czJxSwgh9ZHGEFh9WweD1Es6BUBOTk7IysoCAHh6euLy5csAgPT0dOTm5uqvdaReYIzh7H0eAHWhAIgQooPSvT4U/xBj0CkJukePHoiMjET79u0xevRozJgxA//88w8iIyPNvrCSObqfkovk7ELIJGK096T1vwghNVc65qEhMGIMOgVA3377LfLz8wEAc+fOhVQqxdGjRzFy5EjMmzdPrw0kdd+Ze7z3p72XAyz1VFyMEGJeNGeBma4dxHzUOAAqKirCrl27MHAgr94pFosxZ84czJkzR++NI/XD2XtpAHgBREII0YVIREnQxLhqnANkYWGBV199FQUFBYZoD6mHhPyfzj6U/0MI0Y3GEBh1AREj0CkJOjQ0FFFRUfpuC6mHUrILcPtxDgAg2Id6gAghuqEhMGJsOuUATZs2DW+99RYePHiA4ODgcovBlV7VljRs5+7z4a8WrrZoREsIEEJ0RENgxNh06gEaM2YM7t69i+nTp6Nbt27o2LEjgoKC1F+J+RACoM6U/0MIqYXSFyNRAwyAfH19sXTpUvX3IpEIO3bsqHT/e/fuQSQSITo6ulbPq6/jNEQ69QBVtQ4KMS/CDLAQyv8hhNRC6ZhH0vDin3ISEhLQqJF+PzhOnDgR6enpGoGVt7c3EhIS4OzsrNfnagh0CoB8fHz03Q5SD+UrlLj0MAMAzQAjhNRO6V4fkRkkAbm7uxvleSQSidGeq77RaQhs/fr1Vd5qYsWKFeoFzYKDg3HkyJEq9//1118RGBgIa2treHh44MUXX0RKSorGPlu3bkVAQADkcjkCAgKwffv2Gr9GUr0LcelQKBlc7ORo6mRt6uYQQuqxuroa/A8//ABPT0+oVCqN7cOGDcOECRMA8OWhnnrqKbi5ucHW1hadO3fGgQMHqjxu2SGw06dPIygoCJaWlggJCSk30UipVGLy5Mnw8/ODlZUVWrVqhWXLlqnvnz9/Pn7++Wf8+eefEIlEEIlEOHToUIVDYIcPH0aXLl0gl8vh4eGBd999F0VFRer7e/fujenTp2POnDlwcnKCu7s75s+fX+XrOXPmDAYMGABnZ2c4ODigV69eOH/+vMY+6enpePnll+Hm5gZLS0u0a9cOu3fvVt9/7Ngx9OrVC9bW1mjUqBEGDhyItLS0Kp+3VpgOHB0dNW42NjZMJBIxuVzOGjVqpPVxNm3axKRSKVu1ahW7evUqmzFjBrOxsWH379+vcP8jR44wsVjMli1bxu7cucOOHDnC2rZty4YPH67e5/jx40wikbBPP/2UxcTEsE8//ZRZWFiwkydPat2ujIwMBoBlZGRo/Rhz9O0/N5nPO7vZq7+cNXVTCCF1XF5eHrt69SrLy8sr2ahSMVaQzVhBNkt8nMwu3nnILt55yHKy0tXbDXZTqbRqd0pKCpPJZOzAgQPqbampqUwmk7F9+/YxxhiLjo5m33//Pbt48SK7ceMGe//995mlpaXGtczHx4d9/fXX6u8BsO3btzPGGMvOzmYuLi5szJgx7PLly2zXrl2sWbNmDACLiopijDFWWFjIPvzwQ3b69Gl2584d9ssvvzBra2u2efNmxhhjWVlZbPTo0eyJJ55gCQkJLCEhgRUUFLC7d+9qHOfBgwfM2tqaTZs2jcXExLDt27czZ2dn9tFHH6nb1qtXL2Zvb8/mz5/Pbty4wX7++WcmEonY/v37Kz1PBw8eZBs2bGBXr15lV69eZZMnT2Zubm4sMzOTMcaYUqlkXbt2ZW3btmX79+9nt2/fZrt27WJ79uxhjDEWFRXF5HI5e/XVV1l0dDS7fPky++abb9jjx4/LPVeF76ViNbl+6zQEVlFEdvPmTbz66quYPXu21sdZsmQJJk+ejClTpgAAli5din379mHlypVYtGhRuf1PnjwJX19fTJ8+HQDg5+eHV155BYsXL1bvs3TpUgwYMABz584FwCtVHz58GEuXLsXGjRtr9DpJ1c4W5/8EU/4PIUQXilzg0yYAALfim9G8Fw/IbKrdzcnJCU888QR+++039VJPW7ZsgZOTk/r7wMBABAYGqh/zySefYPv27di5cydef/31ap/j119/hVKpxJo1a2BtbY22bdviwYMHePXVV9X7SKVSLFiwQP29n58fjh8/jt9//x2jR4+Gra0trKysUFBQUOWQ14oVK+Dt7Y1vv/0WIpEIrVu3Rnx8PN555x18+OGHEIv5wFCHDh3w0UcfAQD8/f3x7bff4uDBgxgwYECFx+3bt6/G9z/88AMaNWqEw4cPY8iQIThw4ABOnz6NmJgYtGzZEgDQrFkz9f6LFy9GSEgIVqxYod7Wtm3bas9dbeg0BFYRf39/fPbZZ5gxY4ZW+xcWFuLcuXOIiIjQ2B4REYHjx49X+Jjw8HA8ePAAe/bsAWMMjx49wh9//KFemR4ATpw4Ue6YAwcOrPSYAFBQUIDMzEyNG6maSsVoBhghxCw8//zz2Lp1q7oA8K+//opnn30WEglf+icnJwdz5sxBQEAAHB0dYWtri2vXriE2Nlar48fExKhTOwRhYWHl9vv+++8REhICFxcX2NraYtWqVVo/R+nnCgsL08i56tatG7Kzs/HgwQP1trLlbDw8PJCUlFTpcZOSkjB16lS0bNkSDg4OcHBwQHZ2trp90dHR8PLyUgc/ZUVHRxt9LVGdeoAqI5FIEB8fr9W+ycnJUCqVcHPTjPnd3NyQmJhY4WPCw8Px66+/YsyYMcjPz0dRURGGDRuGb775Rr1PYmJijY4JAIsWLdKIrEn1biZlIzO/CNYyCQI87E3dHEJIfSS15j0xAB5nFyAxg68x2cbdDhYSvX0+r/y5tTR06FCoVCr89ddf6Ny5M44cOYIlS5ao7589ezb27duHL7/8Ei1atICVlRVGjRqFwsJCrY7PR8Sq9vvvv+PNN9/EV199hbCwMNjZ2eGLL77AqVOntH4dwnOVLTMgPH/p7VKpVGMfkUhULg+qtIkTJ+Lx48dYunQpfHx8IJfLERYWpj4HVlZWVbaruvsNQacAaOfOnRrfM8aQkJCAb7/9Ft26davRsSr6QVRWA+Lq1auYPn06PvzwQwwcOBAJCQmYPXs2pk6ditWrV+t0TIAPk82aNUv9fWZmJry9vWv0OsyNMP09qKmj4f9QEUIaJpFIPQwlklmASfnfErGlrWZWtIlZWVlh5MiR+PXXX3Hr1i20bNkSwcHB6vuPHDmCiRMnYsSIEQCA7Oxs3Lt3T+vjBwQEYMOGDcjLy1MHAidPntTY58iRIwgPD8e0adPU227fvq2xj0wmg1KprPa5tm7dqnFdPH78OOzs7ODp6al1m8s6cuQIVqxYgSeffBIAEBcXh+TkZPX9HTp0wIMHD3Djxo0Ke4E6dOiAgwcPGrUzQqcAaPjw4Rrfi0QiuLi4oG/fvvjqq6+0OoazszMkEkm5npmkpKRyPTiCRYsWoVu3buo8ow4dOsDGxgY9evTAJ598Ag8PD7i7u9fomAAgl8shl8u1ajfhKP+HEKJPQrwjggh1J/Qp8fzzz2Po0KG4cuUKXnjhBY37WrRogW3btmHo0KEQiUSYN29elb0lZT333HN4//33MXnyZHzwwQe4d+8evvzyy3LPsX79euzbtw9+fn7YsGEDzpw5Az8/P/U+vr6+2LdvH65fv47GjRvDwcGh3HNNmzYNS5cuxRtvvIHXX38d169fx0cffYRZs2ap83900aJFC2zYsAEhISHIzMzE7NmzNXp1evXqhZ49e+Lpp5/GkiVL0KJFC1y7dg0ikQhPPPEE5s6di/bt22PatGmYOnUqZDIZ/v33XzzzzDMGq2Gk06tVqVQaN6VSicTERPz222/w8PDQ6hgymQzBwcGIjIzU2B4ZGYnw8PAKH5Obm1vuBySMwQpdeGFhYeWOuX///kqPSXRzlvJ/CCF6JC4Oe8SiulkJum/fvnBycsL169fx3HPPadz39ddfo1GjRggPD8fQoUMxcOBAdOrUSetj29raYteuXbh69SqCgoLw/vvv4/PPP9fYZ+rUqRg5ciTGjBmD0NBQpKSkaPQGAcBLL72EVq1aqfOEjh07Vu65PD09sWfPHpw+fRqBgYGYOnWqOvCqjTVr1iAtLQ1BQUEYN24cpk+fDldXV419tm7dis6dO2Ps2LEICAjAnDlz1D1WLVu2xP79+3HhwgV06dIFYWFh+PPPP2FhoddMHU3VzhMzIGEa/OrVq9nVq1fZzJkzmY2NDbt37x5jjLF3332XjRs3Tr3/2rVrmYWFBVuxYgW7ffs2O3r0KAsJCWFdunRR73Ps2DEmkUjYZ599xmJiYthnn31G0+D17GFaLvN5Zzfze3c3y8pXmLo5hJB6oKqpy4wxlpZTwC7EpbGr8fR3l1TNpNPgR40ahZCQELz77rsa27/44gucPn0aW7Zs0eo4Y8aMQUpKChYuXIiEhAS0a9cOe/bsUVeaTkhI0MhwnzhxIrKysvDtt9/irbfegqOjI/r27asRKYeHh2PTpk344IMPMG/ePDRv3hybN29GaGioLi+VVODwjccAgEBvR9jKDRidE0LMhtDpYwZFoEkdIWJMi/TzMlxcXPDPP/+gffv2GtsvXbqE/v3749GjR3proClkZmbCwcEBGRkZsLenGU5lTd1wDn9fScSb/VtiRn9/UzeHEFIP5Ofn4+7du+rK/2Vl5ilwLyUHVlIJ/N3sTNBCUl9U9V6qyfVbp4/v2dnZkMlk5bZLpVKqodPAKZQqHLvFM/t7t3IxcWsIIQ2FjdwC9pZSOFhJq9+ZED3QKQm6Xbt22Lx5c7ntmzZtQkBAQK0bRequ8/fTkFVQBCcbGdp7lp9hQAghupCIRfB1tkEjm/IfrgkxBJ16gObNm4enn34at2/fVpe/PnjwIDZu3Kh1/g+pnw4V5//09HeGmAbrCSE1pEPWBSEa9PUe0ikAGjZsGHbs2IFPP/0Uf/zxB6ysrNChQwccOHAAvXr10kvDSN106DoPgHrR8BchpAaEysK5ubkmqfpLGg6hurRQBkdXOk/hGTx4sMYaXKThe5SZj5iETIhEQE9/CoAIIdqTSCRwdHRUrydlbW1dJ+v9kLpNpVLh8ePHsLa2rnWNIJ0efebMGahUqnJTy0+dOgWJRIKQkJBaNYrUTcL09w6eDmhsS5WzCSE1I6xSXtWimoRURywWo2nTprUOoHUKgF577TXMmTOnXAD08OFDfP755zVenI3UD0IA1Ksl9f4QQmpOJBLBw8MDrq6uUCgUpm4OqadkMlmtlu0Q6BQAXb16tcIy30FBQbh69WqtG0XqniKlCkeEAKiVazV7E0JI5SQSSa3zNwipLZ1CKLlcXmGxw4SEBMOu20FM5sKDdGTmF8HBSoqO3o6mbg4hhBBSKzoFQAMGDMDcuXORkZGh3paeno733nsPAwYM0FvjSN0hzP7q4e8MCU1/J4QQUs/p1F3z1VdfoWfPnvDx8UFQUBAAIDo6Gm5ubtiwYYNeG0jqBiEA6k3DX4QQQhoAnQIgT09PXLx4Eb/++isuXLgAKysrvPjiixg7dqy61gNpOJKzC3DpIe/t69nS2cStIYQQQmpP54QdGxsbdO/eHU2bNlUXJdq7dy8AXiiRNBz/FSc/t21iD1e78osYEkIIIfWNTgHQnTt3MGLECFy6dAkikQiMMY35+EqlUm8NJKb39+VEADT9nRBCSMOhUxL0jBkz4Ofnh0ePHsHa2hqXL1/G4cOHERISgkOHDum5icSUbiVlITKGz/gbHuRp4tYQQggh+qFTD9CJEyfwzz//wMXFBWKxGBKJBN27d8eiRYswffp0REVF6budxERW/HsbjAERAW5o6WZn6uYQQggheqFTD5BSqYStrS0AwNnZGfHx8QAAHx8fXL9+XX+tIyYVm5KLPy/wn+3rfVuYuDWEEEKI/ujUA9SuXTtcvHgRzZo1Q2hoKBYvXgyZTIYff/wRzZo103cbiYmsPHwbShVDz5Yu6ODlaOrmEEIIIXqjUwD0wQcfICcnBwDwySefYMiQIejRowcaN26MzZs367WBxDQSM/Kx9dwDAMDrfaj3hxBCSMOiUwA0cOBA9f+bNWuGq1evIjU1FY0aNar16qykbvjxvzsoVKrQxdcJXfycTN0cQgghRK/0tnCXkxNdJBuK5OwC/Hb6PgDK/SGEENIw1X49edLgrDl6F/kKFTp4OaCHP1V+JoQQ0vBQAEQ0ZOQpsOEE7/15rU8LGtIkhBDSIFEARDRsO/8AWQVF8He1xYA2bqZuDiGEEGIQFAARNcYYfj0VCwAYH+YDsZh6fwghhDRMFAARtdN3U3ErKRvWMgkte0EIIaRBowCIqAm9P091bAI7S6mJW0MIIYQYDgVABACQkl2gXvX9uS4+Jm4NIYQQYlgUABEAwB/nHqBQqUKglwPaezmYujmEEEKIQVEARKBSMfx2mg9/PR9KvT+EEEIaPgqACI7dTsb9lFzYyS0wJNDD1M0hhBBCDI4CIILfipOfR3byhLVMb6ujEEIIIXUWBUBm7lFmPvZffQQAeI6GvwghhJgJkwdAK1asgJ+fHywtLREcHIwjR45Uuu/EiRMhEonK3dq2baveZ926dRXuk5+fb4yXU+/8fiYOShVDZ99GaOVuZ+rmEEIIIUZh0gBo8+bNmDlzJt5//31ERUWhR48eGDRoEGJjYyvcf9myZUhISFDf4uLi4OTkhGeeeUZjP3t7e439EhISYGlpaYyXVK/kFSqx/iRf9+u50KYmbg0hhBBiPCYNgJYsWYLJkydjypQpaNOmDZYuXQpvb2+sXLmywv0dHBzg7u6uvp09exZpaWl48cUXNfYTiUQa+7m7uxvj5dQ7G07ew+OsAng7WWFIhyambg4hhBBiNCYLgAoLC3Hu3DlERERobI+IiMDx48e1Osbq1avRv39/+Pho5q5kZ2fDx8cHXl5eGDJkCKKiovTW7oYiu6AI3x++AwCY3tcfUonJR0MJIYQQozHZlJ/k5GQolUq4uWmuOO7m5obExMRqH5+QkIC9e/fit99+09jeunVrrFu3Du3bt0dmZiaWLVuGbt264cKFC/D396/wWAUFBSgoKFB/n5mZqcMrql9+Pn4PqTmF8HO2wQha94sQQoiZMfnHfpFIc8Vxxli5bRVZt24dHB0dMXz4cI3tXbt2xQsvvIDAwED06NEDv//+O1q2bIlvvvmm0mMtWrQIDg4O6pu3t7dOr6W+yMxX4Mf/eO/PjH7+sKDeH0IIIWbGZFc+Z2dnSCSScr09SUlJ5XqFymKMYc2aNRg3bhxkMlmV+4rFYnTu3Bk3b96sdJ+5c+ciIyNDfYuLi9P+hdRDa47eRUaeAi1cbTE0kHJ/CCGEmB+TBUAymQzBwcGIjIzU2B4ZGYnw8PAqH3v48GHcunULkydPrvZ5GGOIjo6Gh0flFY7lcjns7e01bg1VRq4Cq4/cBQDM7O8Pibj63jZCCCGkoTFp2d9Zs2Zh3LhxCAkJQVhYGH788UfExsZi6tSpAHjPzMOHD7F+/XqNx61evRqhoaFo165duWMuWLAAXbt2hb+/PzIzM7F8+XJER0fju+++M8prqutWHbmDrIIitHa3w5PtaNkLQggh5smkAdCYMWOQkpKChQsXIiEhAe3atcOePXvUs7oSEhLK1QTKyMjA1q1bsWzZsgqPmZ6ejpdffhmJiYlwcHBAUFAQ/vvvP3Tp0sXgr6euS80pxNpjQu9PS4ip94cQQoiZEjHGmKkbUddkZmbCwcEBGRkZDWo4bOWh2/j872sI8LDHX9O7a5VsTgghhNQXNbl+0/QfM8EYw5ZzPLl7QrgPBT+EEELMGgVAZuJ8bBruPM6BlVSCwVT1mRBCiJmjAMhMbDn7AAAwqL07bOUmTf0ihBBCTI4CIDOQW1iE3RcTAACjQxp2kUdCCCFEGxQAmYG9lxKRXVCEpk7WCPVzMnVzCCGEEJOjAMgMCMnPzwR7UfIzIYQQAgqAGrzYlFycvJMKkQh4OtjL1M0hhBBC6gQKgBq4P4p7f7q3cEYTRysTt4YQQgipGygAasCUKoY/zvHZX89Q8jMhhBCiRgFQA3b8djLiM/Jhb2mBiAA3UzeHEEIIqTMoAGrAhNo/T3X0hKVUYuLWEEIIIXUHBUANVEaeAvuuJAIAngmh5GdCCCGkNAqAGqi/LiagoEiFVm52aO/pYOrmEEIIIXUKBUANlDD76+lgT6r9QwghhJRBAVADdPtxNs7HpkMiFmF4R09TN4cQQgipcygAaoC2nefJz71ausDV3tLErSGEEELqHgqAGhilimHb+YcAgFFU+ZkQQgipEAVADczx28lIyMiHg5UU/dq4mro5hBBCSJ1EAVADs7W48vOwwCaQW1DtH0IIIaQiFAA1IJn5CvxdXPuHhr8IIYSQylEA1IDsuZiAfIUK/q626OBFtX8IIYSQyliYugFEN+fup+Lmo2y083RAK3c7SCVi9cKnTwd7Ue0fQgghpAoUANVD6bmFeP6nU8hXqAAAcgsx2njYIzouHWIRMCKIav8QQgghVaEAqB7acykR+QoV7Cz5jy8rvwjRcekAgJ4tXeBGtX8IIYSQKlEAVA/tiOJ1ft7o2wJTujfD/dRcXHyQjnvJuRjZiXp/CCGEkOpQAFTPxKXm4vS9VIhEwLBAT4jFIvg528DP2cbUTSOEEELqDZoFVs/svBAPAAhr1hjuDjTURQghhOiCAqB6hDGG7cXDX8Mp0ZkQQgjRGQVA9ciV+EzcSsqG3EKMJ9q5m7o5hBBCSL1FAVA9IiQ/92/jBntLqYlbQwghhNRfFADVE0oVw5/F+T80/EUIIYTUDgVA9cTx28l4nFUAR2sperV0MXVzCCGEkHqNAqB6Qkh+HtzeAzIL+rERQgghtUFX0nogr1CJfZf5Ku+0zAUhhBBSeyYPgFasWAE/Pz9YWloiODgYR44cqXTfiRMnQiQSlbu1bdtWY7+tW7ciICAAcrkcAQEB2L59u6FfhsFkFxRh2cGbyClUwquRFYJ9Gpm6SYQQQki9Z9IAaPPmzZg5cybef/99REVFoUePHhg0aBBiY2Mr3H/ZsmVISEhQ3+Li4uDk5IRnnnlGvc+JEycwZswYjBs3DhcuXMC4ceMwevRonDp1ylgvSy/iUnPx8e6rCPv0IL4/fBsAMLZLU1rlnRBCCNEDEWOMmerJQ0ND0alTJ6xcuVK9rU2bNhg+fDgWLVpU7eN37NiBkSNH4u7du/Dx8QEAjBkzBpmZmdi7d696vyeeeAKNGjXCxo0btWpXZmYmHBwckJGRAXt7+xq+qtpRqRg+3HkZv52Khar4J9PMxQaTuvnhuS5NIRZTAEQIIYRUpCbXb5P1ABUWFuLcuXOIiIjQ2B4REYHjx49rdYzVq1ejf//+6uAH4D1AZY85cOBArY9paudj0/DLSR789PB3xroXO+PAm73wQlcfCn4IIYQQPTHZYqjJyclQKpVwc3PT2O7m5obExMRqH5+QkIC9e/fit99+09iemJhY42MWFBSgoKBA/X1mZqY2L8EgIq8+AgAMC2yC5WODTNYOQgghpCEzeRJ02ZwWxphWeS7r1q2Do6Mjhg8fXutjLlq0CA4ODuqbt7e3do03gMgYHgANCHCrZk9CCCGE6MpkAZCzszMkEkm5npmkpKRyPThlMcawZs0ajBs3DjKZTOM+d3f3Gh9z7ty5yMjIUN/i4uJq+Gr04/bjbNx5nAOpRITerajYISGEEGIoJguAZDIZgoODERkZqbE9MjIS4eHhVT728OHDuHXrFiZPnlzuvrCwsHLH3L9/f5XHlMvlsLe317iZgjD81bVZY9jRWl+EEEKIwZgsBwgAZs2ahXHjxiEkJARhYWH48ccfERsbi6lTpwLgPTMPHz7E+vXrNR63evVqhIaGol27duWOOWPGDPTs2ROff/45nnrqKfz55584cOAAjh49apTXVBtCABRBw1+EEEKIQZk0ABozZgxSUlKwcOFCJCQkoF27dtizZ496VldCQkK5mkAZGRnYunUrli1bVuExw8PDsWnTJnzwwQeYN28emjdvjs2bNyM0NNTgr6c2HmcV4HxsGgCgXxsKgAghhBBDMmkdoLrKFHWAfj8ThzlbL6Kdpz12v9HDKM9JCCGENCT1og4Q0bS/ePhrQBt3E7eEEEIIafgoAKoD8gqVOHrrMQADT3/PeAB83x04+b3hnoMQQgipBygAqgOO3HyMfIUKno5WaONhZ7gnurAJSLwE/PMxkG+6Yo+EEEKIqVEAVAcIs78GBLgZdrHTu//xr4XZwMXNhnseQgghpI6jAMjElCqGf64lATDw8JciH4g7VfL9mZ8Ayn8nhBBipigAMrGo2DSk5BTCztICXfycDPdED84ARfmAtTMgtQEeXwPu1f3aSIQQQoghmLQOkDlKzi5ATEImYhIycTU+E2fu8do/fVq5QioxYDwqDH817wPIbIFza4EzqwA/mnJPCCHE/FAAZEQHYx5h8s9ny20Xi4BRwV6GfXIhAPLrCTTpxAOgmN1AZjxg38Swz00IIYTUMRQAGZG/qx1EIsDHyRoBTezRxt0ebTzs0d7LAW72loZ74oJs4GFx4OXXE2jkCzQNA2JPAOfWAX3eM9xzE0IIIXUQBUBG5O1khcvzB8JGbuTTHnsSUBUBjk158AMAnaeUBEA9ZwMSWnyVEEKI+aAAyIhEIlH54OfhOeDUjzw4cW8HuLcHHH0BsR7zge4e5l/9epZsazMMsHEFsh8BMbuAdiP193yEEEJIHUcBkKkdmF+SnyOQ2fIhqsBngdaDAalV7Z5Dnf/Tq2SbhQwIngj8t5hPiacAiBBCiBmhAMiUFPlAbHFtnrYjgdQ7QFIML1R4K5Lf5PZAwFO8xyYniVdyTrwMPLrMh7Mm7QOkVeQP5aUBCRf4/33LzPgKnggc+Qq4f4w/r2sbQ7xKQgghpM6hAMiUHpwGlAWArTswag0gEgHKIl6jJ2YncGEjkB4LRG3gt7ISooEr24GOYyt/jntHATDAuRVg76F5n4Mn4D8AuPE3cHUnBUCEEELMBhVCNCVhaKpZLx78AIDEgucC9XkPmH4BmLgHCHoBaOTHc3i6vgYMXwmEvsr3P7NKu+conf9TWqsn+dcbe2v3WgghhJB6hHqATKm64EQsBny78VtZLQbw3J2H54CH5wHPTro9R8sn+Nf4KCAzoXwvESGEENIAUQ+QqRRk8eAFqDw4qYqtC9B2OP//mdUV75P1iA+nQQT4dq94Hzs3wDOY///mvpq3gxBCCKmHKAAyFaE2TyNfPgVeF51f4l8v/wHkppa//94R/tW9PWBdxTpjLQfxr9f/1q0dhBBCSD1DAZCp3DnEv+rS+yPw7sKDm6J8IOqX8vdXVP+nIq2eKGmTIk/39hBCCCH1BAVAplJRbZ6aEolKeoHOrgZUqpL7Hp4Hrv6p3XO4tQPsvYCiPODOYe2e+9ZB4MG5mreZEEIIqQMoADKF3FRezwcoX5unpto/A1g6AGn3gNsH+bY7h4GfhwL5GTy/p1nvqo8hEpX0AmkzG+zmAeCXkcDaJ3igRQghhNQzFACZglCbx6U1T0KuDZk10PEF/v/Tq3g9n19H8WKKfj2B8X/yqs/VEfKAbuwDGKt8v7w0YOcb/P/KQuD3CRXnHxFCCCF1GAVAplDd1PSa6jyZf725H9gygQcmbYYCz/8ByO20O4Zvd0BqA2Ql8AKLldn7LpAVDzg1B5yaARmxwLaXNIffTEWRb+oWEEIIqScoADIFfQdAjZsDzfsCYABTAZ3GA8/8DFjItT+G1BJo3of/v7LZYDG7gYubAJEYGPE9MHoDYGEF3DoA/PdFrV+GWtp9QKmo2WMOLwb+5wZ82RLYMBKI/BC49AeQk6y/dhFCCGkwKAAytqxEIPk6qqzNo4te7wDWzkDP2cDQ5YBYUvNjtBKmw+8pf19OCrB7Jv9/+PTiGWjtgCFf822HFvHcoNq6+DuwLBD4oSc/V9pgDDi7hv8/+xHPhTq2DNg6GVjVp270TtVncWeA5JumbgUhhOgVBUDGdre4No9HIGDVSH/HbdoVmHMb6PtBybIaNeU/EIAISLwIZDws2c4Y8NebQM5jwKUNX6ZD0HEsEPwiAAZsmwLc/gdQKXV7/oyHwF9v82MlXQVWR/AFYquTEM2H7qQ2wIt/A4OXACGTeO9UemzVQ3qkao+vA2sGAusG17xXjhBC6jBaCsPYtK3NYwq2LoBXCPDgDF9k1bsLn6324AyfUi+24ENfZYfWBn3Og4z4KGDDCMDeE+gwGggcy9cwS75esoJ9ViIfomtWZmo+Y8DO14GCDB4c5mcCaXeB1QOBcdt4vaPKCEN2zfsAPmH8BgDZScC13XyIrrKlQkjVLmwEmJL3rN07WjJMSggh9RwFQMamj/o/htRqEA949r9f/r6es4EmHctvt5ADz20BDn0KXN4KZD4Ejn7Nb2ILXvG6tKs7gBE/AO1HlWw7t473HllYAiN/4lP7f3kaeHQJWDsYeG5zSWBTljB1XxjCE7TozwOgm5FArzlangCiplIBF7eUfB+zq24GQIW5PBFfbg8M/F/VVc+JcTCme080IUZCQ2DGlHYPSL/Pg4KmXU3dmoq1HcGDEACwdedBRLeZwNhNPM+oMrYuPB/orRs8AbvlIEAk4cGP3AHw6QZ0eQVoPYRv2zoFOPUjf2zaPWD/B/z//T4EXFry8gATdwNNw3iv0IbhfDimrMx4IOECAFHxEF4p/gP414dnaaq+Lu4fAzIflHx/7a+6mU8V/SsPdC/8BnzfHbh/wtQtMm8qJa8TtrQ9L5hKSB1FPUDGlHyT56V4BAJyW1O3pmJOzYA3r/BPcLYuNX+81JIv0tp2OA86CrMBB++ST4MqFfD3u8DpH4C9s4HcFH6hLczmQVLoqyXHsnIEXtgG/Daar2t2dCkwYqXm890oHv7yCinfXgcvnrP0OIb3LpXucSLVu7iZf+3wLE+Mz07kwaR3F9O2qzSVEji5gv9fZsd7H9cNBvrMBbrP0m0yAKmdi5v57xvAA6HubwJ93gckUtO2i5AyKAAyJv8BwLv3eW5KXWbjrJ/jWDuVH44Qi3nOkHVjPmR2+DO+XWoDPPUdv780mTXQfz7wUz/g0hbeQ2TvUXK/kP/T8omK2+DfnwdAtw5QAFQTirySpVQ6jeN5QJe2ADE7Kw6AYnbz4Kg0kZgH1O7tedHPmpRl0Nb1PTxR3tIReP0MsH8eL9XwzyfA7UOAd2fN/d078F5OGp4xDEU+8M//+P/dO/AJFUe/Bu4dA0at1n3hZ0IMgAIgY7OQA47epm6FaYlEQO93eHC0ZzYABkR8DDj5Vby/VwgfCos9wXuO+s/n2wtzS5LKy+b/CFoMAI5/wwMglap8gFXXMcan9IvEQLfpxnveG38DBZm8965pOK+ndGkLzwMa8LFmAJF4Gdj8AoAqKoiLLQDnlnzdOfd2PChya69bL2Npx7/lXztPBmxdgZE/8AT7v94C7h/lt7KubAeGfcN7GIl+nf6RD5vaewKT9/P30c7pwIPTfHhy1FqgRT9Tt5IQABQAEVPq8hLvGciI4zPGqhL+Bg+Azq4BerzNhxDvHAKK8gGHpoBrQMWPaxoGyGz5FP7EC0CTIL2/DIM6uBA4uoT/v3lfHjwYw8Xf+df2z/CgsUV/nhuWdg94dEWzHQc+AsAAzxDAO7Rku7KA520lXgLy03lpg6SrwKXfS/axdQd6vwuEvFjzNsadBuJOAhIZ0OXlku0dnwO8OgPRvwFFBSXbC7P5tpidQHw0MGpN+R4iXeRnAJvH8eG30iwdgZE/8kKl5iAvDTjyFf9/n/cBqRXvbWsSBPwxCXh4Dtj0PDChkl5EQoyMAiBiWn5aLgbbchBffiP1NhD1C9B1aqnZX09UPqRhIeMz7q7/xQs1lg6AFHl8pplKyROu61qOwsnvS4IfgOdWGCMAyknhy6oAQIcx/KvcFmjej5/HmF0l7bhzmPeuiS0qv9gzxoODxEvF5RCKv6be4XlFu2cCUmsgcEzN2nn8G/61/WjAzl3zPmd/oP9H5R8TPBH440UeyK19Aug7jxf2rE3P4PW9JT2RZW17GZi0D5DUwT+1jPGgRV+z5o4s4YGuawAQ+GzJ9ka+vD7X5uf5++rXZ/g5cW1d/TFVKt4TaS69dbmpNIvRiEw+HrBixQr4+fnB0tISwcHBOHLkSJX7FxQU4P3334ePjw/kcjmaN2+ONWvWqO9ft24dRCJRuVt+Pq0TVa+JxUDYa/z/J1fwonzV5f8I/Pvzr7ciNbf/8wlPwI47yXuX6pLLW3myOAA0K556fukP3YtM1sSVbXymnkeg5kWqzRD+NWYX/6pS8SVHAF54srKeDpGIJ6S3GgT0mg2MXg9MPw/MfVCS9P7nNB5IlcUYn9WVmaC5PfUOn/kFAOGva//aPDsBr/wHtB3JX+OBj4DDn2v/+Io8KM59aj+aX+hf/Jsn78sdeF7U8WW1O74hpN7hVdK/9Ofvq9rKeACc+oH/v//88snnFjLgmXW8lzA/nSdHZ5TpMavIvveAL1qUlA9pqFRKYNdMYLEfsH0qFR01EpMGQJs3b8bMmTPx/vvvIyoqCj169MCgQYMQGxtb6WNGjx6NgwcPYvXq1bh+/To2btyI1q01P0nY29sjISFB42ZpaWnol0MMLXAsT55Ov8+HhnKS+PBWdUuKtCieDv/gTMl0+PvHgRPflexT2fpnpnDnELDtFQAM6PwSr4Fk6cAXob1X9QeEKj2+zoe2qguiSs/+Kq3lE7y0QdIVIOU2cHU7L4ApswV66lBnSW4LDPyUD7OpioDN4/kwiSDuDK9CvfYJYHlH4MB8PtwEACdX8nXvWgwAXNvU7HktHfjw1xPFCfgnvq1dmYQHZ/jXVk+UFOJs0Y8n+wPAv4v4sKE2bh4AzvwExJ4ECrJ0b1NVLv0BfN+TFy5VFQE73wCSYireNzMBOPdzyXmvzL+f8iFPn+6Af0TF+8hsgOd+Bxr78x7BX0ZWf95v/A2oFMCBBTwY1lVhDnBmNX/NtTmOIRQVAFsmAufW8u8vbORDhYW52j0+Phq4sAlQFlW7a63lpfGabdouU1THmTQAWrJkCSZPnowpU6agTZs2WLp0Kby9vbFy5coK9//7779x+PBh7NmzB/3794evry+6dOmC8PBwjf1EIhHc3d01bqQBkFkDnafw/x9fzr8271v97CJHb55rxFTAnX+Bgmxgx6sAGP9jDPDhtLrwh/HWAWDTC/yPfsBwfhG1kPNcCqAkN0cXWybygoGHPqt8n5Tb/IIuEgPtnta8z9qpZMjyynYehAJAtxm6JzOLxcBTK/jPUZHDh0duHQR+nwCs7g/EneJBV1E+n020PIgPfUX9wh9fk96f0kQiIHQqn6lUmK0ZDNeEIo9XOAd43lFpgc8CrZ7kP8vtU4GiwqqPde8Y8OsonsC9ZiCwyIuvi7fxOeCPyZq3gwtrvtBvYS4PdrZOBgqzeH6cbw9AkcuT2PMzNfdPugas6gvsmg6sfRLIelTxcR+c47lVADBgYdUz7Gwa88rudh7A42vAxrGV93YU5vChSoD3pAlT68tKigH2vlP17Nq/5wJ/zQJ+7A2sCOMlNTLjK9/fWAqy+Hs+ZifPZes+i+fa3dzHA8S89Koff/VPYPUAYPsrwM9DtetVq01b1w8Hds0AVnbTz9qPJmayAKiwsBDnzp1DRITmp4WIiAgcP368wsfs3LkTISEhWLx4MTw9PdGyZUu8/fbbyMvL09gvOzsbPj4+8PLywpAhQxAVFVVlWwoKCpCZmalxI3VU55cASamAp9WT2j2uRfEw2M0DfNgm7R6f4TSh+A9P6h3TLvj56CrPR/rlaX5x8u3Bc2qEoQShN+bqn9p/Miwt5TZPQAaA/xYDN/ZVvJ+wqGyzPrwYZVmti4fBDi/m59DGFeg6rebtKc1CxofFPDryulC/jOTVwiECgl4A3rwMPLuRB6u5KbxopiKXzySrTUV1kaikuOepH/in25pKuMB7UWxc+fup7PGHLOVr/iVeBI58WflxSgflzi0BuyZ8e9o9nnd1+Q/N25GveDB4ZAkPwio7Zuwp3qO0ayawMgw4vx6AiFd1n7CbD0vZewIpt4A/Xyv5EPDgLO95yyoOEh5dBtZEAKl3S47PGHB2LbDuSd7ugOGAV3D158yxKfDCVl65O+4kzyOryONr0JhZePjz8h9SCrKB38YAp74H9lbSC5key4tlAvxvx+MYPvS5JIBf0C/+rtvvVG3lpAA/D+P5YzJb4PktPG9t3A4+fBp7gte0qizwPLeOf6hRFgIQAbHHge+78Zw0fSsq5In+wrqKucnAr0/zshO6Dtelx5nmvJdisgAoOTkZSqUSbm6af2Td3NyQmFhx99qdO3dw9OhRXL58Gdu3b8fSpUvxxx9/4LXXXlPv07p1a6xbtw47d+7Exo0bYWlpiW7duuHmzcovbosWLYKDg4P65u1t5tPU6zJbl5IES5G48u72soSq0Fd3AGdX8/8/9S1g34QHG0BJUrUxZSYAf77O/3DdOgCIpTwvZuwmzZ4t71B+4SjM5rVvakooGCkuTsbd9nLJp2uAX1gOf8GHgwBe+6ciQgCkLJ5d1ftd/RT1lNsBz//B6wYBPOF66lFeG8q+CdD6SWDaCWDwV4B1cZ2qnrNrX8+n1ZN8an5hFk86rykh/8erc8VtsXPji/MCwH9f8iGYikTO40O7Dt7AlIPAWzHA7DvA+D+BJ78EBi4quUX8j+dnFWQCBxcA34QAUb/yC9/hxfxCtTyI9yCtieA9SufW8p+3rRs/Zt8PeGK2jTOv3C6W8l6IE9/xnpafh/GA0DMYmPIP4OjDH79mIE9gz8/gyeS7Z/LeuRb9eSV4bbm1LfndrWyx4kfFAbtrWx64xJ0qnwsknDeA90qWHkIVHP2aB6nNegOzbwJDl/PSDmC8R3jbSzwXasdrfL07Y1Q7f3SF/2zizwNWTvyDWLPe/D6fMODFPTyofnQZ+KEHcPBjIPmW5mvaNYP3aneaALx+ln+AyEsDNj7Le7xKz4CsTlEhsO994KvWPDey9PCrSsVz9O78W7zg9F7+QRTgPfFrnuC9tmd+4m1a1Q/4shVvg6KS3NuYXfxvnpDnaCIixkzT7x8fHw9PT08cP34cYWElazz973//w4YNG3Dt2rVyj4mIiMCRI0eQmJgIBwcHAMC2bdswatQo5OTkwMrKqtxjVCoVOnXqhJ49e2L58uUVtqWgoAAFBSVvlszMTHh7eyMjIwP29va1falE31Ju8675Zr2B0T9r95iiAuBzPz7MAvBf4MHFn8hPrwL2vM3/KE4yYhB07xgfAigozq8IeAro91HlycT/fAL89wW/cDy/peJ9KrNuCM8f6r+A//F5eJZfRCft5z1g+94DThUPPfd6B+g9t/Lg4qcBvK5L4xbAtJP6nT1XkMU/GbpVUtYA4J/6M+P5kin6cGUHsGUC/9T95iWeIyRgjPfyOPvzHJayfp/Ag+p+HwI93qr8ObZM5BdoB28ecJTuKbl1kPd6ATw4ES6EVVGpeF2mgws1lyspy9ad95S5t+OBXot+vEeqLOF3QCThHyxUCt4LOOYXHuBmJQIbRvL8L0sHPsVfWNan30dA2Os1n0l3bDkPYNoMA8ZsKH//33P5hIfQV/mF/vQPPMfoxb/4/aXPm2cwD358ewATdpW8dzMeAMs68tfz4l7Ap1S6ROod3vtzYaPmhwGHpnxGYuBY/ZcwYIwHo3/P5YGjvRcwbnvF7+XUO/ycp5XqdfPqwmfVCaUkus/i7z2RiP+NOzC/pDK6rRvPrwscW/Xs0dQ7wJYXNQNRGxf+N6DTBN5jfvI7/rN+bnNJb/rVnXwB66ryw9zbA6PWAc4t+PeKfN6De2YV/94zmPdEyqwrP0YNZWZmwsHBQavrt8kCoMLCQlhbW2PLli0YMWKEevuMGTMQHR2Nw4fLd4tOmDABx44dw61bJZFwTEwMAgICcOPGDfj7+1f4XC+99BIePHiAvXu1u7jV5AQSEykq5BfemvQAbBzLe08a+QGvHiu5oKXH8nWLRGJg9u3aT0MtyOKf8JJv8ByTihaQvbaHf4Iuyuef3AYtBpqGlt+vtOSbwLch/CL11nXt827y0oEvmvNPwdOjeMDzfQ8gLxXo+ALffnET3/eJz3mJgapc+4sHTMO+Afx6ateGukyl4sNDj68BfT7gM9UA/mn6z9f5bLP2zwBP/1T+sV+343WsJuyq+lzkpPBq5ml3+YWk/3yg62u8F2dlOE8KLh2Ua0uRxxPCz67hQ0pCoOPenn/V9j3CGO8JuVQcWAcM50OwpXsh89L4cFPcKf69Y1Ne2NArpGZtFtw5BKx/il/QZ1wof78wPDTsG94juLwjH+6Z+Bd/bcJ56/IyL2XwTTDvmXz+j5Ie37/e5hdb3x681EVlrz32JF9L7soO/jMReHXhye2lh90BPqvRvT3/W6Jt4JefwYtCXt3Bv28xABjxfdWV9xV5/G9W9Ebg9kEeCAoiPuH10cq6vpc/T06pnCj39vw97BnCe9+EsgKX/uDDo4VZPDAOnw5EbeBBEcCHYoVh0JGrgA6jNZ8r7T7PrUq6xicjCO8/gA9J5qbwXqMhX/MZmFte5GUwAP5c/T7Ue/mRehEAAUBoaCiCg4OxYsUK9baAgAA89dRTWLRoUbn9f/zxR8ycORNJSUmwteXd7n/++SdGjhyJ7OzsCnuAGGPo0qUL2rdvrzFdvioUADVQD88Bhz4H+r7Pez9KW9mNdzeP+LF8PZpre3j9oa7TKl9b6v5x/skr8bLmJzaAT7nu/xH/Qw/wP2Z/vsaXl2j1JJ+RJC3/3q3Qj314t7k2gYrg0h888dWlNfBa8cXr9j/806WQYyGSAMNX1rwWT0MhnCNLR55z9Ogq/z4jjt8vkQNzbvOhOkFWIvBVKwAiYG6c5n0VyUvnQwTCBdA/gud+XNlWPig3hcIcYM8cfnHvNafi93phLrBvLv+w0O+j2tXnyU3l074B4J375Y/1RQtewHTKP7zHbPcsPnzt14u3MfpXPmQ69Sg/b/s/4Anyrm2BqUeA7Ec8iVxZWH2AKlDk8QD/wqbyAUdFpDa8t1IION3b8zpIwrBwdhKvf/XoMp+FJvSaCQFwTXrNshJ5gHozkufGlQ1GSisq5GU/LmzkM1xVZfJ0HJryoeW4k/z7pmE8wHfw4o89t5ZPlsgrnqUX8b+aTzjIjOdD7cLMVbGUt8O6MTDih5IgVc/qTQC0efNmjBs3Dt9//z3CwsLw448/YtWqVbhy5Qp8fHwwd+5cPHz4EOvXrwfAk5vbtGmDrl27YsGCBUhOTsaUKVPQq1cvrFrFu9QWLFiArl27wt/fH5mZmVi+fDk2bNiAY8eOoUsX7aqPUgBkhg5+zJNUA4ZrDqslXODDbaoioNe7fJHNsh5d5Z/uFaUS+uw8eN5E3CkArKRasXVjnrcBAIHP8U+3NSmSd+oH/smqSSfg5X+1e8zWKfwPZ7eZwIAFJdsPfwH8+wmfdTJ6PdByoPbtaGhUSuC7UCDlJh9miT3BA9RGfvxnnxFX/hNwzG5e3M+1LTCt4okb5ZQdAgEAiIBJfwNNu+r9ZdV5X7cHMmL5MEjpoqjZj4Evi4dN3ovnAU56HM9tUl/My5y33FTeS5SfwYP5hIt8WLdpGB/+qmm+mBBwJF7S3K5S8g9ESTGlfoalifiyPoU5PAgrzdGnuNdMi2RxfclN5XXFbh3kgZgQ1Att7fk2/9tW9u9QXjrP67Fx5gVEdaFS8ty3w5/xYNK3B/89Kr2eo57V5Ppt0vKkY8aMQUpKChYuXIiEhAS0a9cOe/bsgY+PDwAgISFBoyaQra0tIiMj8cYbbyAkJASNGzfG6NGj8cknn6j3SU9Px8svv6zOEwoKCsJ///2ndfBDzFSrQTwAunWQfwKykPEx9e1T+QUQ4LNQvEI0P7nkZwK/j+PBj28P/sfErT2f7gvwP577P+Dd/UKCMcA//UV8UvO8ibYj+cUz/jwfEnOueNhXTVnEPzEKr7G0Hm/x3APnljWvpdPQiCU8qXr7yyXrh7Ubxbvuj3/DZ85d3qYZAAn1f2pyMROJeNFI71CeF5R8gw9jmGPwAwAeHXgAlHBBMwASZiw28i3pFXP05sucnC/+gBL+uuZ5s3biOTEHPuK5UcKsvl7v6JYsb+de8RCTQFnEZ889ulzSy5N4iQc9whASRDyPyK0dr0IfPNH4Va2tnfiyQ12KE5fz0vgQ/ePrvE2enSp+nJUj/3tWG2IJX/fRvz/P3Wz3dOW96CZg0h6guop6gMyQSsWHM3KS+DTU5n148bWjS/isoxb9eIFAq0bAy4eBRj780/zv43hSsb0XrzAsBD6lMcYDq8h5/FNj3w948KHrDKZfR/M6IUHjeA9SVce5d5RPpbVuDLx9s0798alzlEV8Zk5SDK+/FDSOn9ukGGBFV96FP/tWyQVMSCwf9g3QaXzNn0+Rx3sPPTuZ7+r0hxcD//6PL7ky8seS7SdX8hlCrQYDY38r2Z52n8+KcvQBJkcC0jIFbhV5PBdIWJfNqwtflNWY5zf7MU8WF4bHTDmsaYbqTQ8QIXWGWAy0jOAF9m78zXMzji3l9w35mg8PJd/kPS+/j+drGZ1ZxYMfsZQPm1UU/AD8j69/f17sLy+t8v20FfoKD4CiNvBPl93frHxfoSaIfwQFP9WRWPChEkAz+de1Dc+fenyNJ6R2fI537T88z+/31DEJWGpl3KGQukjIxUsokwQtVM4uOxuwkQ8w8zL/+VRUAFVqxRdi/bO4NpWuvT+1YesC2PY27nMSnZh8LTBC6oyWxUNE1/bwonRMxT+ZBgzjf2xHr+c1OxKigU1jgcjixTafWKTdTBixuPbBD8B7oyL+x/9/YD6vAVMZIQCqbr00wlV2YW1bPN368jb+NSmGl1SQ2QEurYzXvoZGCICSb2gWxROGwFwrKIdgaV919ffAZ3nvXZeX+e8KIZWgAIgQQfM+fLZPRixPhrXzKFnPCeA5CE//BEDEZ1ExJQ+QhOU5jCn8dT6NFODLG1RU2Tn5Jk/WFEt57xPRnbAUyZ1/eVLpw+ICiJ5B1LNWG3buvOAfU5X0+qhUfFo1UHEAVB2xhBc5ffIL8x1aJFqhAIgQgcxGc6rssG/KF41r0Q/o8x7/v2sAHx4z1R/Z/gv4EhlMyQvyxZ3RvF/o/fHtzj81E925tOSJrKoiPuypToDuXPXjSPWEXqDE4mGw9Pu8d00i038hQkJKoQCIkNI6Pse/dp5SeZ2KnrOByQeAKQdMm+AoFvNPui0GAEV5vKjcn6/zmkSMlSx/UXb2F9GN0At0ZTtfABTQPf+HlPDowL8KeUDC8JdzK70XySOkNEqCJqS0diMB7y58gcjKiESAdx355C8pTsD+ZRRfDDFqA785+vBlAADK/9GXtiOAfz7m61EJBfJ0rYJMSqgToS/yr8IaYFUth0KIHlAPECFlOXjVr9wBmQ1fHmDiX3xpC5ktH0ZgSj5M18jH1C1sGBo35xdrpgTA+FIQtq6mblX9517cA5R0la8srk6ANvPaVMTgqAeIkIZALOa5Pr7defLntb94orYwpEf0o+3IkqEayv/Rj0a+fCHaggxeakAdALU1abNIw0c9QIQ0NDJroMMzwIiVmtV1Se21HV7yf8r/0Q+RqCQP6MEZPnsRoCEwYnAUABFCiLYa+fKVycVSqjGjT0Ie0KU/+BCj3KHqPDxC9ICGwAghpCbGbOALbto3MXVLGg4hALp/jH91bVO/8vBIvUQBECGE1ITMhtZ30jchEVpAw1/ECGgIjBBCiGk5+wMWViXf61IBmpAaogCIEEKIaYklgHu7ku/daAYYMTwKgAghhJiekAcEUA0gYhQUABFCCDE9IQ/Irkn5NfgIMQAKgAghhJhe68G8Fyj0ZVO3hJgJmgVGCCHE9GycgVf+M3UriBmhHiBCCCGEmB0KgAghhBBidigAIoQQQojZoQCIEEIIIWaHAiBCCCGEmB0KgAghhBBidigAIoQQQojZoQCIEEIIIWaHAiBCCCGEmB0KgAghhBBidigAIoQQQojZoQCIEEIIIWaHAiBCCCGEmB0KgAghhBBidixM3YC6iDEGAMjMzDRxSwghhBCiLeG6LVzHq0IBUAWysrIAAN7e3iZuCSGEEEJqKisrCw4ODlXuI2LahElmRqVSIT4+HnZ2dhCJRHo9dmZmJry9vREXFwd7e3u9HptoonNtPHSujYfOtfHQuTYefZ1rxhiysrLQpEkTiMVVZ/lQD1AFxGIxvLy8DPoc9vb29AtlJHSujYfOtfHQuTYeOtfGo49zXV3Pj4CSoAkhhBBidigAIoQQQojZoQDIyORyOT766CPI5XJTN6XBo3NtPHSujYfOtfHQuTYeU5xrSoImhBBCiNmhHiBCCCGEmB0KgAghhBBidigAIoQQQojZoQCIEEIIIWaHAiAjWrFiBfz8/GBpaYng4GAcOXLE1E2q9xYtWoTOnTvDzs4Orq6uGD58OK5fv66xD2MM8+fPR5MmTWBlZYXevXvjypUrJmpxw7Fo0SKIRCLMnDlTvY3Otf48fPgQL7zwAho3bgxra2t07NgR586dU99P51o/ioqK8MEHH8DPzw9WVlZo1qwZFi5cCJVKpd6HzrXu/vvvPwwdOhRNmjSBSCTCjh07NO7X5twWFBTgjTfegLOzM2xsbDBs2DA8ePCg9o1jxCg2bdrEpFIpW7VqFbt69SqbMWMGs7GxYffv3zd10+q1gQMHsrVr17LLly+z6OhoNnjwYNa0aVOWnZ2t3uezzz5jdnZ2bOvWrezSpUtszJgxzMPDg2VmZpqw5fXb6dOnma+vL+vQoQObMWOGejuda/1ITU1lPj4+bOLEiezUqVPs7t277MCBA+zWrVvqfehc68cnn3zCGjduzHbv3s3u3r3LtmzZwmxtbdnSpUvV+9C51t2ePXvY+++/z7Zu3coAsO3bt2vcr825nTp1KvP09GSRkZHs/PnzrE+fPiwwMJAVFRXVqm0UABlJly5d2NSpUzW2tW7dmr377rsmalHDlJSUxACww4cPM8YYU6lUzN3dnX322WfqffLz85mDgwP7/vvvTdXMei0rK4v5+/uzyMhI1qtXL3UAROdaf9555x3WvXv3Su+nc60/gwcPZpMmTdLYNnLkSPbCCy8wxuhc61PZAEibc5uens6kUinbtGmTep+HDx8ysVjM/v7771q1h4bAjKCwsBDnzp1DRESExvaIiAgcP37cRK1qmDIyMgAATk5OAIC7d+8iMTFR49zL5XL06tWLzr2OXnvtNQwePBj9+/fX2E7nWn927tyJkJAQPPPMM3B1dUVQUBBWrVqlvp/Otf50794dBw8exI0bNwAAFy5cwNGjR/Hkk08CoHNtSNqc23PnzkGhUGjs06RJE7Rr167W558WQzWC5ORkKJVKuLm5aWx3c3NDYmKiiVrV8DDGMGvWLHTv3h3t2rUDAPX5rejc379/3+htrO82bdqE8+fP48yZM+Xuo3OtP3fu3MHKlSsxa9YsvPfeezh9+jSmT58OuVyO8ePH07nWo3feeQcZGRlo3bo1JBIJlEol/ve//2Hs2LEA6H1tSNqc28TERMhkMjRq1KjcPrW9flIAZEQikUjje8ZYuW1Ed6+//jouXryIo0ePlruPzn3txcXFYcaMGdi/fz8sLS0r3Y/Ode2pVCqEhITg008/BQAEBQXhypUrWLlyJcaPH6/ej8517W3evBm//PILfvvtN7Rt2xbR0dGYOXMmmjRpggkTJqj3o3NtOLqcW32cfxoCMwJnZ2dIJJJy0WpSUlK5yJfo5o033sDOnTvx77//wsvLS73d3d0dAOjc68G5c+eQlJSE4OBgWFhYwMLCAocPH8by5cthYWGhPp90rmvPw8MDAQEBGtvatGmD2NhYAPS+1qfZs2fj3XffxbPPPov27dtj3LhxePPNN7Fo0SIAdK4NSZtz6+7ujsLCQqSlpVW6j64oADICmUyG4OBgREZGamyPjIxEeHi4iVrVMDDG8Prrr2Pbtm34559/4Ofnp3G/n58f3N3dNc59YWEhDh8+TOe+hvr164dLly4hOjpafQsJCcHzzz+P6OhoNGvWjM61nnTr1q1cOYcbN27Ax8cHAL2v9Sk3NxdisealUCKRqKfB07k2HG3ObXBwMKRSqcY+CQkJuHz5cu3Pf61SqInWhGnwq1evZlevXmUzZ85kNjY27N69e6ZuWr326quvMgcHB3bo0CGWkJCgvuXm5qr3+eyzz5iDgwPbtm0bu3TpEhs7dixNYdWT0rPAGKNzrS+nT59mFhYW7H//+x+7efMm+/XXX5m1tTX75Zdf1PvQudaPCRMmME9PT/U0+G3btjFnZ2c2Z84c9T50rnWXlZXFoqKiWFRUFAPAlixZwqKiotQlYLQ5t1OnTmVeXl7swIED7Pz586xv3740Db6++e6775iPjw+TyWSsU6dO6qnaRHcAKrytXbtWvY9KpWIfffQRc3d3Z3K5nPXs2ZNdunTJdI1uQMoGQHSu9WfXrl2sXbt2TC6Xs9atW7Mff/xR43461/qRmZnJZsyYwZo2bcosLS1Zs2bN2Pvvv88KCgrU+9C51t2///5b4d/oCRMmMMa0O7d5eXns9ddfZ05OTszKyooNGTKExcbG1rptIsYYq10fEiGEEEJI/UI5QIQQQggxOxQAEUIIIcTsUABECCGEELNDARAhhBBCzA4FQIQQQggxOxQAEUIIIcTsUABECCGEELNDARAhhGjh0KFDEIlESE9PN3VTCCF6QAEQIYQQQswOBUCEEEIIMTsUABFC6gXGGBYvXoxmzZrBysoKgYGB+OOPPwCUDE/99ddfCAwMhKWlJUJDQ3Hp0iWNY2zduhVt27aFXC6Hr68vvvrqK437CwoKMGfOHHh7e0Mul8Pf3x+rV6/W2OfcuXMICQmBtbU1wsPDy63aTgipHygAIoTUCx988AHWrl2LlStX4sqVK3jzzTfxwgsv4PDhw+p9Zs+ejS+//BJnzpyBq6srhg0bBoVCAYAHLqNHj8azzz6LS5cuYf78+Zg3bx7WrVunfvz48eOxadMmLF++HDExMfj+++9ha2ur0Y73338fX331Fc6ePQsLCwtMmjTJKK+fEKJftBgqIaTOy8nJgbOzM/755x+EhYWpt0+ZMgW5ubl4+eWX0adPH2zatAljxowBAKSmpsLLywvr1q3D6NGj8fzzz+Px48fYv3+/+vFz5szBX3/9hStXruDGjRto1aoVIiMj0b9//3JtOHToEPr06YMDBw6gX79+AIA9e/Zg8ODByPt/+/bv0kgQxmH8kZxGIUJQUYL4oxAVQQMBqwhW9lZaKpY2IlqtYJEttBbR3tJS8D+QaGllwKCgZUACNtq4XHEkmDu4O7jzYm6fDywM7DD7zlZf3p19eaGzs/OD34Kkv8kOkKRP7+bmhtfXVxYWFkilUvXr5OSEu7u7+rz34ainp4eJiQlKpRIApVKJfD7fsG4+n6dcLvP29sb19TWJRIL5+fmf1jIzM1MfZzIZACqVyh/vUdK/9aXZBUjSr0RRBMD5+TmDg4MN95LJZEMI+l5bWxvw7QxRbVzzvgHe1dX1W7W0t7f/sHatPkmtww6QpE9vamqKZDLJ4+MjY2NjDdfQ0FB93tXVVX1crVa5vb1lcnKyvsbFxUXDusVikfHxcRKJBNPT00RR1HCmSNL/yw6QpE+vu7ub7e1tNjc3iaKIubk5np+fKRaLpFIpRkZGACgUCvT29jIwMMDOzg59fX0sLi4CsLW1xezsLGEYsry8zOXlJYeHhxwdHQEwOjrKysoKa2trHBwckM1meXh4oFKpsLS01KytS/ogBiBJLSEMQ/r7+9nb2+P+/p50Ok0ulyMIgvonqP39fTY2NiiXy2SzWc7Ozujo6AAgl8txenrK7u4uYRiSyWQoFAqsrq7Wn3F8fEwQBKyvr/P09MTw8DBBEDRju5I+mH+BSWp5tT+0qtUq6XS62eVIagGeAZIkSbFjAJIkSbHjJzBJkhQ7doAkSVLsGIAkSVLsGIAkSVLsGIAkSVLsGIAkSVLsGIAkSVLsGIAkSVLsGIAkSVLsGIAkSVLsfAUCOTMSfUOjuQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(train_acc, label=\"train acc\")\n",
    "plt.plot(validation_acc, label=\"validation acc\")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracies\")\n",
    "plt.title(\"train vs validation accs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "We will perform grid search on the no. of training epochs, lr, optimizer and batch sizes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2. RNN\n",
    "(a) Report the final configuration of your best model, namely the number of training epochs,\n",
    "learning rate, optimizer, batch size.\n",
    "  - Implement Bayesian search\n",
    "(b) Report the accuracy score on the test set, as well as the accuracy score on the validation\n",
    "set for each epoch during training.\n",
    "(c) RNNs produce a hidden vector for each word, instead of the entire sentence. Which methods\n",
    "have you tried in deriving the final sentence representation to perform sentiment classification?\n",
    "Describe all the strategies you have implemented, together with their accuracy scores on the\n",
    "test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding with \"the\" token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use \"the\" as pad \n",
    "word2idx[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Others:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = [word_embeddings[word] for word in word_embeddings.keys()]\n",
    "\n",
    "embedding_matrix_np = np.array(embeddings)\n",
    "embedding_matrix_np = np.vstack((np.zeros((1, 100)), embedding_matrix_np))\n",
    "\n",
    "embedding_matrix_np.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from huggingface first \n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "with open('result/word2idx.json', \"r\") as file:\n",
    "    word2idx = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop2(train_dataloader, model, loss_fn, optimizer):\n",
    "    if train_on_gpu:\n",
    "        model.cuda()\n",
    "    model.train()\n",
    "    num_batches = len(train_dataloader)\n",
    "    size = len(train_dataloader.dataset)\n",
    "    train_loss, train_correct = 0, 0\n",
    "    for batch_no, (X_batch, y_batch) in enumerate(train_dataloader):\n",
    "        y_batch = y_batch.long()\n",
    "        if train_on_gpu:\n",
    "            X_batch = X_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(X_batch)\n",
    "\n",
    "        #print(pred, y_batch)\n",
    "        loss = loss_fn(pred.squeeze(), y_batch.float())\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        probabilities = torch.sigmoid(pred.squeeze())\n",
    "        pred_binary = (probabilities >= 0.5).long()\n",
    "        train_correct += (pred_binary == y_batch.long()).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss /= num_batches \n",
    "    train_correct /= size \n",
    "\n",
    "    return train_loss, train_correct \n",
    "   \n",
    "\n",
    "def test_loop2(validate_dataloader, model, loss_fn):\n",
    "    if train_on_gpu:\n",
    "        model.cuda()\n",
    "    model.eval()\n",
    "    num_batches = len(validate_dataloader)\n",
    "    size = len(validate_dataloader.dataset)\n",
    "    test_loss, test_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in validate_dataloader:\n",
    "            y_batch = y_batch.long()\n",
    "            if train_on_gpu:\n",
    "                X_batch = X_batch.cuda()\n",
    "                y_batch = y_batch.cuda()\n",
    "\n",
    "            pred = model(X_batch)\n",
    "            \n",
    "            test_loss += loss_fn(pred.squeeze(), y_batch.float()).item()\n",
    "            \n",
    "            probabilities = torch.sigmoid(pred.squeeze())\n",
    "            pred_binary = (probabilities >= 0.5).long()\n",
    "            test_correct += (pred_binary == y_batch.long()).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_correct /= size\n",
    "    return test_loss, test_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_dataloader, model, loss_fn, optimizer):\n",
    "    if train_on_gpu:\n",
    "        model.cuda()\n",
    "    model.train()\n",
    "    num_batches = len(train_dataloader)\n",
    "    size = len(train_dataloader.dataset)\n",
    "    train_loss, train_correct = 0, 0\n",
    "    for batch_no, (X_batch, y_batch) in enumerate(train_dataloader):\n",
    "        y_batch = y_batch.long()\n",
    "        if train_on_gpu:\n",
    "            X_batch = X_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(X_batch)\n",
    "        #print(pred, y_batch)\n",
    "        pred = pred.squeeze(1)\n",
    "        y_val = y_batch\n",
    "        loss = loss_fn(pred, y_val.float())\n",
    "        train_loss += loss.item() \n",
    "        train_correct += ((pred >= 0.5).long()==y_batch).sum().item() \n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss /= num_batches \n",
    "    train_correct /= size \n",
    "\n",
    "    return train_loss, train_correct \n",
    "   \n",
    "\n",
    "def test_loop(validate_dataloader, model, loss_fn):\n",
    "    if train_on_gpu:\n",
    "        model.cuda()\n",
    "    model.eval()\n",
    "    num_batches = len(validate_dataloader)\n",
    "    size = len(validate_dataloader.dataset)\n",
    "    test_loss, test_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in validate_dataloader:\n",
    "            y_batch = y_batch.long()\n",
    "            if train_on_gpu:\n",
    "                X_batch = X_batch.cuda()\n",
    "                y_batch = y_batch.cuda()\n",
    "\n",
    "            pred = model(X_batch)\n",
    "            pred = pred.squeeze(1)\n",
    "            pred_binary = (pred >= 0.5).long()\n",
    "            test_loss += loss_fn(pred, y_batch.float()).item()\n",
    "            test_correct += (pred_binary == y_batch).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_correct /= size\n",
    "    return test_loss, test_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "# TODO: change the num_tokens \n",
    "class EmbeddingsDataset2(Dataset):\n",
    "  def __init__(self, X, y, num_tokens_per_sentence=8, word_embeddings=word_embeddings):\n",
    "    self.num_tokens_per_sentence = num_tokens_per_sentence\n",
    "    self.word_embeddings = word_embeddings\n",
    "    self.X = X # train_dataset['text']\n",
    "    self.y = y # train_dataset['label']\n",
    "    self.len = len(self.X)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # tokenize the sentence \n",
    "    tokens = self.tokenize_sentence(self.X[index])\n",
    "    # convert each token to embeddings \n",
    "    sentence_tensor = self.convert_sentence_into_indices(tokens)\n",
    "    label = torch.tensor(self.y[index], dtype=torch.long)\n",
    "    return sentence_tensor, label \n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len \n",
    "\n",
    "  def tokenize_sentence(self, x): \n",
    "    '''\n",
    "    returns a list containing the embeddings of each token \n",
    "    '''\n",
    "    tokens = nltk.word_tokenize(x.lower())\n",
    "    return tokens \n",
    "  \n",
    "  def convert_sentence_into_indices(self, tokens):\n",
    "    indices = []\n",
    "    num_tokens_used = 0 \n",
    "    for token in tokens:\n",
    "      if num_tokens_used == self.num_tokens_per_sentence:\n",
    "        break # we have enough of tokens from the sentence \n",
    "      if token in word2idx:\n",
    "        indices.append(word2idx[token])\n",
    "        num_tokens_used += 1 \n",
    "    # # if not enough tokens in the sentence, use index of ?? \n",
    "    if len(indices) < self.num_tokens_per_sentence:\n",
    "      padding = [0 for _ in range(self.num_tokens_per_sentence - len(indices))]\n",
    "      indices.extend(padding)\n",
    "    #print(indices)\n",
    "    indices = torch.tensor(indices, dtype=torch.long)\n",
    "    return indices\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla RNN with \\<pad\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nn.Embeddings \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class VanillaRNNWithEmbedding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, embedding_matrix_torch=torch.tensor(embedding_matrix_np, dtype=torch.float)):\n",
    "        super(VanillaRNNWithEmbedding, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix_torch, freeze=True)\n",
    "        self.num_layers = num_layers \n",
    "        self.hidden_size = hidden_size \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, dropout=0.3) # this is the num rows of the input matrix \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    " \n",
    "    def forward(self, x):\n",
    "        # Pass input through embedding layer\n",
    "        x = self.embedding(x)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=torch.float).to(x.device)\n",
    "        # Pass the embeddings through the RNN layer\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Max pooling\n",
    "        out, _ = torch.max(out, dim=1)\n",
    "        # Only take the last output for each sequence\n",
    "        #out = out[:, -1, :]\n",
    "        # Pass through the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        # Apply sigmoid activation (for binary classification)\n",
    "        #out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nn.Embeddings \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class VanillaRNNWithEmbedding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, embedding_matrix_torch=torch.tensor(embedding_matrix_np, dtype=torch.float)):\n",
    "        super(VanillaRNNWithEmbedding, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix_torch, freeze=True, padding_idx=0)\n",
    "        self.num_layers = num_layers \n",
    "        self.hidden_size = hidden_size \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True) # this is the num rows of the input matrix \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    " \n",
    "    def forward(self, x):\n",
    "        # Pass input through embedding layer\n",
    "        x = self.embedding(x)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=torch.float).to(x.device)\n",
    "        # Pass the embeddings through the RNN layer\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # Max pooling\n",
    "        #print(\"before max pooling\", hidden.size())\n",
    "        \n",
    "        res, _ = torch.max(out, dim=1)\n",
    "        #print(res, hidden, hidden.size(), res.size())\n",
    "         \n",
    "        #print(\"after max pooling\", res.size())\n",
    "        # Only take the last output for each sequence\n",
    "        #out = out[:, -1, :]\n",
    "        # Pass through the fully connected layer\n",
    "        res = self.fc(res)\n",
    "        # Apply sigmoid activation (for binary classification)\n",
    "        res = self.sigmoid(res)\n",
    "\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6990, Validate Loss: 0.6954\n",
      "Epoch:1 \tValidation Acc:0.4915572232645403 \tTrain Acc:0.505158264947245\n",
      "Epoch 2, Train Loss: 0.6920, Validate Loss: 0.6935\n",
      "Epoch:2 \tValidation Acc:0.5168855534709194 \tTrain Acc:0.5259085580304806\n",
      "Epoch 3, Train Loss: 0.6887, Validate Loss: 0.6969\n",
      "Epoch:3 \tValidation Acc:0.49343339587242024 \tTrain Acc:0.5229777256740914\n",
      "Epoch 4, Train Loss: 0.6814, Validate Loss: 0.7067\n",
      "Epoch:4 \tValidation Acc:0.5056285178236398 \tTrain Acc:0.5479484173505276\n",
      "Epoch 5, Train Loss: 0.6794, Validate Loss: 0.6961\n",
      "Epoch:5 \tValidation Acc:0.5131332082551595 \tTrain Acc:0.5527549824150059\n",
      "Epoch 6, Train Loss: 0.6724, Validate Loss: 0.7006\n",
      "Epoch:6 \tValidation Acc:0.5178236397748592 \tTrain Acc:0.5640093786635404\n",
      "Epoch 7, Train Loss: 0.6643, Validate Loss: 0.7176\n",
      "Epoch:7 \tValidation Acc:0.5093808630393997 \tTrain Acc:0.5723329425556858\n",
      "Epoch 8, Train Loss: 0.6511, Validate Loss: 0.7288\n",
      "Epoch:8 \tValidation Acc:0.5121951219512195 \tTrain Acc:0.585345838218054\n",
      "Epoch 9, Train Loss: 0.6356, Validate Loss: 0.7336\n",
      "Epoch:9 \tValidation Acc:0.5056285178236398 \tTrain Acc:0.6036342321219226\n",
      "Epoch 10, Train Loss: 0.6191, Validate Loss: 0.7276\n",
      "Epoch:10 \tValidation Acc:0.5347091932457786 \tTrain Acc:0.6174677608440797\n",
      "Epoch 11, Train Loss: 0.5973, Validate Loss: 0.7448\n",
      "Epoch:11 \tValidation Acc:0.5075046904315197 \tTrain Acc:0.6310668229777256\n",
      "Epoch 12, Train Loss: 0.5736, Validate Loss: 0.7718\n",
      "Epoch:12 \tValidation Acc:0.5234521575984991 \tTrain Acc:0.6451348182883939\n",
      "Epoch 13, Train Loss: 0.5509, Validate Loss: 0.8053\n",
      "Epoch:13 \tValidation Acc:0.5215759849906192 \tTrain Acc:0.6739742086752638\n",
      "Epoch 14, Train Loss: 0.5166, Validate Loss: 0.8445\n",
      "Epoch:14 \tValidation Acc:0.5178236397748592 \tTrain Acc:0.6879249706916765\n",
      "Epoch 15, Train Loss: 0.4829, Validate Loss: 0.8830\n",
      "Epoch:15 \tValidation Acc:0.5234521575984991 \tTrain Acc:0.7090269636576788\n",
      "Epoch 16, Train Loss: 0.4629, Validate Loss: 0.9302\n",
      "Epoch:16 \tValidation Acc:0.5300187617260788 \tTrain Acc:0.7276670574443141\n",
      "Epoch 17, Train Loss: 0.4379, Validate Loss: 0.9812\n",
      "Epoch:17 \tValidation Acc:0.5215759849906192 \tTrain Acc:0.741031652989449\n",
      "Epoch 18, Train Loss: 0.4116, Validate Loss: 1.0686\n",
      "Epoch:18 \tValidation Acc:0.5375234521575984 \tTrain Acc:0.7608440797186401\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m train_losses, validate_losses \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m---> 19\u001b[0m   train_loss, train_correct \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRNN_embeddings_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     20\u001b[0m   validate_loss, validate_correct \u001b[38;5;241m=\u001b[39m test_loop2(validation_dataloader2, RNN_embeddings_model, criterion)\n\u001b[0;32m     21\u001b[0m   validation_acc\u001b[38;5;241m.\u001b[39mappend(validate_correct)\n",
      "Cell \u001b[1;32mIn[141], line 28\u001b[0m, in \u001b[0;36mtrain_loop2\u001b[1;34m(train_dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     27\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 28\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches \n\u001b[0;32m     31\u001b[0m train_correct \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m size \n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    214\u001b[0m         group,\n\u001b[0;32m    215\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m         state_steps,\n\u001b[0;32m    221\u001b[0m     )\n\u001b[1;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:542\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    540\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_lerp_(device_exp_avgs, device_grads, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 542\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcmul_(\n\u001b[0;32m    544\u001b[0m     device_exp_avg_sqs, device_grads, device_grads, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2\n\u001b[0;32m    545\u001b[0m )\n\u001b[0;32m    547\u001b[0m \u001b[38;5;66;03m# Delete the local intermediate since it won't be used anymore to save on peak memory\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RNN_embeddings_model = VanillaRNNWithEmbedding(input_size=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=2, num_classes=1)\n",
    "optim = torch.optim.Adam(RNN_embeddings_model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "train_dataset_ed2 = EmbeddingsDataset2(train_dataset['text'], train_dataset['label'], num_tokens_per_sentence=25)\n",
    "validation_dataset_ed2 = EmbeddingsDataset2(validation_dataset['text'], validation_dataset['label'], num_tokens_per_sentence=25)\n",
    "# test_dataset_ed2 = EmbeddingsDataset(test_dataset['text'], test_dataset['label'])\n",
    "\n",
    "\n",
    "train_dataloader2 = DataLoader(train_dataset_ed2, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader2 = DataLoader(validation_dataset_ed2, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "validation_acc = [] \n",
    "train_acc = []\n",
    "train_losses, validate_losses = [], []\n",
    "for i in range(NUM_EPOCHS):\n",
    "  train_loss, train_correct = train_loop2(train_dataloader2, RNN_embeddings_model, criterion, optim) \n",
    "  validate_loss, validate_correct = test_loop2(validation_dataloader2, RNN_embeddings_model, criterion)\n",
    "  validation_acc.append(validate_correct)\n",
    "  train_acc.append(train_correct)\n",
    "  train_losses.append(train_loss)\n",
    "  validate_losses.append(validate_loss)\n",
    "\n",
    "  print(f\"Epoch {i+1}, Train Loss: {train_loss:.4f}, Validate Loss: {validate_loss:.4f}\")\n",
    "  #if i%10 == 0:\n",
    "  print(f\"Epoch:{i+1} \\tValidation Acc:{validate_correct} \\tTrain Acc:{train_correct}\")\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6951, Validate Loss: 0.6895\n",
      "Epoch:1 \tValidation Acc:0.5619136960600375 \tTrain Acc:0.5073856975381008\n",
      "Epoch 2, Train Loss: 0.6906, Validate Loss: 0.6854\n",
      "Epoch:2 \tValidation Acc:0.5412757973733584 \tTrain Acc:0.5262602579132474\n",
      "Epoch 3, Train Loss: 0.6844, Validate Loss: 0.6773\n",
      "Epoch:3 \tValidation Acc:0.5881801125703565 \tTrain Acc:0.5610785463071513\n",
      "Epoch 4, Train Loss: 0.6770, Validate Loss: 0.6703\n",
      "Epoch:4 \tValidation Acc:0.5956848030018762 \tTrain Acc:0.5722157092614303\n",
      "Epoch 5, Train Loss: 0.6722, Validate Loss: 0.6682\n",
      "Epoch:5 \tValidation Acc:0.6031894934333959 \tTrain Acc:0.5835873388042204\n",
      "Epoch 6, Train Loss: 0.6673, Validate Loss: 0.6689\n",
      "Epoch:6 \tValidation Acc:0.5975609756097561 \tTrain Acc:0.5951934349355217\n",
      "Epoch 7, Train Loss: 0.6653, Validate Loss: 0.6681\n",
      "Epoch:7 \tValidation Acc:0.5928705440900562 \tTrain Acc:0.5984759671746777\n",
      "Epoch 8, Train Loss: 0.6623, Validate Loss: 0.6761\n",
      "Epoch:8 \tValidation Acc:0.5675422138836773 \tTrain Acc:0.6026963657678781\n",
      "Epoch 9, Train Loss: 0.6605, Validate Loss: 0.6606\n",
      "Epoch:9 \tValidation Acc:0.6116322701688556 \tTrain Acc:0.6073856975381008\n",
      "Epoch 10, Train Loss: 0.6577, Validate Loss: 0.6623\n",
      "Epoch:10 \tValidation Acc:0.6060037523452158 \tTrain Acc:0.6076201641266119\n",
      "Epoch 11, Train Loss: 0.6548, Validate Loss: 0.6678\n",
      "Epoch:11 \tValidation Acc:0.6050656660412758 \tTrain Acc:0.6153575615474794\n",
      "Epoch 12, Train Loss: 0.6537, Validate Loss: 0.6653\n",
      "Epoch:12 \tValidation Acc:0.6031894934333959 \tTrain Acc:0.6187573270808909\n",
      "Epoch 13, Train Loss: 0.6509, Validate Loss: 0.6609\n",
      "Epoch:13 \tValidation Acc:0.6116322701688556 \tTrain Acc:0.6228604923798359\n",
      "Epoch 14, Train Loss: 0.6463, Validate Loss: 0.6634\n",
      "Epoch:14 \tValidation Acc:0.6013133208255159 \tTrain Acc:0.6266119577960141\n",
      "Epoch 15, Train Loss: 0.6433, Validate Loss: 0.6617\n",
      "Epoch:15 \tValidation Acc:0.6078799249530957 \tTrain Acc:0.6328253223915592\n",
      "Epoch 16, Train Loss: 0.6419, Validate Loss: 0.6584\n",
      "Epoch:16 \tValidation Acc:0.6088180112570356 \tTrain Acc:0.6329425556858148\n",
      "Epoch 17, Train Loss: 0.6378, Validate Loss: 0.6561\n",
      "Epoch:17 \tValidation Acc:0.6106941838649156 \tTrain Acc:0.6406799531066822\n",
      "Epoch 18, Train Loss: 0.6333, Validate Loss: 0.6617\n",
      "Epoch:18 \tValidation Acc:0.5881801125703565 \tTrain Acc:0.6411488862837046\n",
      "Epoch 19, Train Loss: 0.6294, Validate Loss: 0.6626\n",
      "Epoch:19 \tValidation Acc:0.6050656660412758 \tTrain Acc:0.6438452520515826\n",
      "Epoch 20, Train Loss: 0.6274, Validate Loss: 0.6610\n",
      "Epoch:20 \tValidation Acc:0.6106941838649156 \tTrain Acc:0.6495896834701055\n",
      "Epoch 21, Train Loss: 0.6231, Validate Loss: 0.6608\n",
      "Epoch:21 \tValidation Acc:0.6050656660412758 \tTrain Acc:0.6506447831184057\n",
      "Epoch 22, Train Loss: 0.6189, Validate Loss: 0.6582\n",
      "Epoch:22 \tValidation Acc:0.6022514071294559 \tTrain Acc:0.6599062133645955\n",
      "Epoch 23, Train Loss: 0.6148, Validate Loss: 0.6657\n",
      "Epoch:23 \tValidation Acc:0.5938086303939962 \tTrain Acc:0.6609613130128956\n",
      "Epoch 24, Train Loss: 0.6091, Validate Loss: 0.6650\n",
      "Epoch:24 \tValidation Acc:0.6013133208255159 \tTrain Acc:0.6671746776084408\n",
      "Epoch 25, Train Loss: 0.6077, Validate Loss: 0.6572\n",
      "Epoch:25 \tValidation Acc:0.6088180112570356 \tTrain Acc:0.6681125439624853\n",
      "Epoch 26, Train Loss: 0.6015, Validate Loss: 0.6622\n",
      "Epoch:26 \tValidation Acc:0.6144465290806754 \tTrain Acc:0.6726846424384525\n",
      "Epoch 27, Train Loss: 0.5947, Validate Loss: 0.6589\n",
      "Epoch:27 \tValidation Acc:0.6125703564727955 \tTrain Acc:0.6833528722157093\n",
      "Epoch 28, Train Loss: 0.5903, Validate Loss: 0.6699\n",
      "Epoch:28 \tValidation Acc:0.6135084427767354 \tTrain Acc:0.6849941383352872\n",
      "Epoch 29, Train Loss: 0.5877, Validate Loss: 0.6695\n",
      "Epoch:29 \tValidation Acc:0.6135084427767354 \tTrain Acc:0.6887456037514654\n",
      "Epoch 30, Train Loss: 0.5849, Validate Loss: 0.6637\n",
      "Epoch:30 \tValidation Acc:0.6116322701688556 \tTrain Acc:0.6879249706916765\n",
      "Epoch 31, Train Loss: 0.5801, Validate Loss: 0.6778\n",
      "Epoch:31 \tValidation Acc:0.6116322701688556 \tTrain Acc:0.6978898007033998\n",
      "Epoch 32, Train Loss: 0.5766, Validate Loss: 0.6678\n",
      "Epoch:32 \tValidation Acc:0.6088180112570356 \tTrain Acc:0.6967174677608441\n",
      "Epoch 33, Train Loss: 0.5710, Validate Loss: 0.6815\n",
      "Epoch:33 \tValidation Acc:0.599437148217636 \tTrain Acc:0.7082063305978898\n",
      "Epoch 34, Train Loss: 0.5671, Validate Loss: 0.6740\n",
      "Epoch:34 \tValidation Acc:0.6210131332082551 \tTrain Acc:0.7023446658851114\n",
      "Epoch 35, Train Loss: 0.5631, Validate Loss: 0.6863\n",
      "Epoch:35 \tValidation Acc:0.6088180112570356 \tTrain Acc:0.7087924970691677\n",
      "Epoch 36, Train Loss: 0.5611, Validate Loss: 0.6755\n",
      "Epoch:36 \tValidation Acc:0.6125703564727955 \tTrain Acc:0.7134818288393904\n",
      "Epoch 37, Train Loss: 0.5556, Validate Loss: 0.6852\n",
      "Epoch:37 \tValidation Acc:0.6135084427767354 \tTrain Acc:0.7174677608440797\n",
      "Epoch 38, Train Loss: 0.5503, Validate Loss: 0.6930\n",
      "Epoch:38 \tValidation Acc:0.6144465290806754 \tTrain Acc:0.7172332942555686\n",
      "Epoch 39, Train Loss: 0.5482, Validate Loss: 0.6908\n",
      "Epoch:39 \tValidation Acc:0.6078799249530957 \tTrain Acc:0.7184056271981243\n",
      "Epoch 40, Train Loss: 0.5417, Validate Loss: 0.6958\n",
      "Epoch:40 \tValidation Acc:0.6106941838649156 \tTrain Acc:0.7304806565064478\n",
      "Epoch 41, Train Loss: 0.5386, Validate Loss: 0.6882\n",
      "Epoch:41 \tValidation Acc:0.6097560975609756 \tTrain Acc:0.7283704572098476\n",
      "Epoch 42, Train Loss: 0.5333, Validate Loss: 0.7040\n",
      "Epoch:42 \tValidation Acc:0.6088180112570356 \tTrain Acc:0.7343493552168816\n",
      "Epoch 43, Train Loss: 0.5315, Validate Loss: 0.7025\n",
      "Epoch:43 \tValidation Acc:0.6144465290806754 \tTrain Acc:0.7365767878077374\n",
      "Epoch 44, Train Loss: 0.5242, Validate Loss: 0.6984\n",
      "Epoch:44 \tValidation Acc:0.6097560975609756 \tTrain Acc:0.7400937866354045\n",
      "Epoch 45, Train Loss: 0.5212, Validate Loss: 0.7070\n",
      "Epoch:45 \tValidation Acc:0.6144465290806754 \tTrain Acc:0.7429073856975381\n",
      "Epoch 46, Train Loss: 0.5189, Validate Loss: 0.7336\n",
      "Epoch:46 \tValidation Acc:0.5881801125703565 \tTrain Acc:0.7439624853458382\n",
      "Epoch 47, Train Loss: 0.5157, Validate Loss: 0.7136\n",
      "Epoch:47 \tValidation Acc:0.6125703564727955 \tTrain Acc:0.7444314185228605\n",
      "Epoch 48, Train Loss: 0.5065, Validate Loss: 0.7163\n",
      "Epoch:48 \tValidation Acc:0.6041275797373359 \tTrain Acc:0.7532239155920282\n",
      "Epoch 49, Train Loss: 0.5060, Validate Loss: 0.7265\n",
      "Epoch:49 \tValidation Acc:0.6022514071294559 \tTrain Acc:0.7497069167643611\n",
      "Epoch 50, Train Loss: 0.5057, Validate Loss: 0.7219\n",
      "Epoch:50 \tValidation Acc:0.5956848030018762 \tTrain Acc:0.7552168815943728\n",
      "Epoch 51, Train Loss: 0.4988, Validate Loss: 0.7300\n",
      "Epoch:51 \tValidation Acc:0.5909943714821764 \tTrain Acc:0.7539273153575615\n",
      "Epoch 52, Train Loss: 0.4923, Validate Loss: 0.7284\n",
      "Epoch:52 \tValidation Acc:0.6210131332082551 \tTrain Acc:0.7626025791324736\n",
      "Epoch 53, Train Loss: 0.4931, Validate Loss: 0.7313\n",
      "Epoch:53 \tValidation Acc:0.6125703564727955 \tTrain Acc:0.7608440797186401\n",
      "Epoch 54, Train Loss: 0.4868, Validate Loss: 0.7236\n",
      "Epoch:54 \tValidation Acc:0.6181988742964353 \tTrain Acc:0.7627198124267291\n",
      "Epoch 55, Train Loss: 0.4820, Validate Loss: 0.7454\n",
      "Epoch:55 \tValidation Acc:0.599437148217636 \tTrain Acc:0.763305978898007\n",
      "Epoch 56, Train Loss: 0.4796, Validate Loss: 0.7451\n",
      "Epoch:56 \tValidation Acc:0.6060037523452158 \tTrain Acc:0.7661195779601406\n",
      "Epoch 57, Train Loss: 0.4737, Validate Loss: 0.7529\n",
      "Epoch:57 \tValidation Acc:0.6041275797373359 \tTrain Acc:0.7699882766705745\n",
      "Epoch 58, Train Loss: 0.4674, Validate Loss: 0.7800\n",
      "Epoch:58 \tValidation Acc:0.6031894934333959 \tTrain Acc:0.782883939038687\n",
      "Epoch 59, Train Loss: 0.4652, Validate Loss: 0.7681\n",
      "Epoch:59 \tValidation Acc:0.6097560975609756 \tTrain Acc:0.7813599062133646\n",
      "Epoch 60, Train Loss: 0.4586, Validate Loss: 0.7579\n",
      "Epoch:60 \tValidation Acc:0.6125703564727955 \tTrain Acc:0.7865181711606096\n",
      "Epoch 61, Train Loss: 0.4549, Validate Loss: 0.7769\n",
      "Epoch:61 \tValidation Acc:0.5891181988742964 \tTrain Acc:0.7861664712778429\n",
      "Epoch 62, Train Loss: 0.4561, Validate Loss: 0.7742\n",
      "Epoch:62 \tValidation Acc:0.6069418386491557 \tTrain Acc:0.7874560375146542\n",
      "Epoch 63, Train Loss: 0.4550, Validate Loss: 0.7854\n",
      "Epoch:63 \tValidation Acc:0.5984990619136961 \tTrain Acc:0.7852286049237983\n",
      "Epoch 64, Train Loss: 0.4437, Validate Loss: 0.7720\n",
      "Epoch:64 \tValidation Acc:0.6013133208255159 \tTrain Acc:0.7927315357561547\n",
      "Epoch 65, Train Loss: 0.4443, Validate Loss: 0.7832\n",
      "Epoch:65 \tValidation Acc:0.6041275797373359 \tTrain Acc:0.7900351699882767\n",
      "Epoch 66, Train Loss: 0.4373, Validate Loss: 0.7954\n",
      "Epoch:66 \tValidation Acc:0.5881801125703565 \tTrain Acc:0.7974208675263775\n",
      "Epoch 67, Train Loss: 0.4329, Validate Loss: 0.8136\n",
      "Epoch:67 \tValidation Acc:0.5975609756097561 \tTrain Acc:0.8028135990621337\n",
      "Epoch 68, Train Loss: 0.4303, Validate Loss: 0.8067\n",
      "Epoch:68 \tValidation Acc:0.6022514071294559 \tTrain Acc:0.8038686987104338\n",
      "Epoch 69, Train Loss: 0.4233, Validate Loss: 0.8333\n",
      "Epoch:69 \tValidation Acc:0.6097560975609756 \tTrain Acc:0.7980070339976554\n",
      "Epoch 70, Train Loss: 0.4167, Validate Loss: 0.8366\n",
      "Epoch:70 \tValidation Acc:0.5966228893058161 \tTrain Acc:0.8106682297772567\n",
      "Epoch 71, Train Loss: 0.4159, Validate Loss: 0.8341\n",
      "Epoch:71 \tValidation Acc:0.6041275797373359 \tTrain Acc:0.8138335287221571\n",
      "Epoch 72, Train Loss: 0.4075, Validate Loss: 0.8316\n",
      "Epoch:72 \tValidation Acc:0.5816135084427767 \tTrain Acc:0.8141852286049238\n",
      "Epoch 73, Train Loss: 0.4060, Validate Loss: 0.8358\n",
      "Epoch:73 \tValidation Acc:0.6050656660412758 \tTrain Acc:0.8200468933177022\n",
      "Epoch 74, Train Loss: 0.4029, Validate Loss: 0.8669\n",
      "Epoch:74 \tValidation Acc:0.5834896810506567 \tTrain Acc:0.8212192262602579\n",
      "Epoch 75, Train Loss: 0.4025, Validate Loss: 0.8522\n",
      "Epoch:75 \tValidation Acc:0.5900562851782364 \tTrain Acc:0.82063305978898\n",
      "Epoch 76, Train Loss: 0.3926, Validate Loss: 0.8954\n",
      "Epoch:76 \tValidation Acc:0.5797373358348968 \tTrain Acc:0.8213364595545135\n",
      "Epoch 77, Train Loss: 0.3924, Validate Loss: 0.8926\n",
      "Epoch:77 \tValidation Acc:0.5909943714821764 \tTrain Acc:0.81957796014068\n",
      "Epoch 78, Train Loss: 0.3859, Validate Loss: 0.8873\n",
      "Epoch:78 \tValidation Acc:0.599437148217636 \tTrain Acc:0.8233294255568582\n",
      "Epoch 79, Train Loss: 0.3832, Validate Loss: 0.9299\n",
      "Epoch:79 \tValidation Acc:0.5919324577861164 \tTrain Acc:0.826611957796014\n",
      "Epoch 80, Train Loss: 0.3830, Validate Loss: 0.9029\n",
      "Epoch:80 \tValidation Acc:0.5947467166979362 \tTrain Acc:0.8273153575615475\n",
      "Epoch 81, Train Loss: 0.3781, Validate Loss: 0.9181\n",
      "Epoch:81 \tValidation Acc:0.5984990619136961 \tTrain Acc:0.8310668229777257\n",
      "Epoch 82, Train Loss: 0.3699, Validate Loss: 0.9081\n",
      "Epoch:82 \tValidation Acc:0.5909943714821764 \tTrain Acc:0.8348182883939038\n",
      "Epoch 83, Train Loss: 0.3709, Validate Loss: 0.9065\n",
      "Epoch:83 \tValidation Acc:0.5863039399624765 \tTrain Acc:0.8330597889800704\n",
      "Epoch 84, Train Loss: 0.3622, Validate Loss: 0.9624\n",
      "Epoch:84 \tValidation Acc:0.5872420262664165 \tTrain Acc:0.8364595545134819\n",
      "Epoch 85, Train Loss: 0.3581, Validate Loss: 0.9230\n",
      "Epoch:85 \tValidation Acc:0.5900562851782364 \tTrain Acc:0.8458382180539273\n",
      "Epoch 86, Train Loss: 0.3531, Validate Loss: 0.9154\n",
      "Epoch:86 \tValidation Acc:0.5956848030018762 \tTrain Acc:0.8471277842907385\n",
      "Epoch 87, Train Loss: 0.3480, Validate Loss: 0.9085\n",
      "Epoch:87 \tValidation Acc:0.5900562851782364 \tTrain Acc:0.8475967174677609\n",
      "Epoch 88, Train Loss: 0.3481, Validate Loss: 0.9535\n",
      "Epoch:88 \tValidation Acc:0.6013133208255159 \tTrain Acc:0.845369284876905\n",
      "Epoch 89, Train Loss: 0.3390, Validate Loss: 1.0026\n",
      "Epoch:89 \tValidation Acc:0.5844277673545967 \tTrain Acc:0.8474794841735053\n",
      "Epoch 90, Train Loss: 0.3401, Validate Loss: 1.0012\n",
      "Epoch:90 \tValidation Acc:0.5928705440900562 \tTrain Acc:0.8485345838218054\n",
      "Epoch 91, Train Loss: 0.3371, Validate Loss: 1.0113\n",
      "Epoch:91 \tValidation Acc:0.5797373358348968 \tTrain Acc:0.8498241500586167\n",
      "Epoch 92, Train Loss: 0.3346, Validate Loss: 1.0142\n",
      "Epoch:92 \tValidation Acc:0.5881801125703565 \tTrain Acc:0.8542790152403282\n",
      "Epoch 93, Train Loss: 0.3234, Validate Loss: 0.9915\n",
      "Epoch:93 \tValidation Acc:0.5900562851782364 \tTrain Acc:0.8637749120750293\n",
      "Epoch 94, Train Loss: 0.3237, Validate Loss: 1.0179\n",
      "Epoch:94 \tValidation Acc:0.6022514071294559 \tTrain Acc:0.8579132473622508\n",
      "Epoch 95, Train Loss: 0.3180, Validate Loss: 1.0886\n",
      "Epoch:95 \tValidation Acc:0.5797373358348968 \tTrain Acc:0.8623681125439625\n",
      "Epoch 96, Train Loss: 0.3150, Validate Loss: 1.0471\n",
      "Epoch:96 \tValidation Acc:0.5975609756097561 \tTrain Acc:0.865767878077374\n",
      "Epoch 97, Train Loss: 0.3060, Validate Loss: 1.0533\n",
      "Epoch:97 \tValidation Acc:0.5769230769230769 \tTrain Acc:0.8670574443141852\n",
      "Epoch 98, Train Loss: 0.3029, Validate Loss: 1.0706\n",
      "Epoch:98 \tValidation Acc:0.5872420262664165 \tTrain Acc:0.87010550996483\n",
      "Epoch 99, Train Loss: 0.3014, Validate Loss: 1.1181\n",
      "Epoch:99 \tValidation Acc:0.5816135084427767 \tTrain Acc:0.8688159437280187\n",
      "Epoch 100, Train Loss: 0.2990, Validate Loss: 1.0939\n",
      "Epoch:100 \tValidation Acc:0.5872420262664165 \tTrain Acc:0.8732708089097304\n"
     ]
    }
   ],
   "source": [
    "RNN_embeddings_model = VanillaRNNWithEmbedding(input_size=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=2, num_classes=1)\n",
    "optim = torch.optim.Adam(RNN_embeddings_model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "train_dataset_ed2 = EmbeddingsDataset2(train_dataset['text'], train_dataset['label'], num_tokens_per_sentence=25)\n",
    "validation_dataset_ed2 = EmbeddingsDataset2(validation_dataset['text'], validation_dataset['label'], num_tokens_per_sentence=25)\n",
    "# test_dataset_ed2 = EmbeddingsDataset(test_dataset['text'], test_dataset['label'])\n",
    "\n",
    "\n",
    "train_dataloader2 = DataLoader(train_dataset_ed2, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader2 = DataLoader(validation_dataset_ed2, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "validation_acc = [] \n",
    "train_acc = []\n",
    "train_losses, validate_losses = [], []\n",
    "for i in range(NUM_EPOCHS):\n",
    "  train_loss, train_correct = train_loop2(train_dataloader2, RNN_embeddings_model, criterion, optim) \n",
    "  validate_loss, validate_correct = test_loop2(validation_dataloader2, RNN_embeddings_model, criterion)\n",
    "  validation_acc.append(validate_correct)\n",
    "  train_acc.append(train_correct)\n",
    "  train_losses.append(train_loss)\n",
    "  validate_losses.append(validate_loss)\n",
    "\n",
    "  print(f\"Epoch {i+1}, Train Loss: {train_loss:.4f}, Validate Loss: {validate_loss:.4f}\")\n",
    "  #if i%10 == 0:\n",
    "  print(f\"Epoch:{i+1} \\tValidation Acc:{validate_correct} \\tTrain Acc:{train_correct}\")\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6817, Validate Loss: 0.6627\n",
      "Epoch:1 \tValidation Acc:0.5928705440900562 \tTrain Acc:0.564947245017585\n",
      "Epoch 2, Train Loss: 0.6484, Validate Loss: 0.6533\n",
      "Epoch:2 \tValidation Acc:0.626641651031895 \tTrain Acc:0.623915592028136\n",
      "Epoch 3, Train Loss: 0.6185, Validate Loss: 0.6524\n",
      "Epoch:3 \tValidation Acc:0.6285178236397748 \tTrain Acc:0.658968347010551\n",
      "Epoch 4, Train Loss: 0.5926, Validate Loss: 0.6490\n",
      "Epoch:4 \tValidation Acc:0.6407129455909943 \tTrain Acc:0.688042203985932\n",
      "Epoch 5, Train Loss: 0.5549, Validate Loss: 0.7002\n",
      "Epoch:5 \tValidation Acc:0.6116322701688556 \tTrain Acc:0.7188745603751465\n",
      "Epoch 6, Train Loss: 0.5269, Validate Loss: 0.6591\n",
      "Epoch:6 \tValidation Acc:0.651031894934334 \tTrain Acc:0.7363423212192263\n",
      "Epoch 7, Train Loss: 0.4780, Validate Loss: 0.6812\n",
      "Epoch:7 \tValidation Acc:0.6191369606003753 \tTrain Acc:0.7726846424384525\n",
      "Epoch 8, Train Loss: 0.4395, Validate Loss: 0.7087\n",
      "Epoch:8 \tValidation Acc:0.6163227016885553 \tTrain Acc:0.8024618991793669\n",
      "Epoch 9, Train Loss: 0.3793, Validate Loss: 0.7088\n",
      "Epoch:9 \tValidation Acc:0.6350844277673546 \tTrain Acc:0.8405627198124267\n",
      "Epoch 10, Train Loss: 0.3343, Validate Loss: 0.7733\n",
      "Epoch:10 \tValidation Acc:0.6350844277673546 \tTrain Acc:0.8647127784290739\n",
      "Epoch 11, Train Loss: 0.2681, Validate Loss: 0.8049\n",
      "Epoch:11 \tValidation Acc:0.6425891181988743 \tTrain Acc:0.9024618991793669\n",
      "Epoch 12, Train Loss: 0.2156, Validate Loss: 0.8936\n",
      "Epoch:12 \tValidation Acc:0.625703564727955 \tTrain Acc:0.9295427901524033\n",
      "Epoch 13, Train Loss: 0.1620, Validate Loss: 0.8837\n",
      "Epoch:13 \tValidation Acc:0.6303939962476548 \tTrain Acc:0.9532239155920281\n",
      "Epoch 14, Train Loss: 0.1134, Validate Loss: 0.9623\n",
      "Epoch:14 \tValidation Acc:0.6181988742964353 \tTrain Acc:0.976084407971864\n",
      "Epoch 15, Train Loss: 0.0892, Validate Loss: 1.0407\n",
      "Epoch:15 \tValidation Acc:0.6200750469043153 \tTrain Acc:0.9814771395076202\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m train_losses, validate_losses \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m---> 19\u001b[0m   train_loss, train_correct \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRNN_embeddings_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     20\u001b[0m   validate_loss, validate_correct \u001b[38;5;241m=\u001b[39m test_loop(validation_dataloader2, RNN_embeddings_model, criterion)\n\u001b[0;32m     21\u001b[0m   validation_acc\u001b[38;5;241m.\u001b[39mappend(validate_correct)\n",
      "Cell \u001b[1;32mIn[149], line 8\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(train_dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      6\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m      7\u001b[0m train_loss, train_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_on_gpu\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RNN_embeddings_model = VanillaRNNWithEmbedding(input_size=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=2, num_classes=1)\n",
    "optim = torch.optim.Adam(RNN_embeddings_model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "train_dataset_ed2 = EmbeddingsDataset2(train_dataset['text'], train_dataset['label'], num_tokens_per_sentence=25)\n",
    "validation_dataset_ed2 = EmbeddingsDataset2(validation_dataset['text'], validation_dataset['label'], num_tokens_per_sentence=25)\n",
    "# test_dataset_ed2 = EmbeddingsDataset(test_dataset['text'], test_dataset['label'])\n",
    "\n",
    "\n",
    "train_dataloader2 = DataLoader(train_dataset_ed2, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader2 = DataLoader(validation_dataset_ed2, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "validation_acc = [] \n",
    "train_acc = []\n",
    "train_losses, validate_losses = [], []\n",
    "for i in range(NUM_EPOCHS):\n",
    "  train_loss, train_correct = train_loop(train_dataloader2, RNN_embeddings_model, criterion, optim) \n",
    "  validate_loss, validate_correct = test_loop(validation_dataloader2, RNN_embeddings_model, criterion)\n",
    "  validation_acc.append(validate_correct)\n",
    "  train_acc.append(train_correct)\n",
    "  train_losses.append(train_loss)\n",
    "  validate_losses.append(validate_loss)\n",
    "\n",
    "  print(f\"Epoch {i+1}, Train Loss: {train_loss:.4f}, Validate Loss: {validate_loss:.4f}\")\n",
    "  #if i%10 == 0:\n",
    "  print(f\"Epoch:{i+1} \\tValidation Acc:{validate_correct} \\tTrain Acc:{train_correct}\")\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(train_acc, label=\"train acc\")\n",
    "plt.plot(validation_acc, label=\"validation acc\")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracies\")\n",
    "plt.title(\"Max pooling: train vs validation accs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(train_losses, label=\"train loss\")\n",
    "plt.plot(validate_losses, label=\"validation loss\")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracies\")\n",
    "plt.title(\"train vs validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box(learning_rate, epoch, batch_size, num_layers): # A list of hyperparameters to optimize\n",
    "    validation_acc = [] \n",
    "    train_acc = []\n",
    "    train_correct, validate_correct = 0, 0\n",
    "\n",
    "    epoch = int(epoch)\n",
    "    batch_size = int(batch_size)\n",
    "    num_layers = int(num_layers)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    RNN_embeddings_model = VanillaRNNWithEmbedding(input_size=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, num_classes=1)\n",
    "    optim = torch.optim.Adam(RNN_embeddings_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_dataset_ed2 = EmbeddingsDataset2(train_dataset['text'], train_dataset['label'])\n",
    "    validation_dataset_ed2 = EmbeddingsDataset2(validation_dataset['text'], validation_dataset['label'])\n",
    "    # test_dataset_ed2 = EmbeddingsDataset(test_dataset['text'], test_dataset['label'])\n",
    "\n",
    "    train_dataloader2 = DataLoader(train_dataset_ed2, batch_size=batch_size, shuffle=True)\n",
    "    validation_dataloader2 = DataLoader(validation_dataset_ed2, batch_size=batch_size, shuffle=True)\n",
    "    for _ in range(epoch):\n",
    "        train_loss, train_correct = train_loop(train_dataloader2, RNN_embeddings_model, criterion, optim) \n",
    "        validate_loss, validate_correct = test_loop(validation_dataloader2, RNN_embeddings_model, criterion)\n",
    "        #validation_acc.append(validate_correct)\n",
    "        #train_acc.append(train_correct)\n",
    "    return validate_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=black_box,\n",
    "    pbounds={\"learning_rate\": (0.0001, 0.01), \"epoch\": (1, 60), \"batch_size\": (5, 64), \"num_layers\": (1, 8)},\n",
    "    random_state=1,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |   epoch   | learni... | num_la... |\n",
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.5385   \u001b[39m | \u001b[39m29.6     \u001b[39m | \u001b[39m72.31    \u001b[39m | \u001b[39m0.0001114\u001b[39m | \u001b[39m3.116    \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m13.66    \u001b[39m | \u001b[39m10.14    \u001b[39m | \u001b[39m0.01871  \u001b[39m | \u001b[39m3.419    \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m28.41    \u001b[39m | \u001b[39m54.34    \u001b[39m | \u001b[39m0.04198  \u001b[39m | \u001b[39m5.797    \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m17.06    \u001b[39m | \u001b[39m87.93    \u001b[39m | \u001b[39m0.002836 \u001b[39m | \u001b[39m5.693    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m29.62    \u001b[39m | \u001b[39m56.31    \u001b[39m | \u001b[39m0.01412  \u001b[39m | \u001b[39m2.387    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m52.24    \u001b[39m | \u001b[39m96.86    \u001b[39m | \u001b[39m0.03141  \u001b[39m | \u001b[39m5.846    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.4944   \u001b[39m | \u001b[39m56.71    \u001b[39m | \u001b[39m89.57    \u001b[39m | \u001b[39m0.008596 \u001b[39m | \u001b[39m1.273    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m15.02    \u001b[39m | \u001b[39m87.94    \u001b[39m | \u001b[39m0.009925 \u001b[39m | \u001b[39m3.948    \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m61.52    \u001b[39m | \u001b[39m53.78    \u001b[39m | \u001b[39m0.06922  \u001b[39m | \u001b[39m3.209    \u001b[39m |\n",
      "| \u001b[35m10       \u001b[39m | \u001b[35m0.5394   \u001b[39m | \u001b[35m45.5     \u001b[39m | \u001b[35m83.63    \u001b[39m | \u001b[35m0.001927 \u001b[39m | \u001b[35m6.251    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.5009   \u001b[39m | \u001b[39m38.32    \u001b[39m | \u001b[39m78.24    \u001b[39m | \u001b[39m0.03072  \u001b[39m | \u001b[39m5.91     \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m48.27    \u001b[39m | \u001b[39m82.71    \u001b[39m | \u001b[39m0.01068  \u001b[39m | \u001b[39m7.913    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m46.25    \u001b[39m | \u001b[39m83.35    \u001b[39m | \u001b[39m0.07759  \u001b[39m | \u001b[39m7.262    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m6.251    \u001b[39m | \u001b[39m80.98    \u001b[39m | \u001b[39m0.09649  \u001b[39m | \u001b[39m5.915    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m26.5     \u001b[39m | \u001b[39m3.217    \u001b[39m | \u001b[39m0.01533  \u001b[39m | \u001b[39m7.801    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m29.39    \u001b[39m | \u001b[39m71.92    \u001b[39m | \u001b[39m0.07659  \u001b[39m | \u001b[39m3.316    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m62.89    \u001b[39m | \u001b[39m27.77    \u001b[39m | \u001b[39m0.0809   \u001b[39m | \u001b[39m4.126    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m24.17    \u001b[39m | \u001b[39m63.94    \u001b[39m | \u001b[39m0.04011  \u001b[39m | \u001b[39m6.261    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m23.05    \u001b[39m | \u001b[39m67.99    \u001b[39m | \u001b[39m0.05518  \u001b[39m | \u001b[39m3.211    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m28.43    \u001b[39m | \u001b[39m20.22    \u001b[39m | \u001b[39m0.00538  \u001b[39m | \u001b[39m3.415    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.4991   \u001b[39m | \u001b[39m5.558    \u001b[39m | \u001b[39m55.47    \u001b[39m | \u001b[39m0.01628  \u001b[39m | \u001b[39m4.345    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m24.61    \u001b[39m | \u001b[39m48.99    \u001b[39m | \u001b[39m0.04174  \u001b[39m | \u001b[39m6.746    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m18.81    \u001b[39m | \u001b[39m45.25    \u001b[39m | \u001b[39m0.05506  \u001b[39m | \u001b[39m7.644    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m11.95    \u001b[39m | \u001b[39m55.5     \u001b[39m | \u001b[39m0.0492   \u001b[39m | \u001b[39m2.022    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.5169   \u001b[39m | \u001b[39m20.5     \u001b[39m | \u001b[39m3.162    \u001b[39m | \u001b[39m0.01683  \u001b[39m | \u001b[39m5.491    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m16.57    \u001b[39m | \u001b[39m40.64    \u001b[39m | \u001b[39m0.05158  \u001b[39m | \u001b[39m1.491    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m15.67    \u001b[39m | \u001b[39m27.91    \u001b[39m | \u001b[39m0.08037  \u001b[39m | \u001b[39m5.536    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m12.89    \u001b[39m | \u001b[39m51.28    \u001b[39m | \u001b[39m0.08892  \u001b[39m | \u001b[39m4.97     \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m29       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m13.95    \u001b[39m | \u001b[39m21.22    \u001b[39m | \u001b[39m0.06728  \u001b[39m | \u001b[39m7.124    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[35m30       \u001b[39m | \u001b[35m0.5638   \u001b[39m | \u001b[35m53.26    \u001b[39m | \u001b[35m17.19    \u001b[39m | \u001b[35m0.001602 \u001b[39m | \u001b[35m2.127    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m31       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m63.17    \u001b[39m | \u001b[39m71.12    \u001b[39m | \u001b[39m0.05829  \u001b[39m | \u001b[39m6.223    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m32       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m58.04    \u001b[39m | \u001b[39m45.77    \u001b[39m | \u001b[39m0.03998  \u001b[39m | \u001b[39m3.181    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m33       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m46.4     \u001b[39m | \u001b[39m39.04    \u001b[39m | \u001b[39m0.02691  \u001b[39m | \u001b[39m4.424    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m34       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m63.66    \u001b[39m | \u001b[39m26.33    \u001b[39m | \u001b[39m0.0619   \u001b[39m | \u001b[39m3.589    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m35       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m55.21    \u001b[39m | \u001b[39m78.51    \u001b[39m | \u001b[39m0.09023  \u001b[39m | \u001b[39m1.654    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m36       \u001b[39m | \u001b[39m0.5028   \u001b[39m | \u001b[39m28.28    \u001b[39m | \u001b[39m65.22    \u001b[39m | \u001b[39m0.01577  \u001b[39m | \u001b[39m3.921    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m37       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m36.82    \u001b[39m | \u001b[39m39.82    \u001b[39m | \u001b[39m0.09373  \u001b[39m | \u001b[39m3.952    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m38       \u001b[39m | \u001b[39m0.4991   \u001b[39m | \u001b[39m33.82    \u001b[39m | \u001b[39m7.355    \u001b[39m | \u001b[39m0.03303  \u001b[39m | \u001b[39m5.481    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m39       \u001b[39m | \u001b[39m0.5056   \u001b[39m | \u001b[39m28.93    \u001b[39m | \u001b[39m2.383    \u001b[39m | \u001b[39m0.04087  \u001b[39m | \u001b[39m6.515    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m40       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m43.65    \u001b[39m | \u001b[39m22.56    \u001b[39m | \u001b[39m0.0703   \u001b[39m | \u001b[39m7.349    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m41       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m22.78    \u001b[39m | \u001b[39m63.6     \u001b[39m | \u001b[39m0.0893   \u001b[39m | \u001b[39m4.529    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m42       \u001b[39m | \u001b[39m0.4991   \u001b[39m | \u001b[39m48.67    \u001b[39m | \u001b[39m98.4     \u001b[39m | \u001b[39m0.01612  \u001b[39m | \u001b[39m6.188    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m43       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m26.22    \u001b[39m | \u001b[39m51.19    \u001b[39m | \u001b[39m0.07251  \u001b[39m | \u001b[39m4.647    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m44       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m33.65    \u001b[39m | \u001b[39m69.15    \u001b[39m | \u001b[39m0.0648   \u001b[39m | \u001b[39m6.607    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m45       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m59.91    \u001b[39m | \u001b[39m91.34    \u001b[39m | \u001b[39m0.07552  \u001b[39m | \u001b[39m5.825    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m46       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m28.21    \u001b[39m | \u001b[39m94.5     \u001b[39m | \u001b[39m0.07652  \u001b[39m | \u001b[39m6.504    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m47       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m25.66    \u001b[39m | \u001b[39m94.35    \u001b[39m | \u001b[39m0.038    \u001b[39m | \u001b[39m3.026    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m48       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m30.48    \u001b[39m | \u001b[39m68.21    \u001b[39m | \u001b[39m0.09317  \u001b[39m | \u001b[39m5.729    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m49       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m43.05    \u001b[39m | \u001b[39m13.4     \u001b[39m | \u001b[39m0.06798  \u001b[39m | \u001b[39m2.798    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m50       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m29.86    \u001b[39m | \u001b[39m42.39    \u001b[39m | \u001b[39m0.08251  \u001b[39m | \u001b[39m3.506    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m51       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m61.73    \u001b[39m | \u001b[39m68.52    \u001b[39m | \u001b[39m0.05952  \u001b[39m | \u001b[39m5.858    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m52       \u001b[39m | \u001b[39m0.4962   \u001b[39m | \u001b[39m63.43    \u001b[39m | \u001b[39m64.76    \u001b[39m | \u001b[39m0.008872 \u001b[39m | \u001b[39m1.494    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m53       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m30.29    \u001b[39m | \u001b[39m18.37    \u001b[39m | \u001b[39m0.04175  \u001b[39m | \u001b[39m6.959    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m54       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m45.66    \u001b[39m | \u001b[39m12.67    \u001b[39m | \u001b[39m0.0544   \u001b[39m | \u001b[39m5.896    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m55       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m27.43    \u001b[39m | \u001b[39m84.99    \u001b[39m | \u001b[39m0.04115  \u001b[39m | \u001b[39m3.61     \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m56       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m50.99    \u001b[39m | \u001b[39m90.4     \u001b[39m | \u001b[39m0.05129  \u001b[39m | \u001b[39m3.067    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m57       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m44.15    \u001b[39m | \u001b[39m46.33    \u001b[39m | \u001b[39m0.03891  \u001b[39m | \u001b[39m1.568    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m58       \u001b[39m | \u001b[39m0.4991   \u001b[39m | \u001b[39m59.4     \u001b[39m | \u001b[39m31.25    \u001b[39m | \u001b[39m0.0541   \u001b[39m | \u001b[39m1.812    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m59       \u001b[39m | \u001b[39m0.5009   \u001b[39m | \u001b[39m21.91    \u001b[39m | \u001b[39m11.28    \u001b[39m | \u001b[39m0.08537  \u001b[39m | \u001b[39m1.988    \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_batch = torch.tensor(X_batch)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_101968\\4173132243.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch = torch.tensor(y_batch, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m60       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m47.47    \u001b[39m | \u001b[39m29.42    \u001b[39m | \u001b[39m0.02467  \u001b[39m | \u001b[39m2.23     \u001b[39m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(init_points=5, n_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': np.float64(0.5637898686679175), 'params': {'batch_size': np.float64(53.26447499168856), 'epoch': np.float64(17.18914449561826), 'learning_rate': np.float64(0.0016018184281454636), 'num_layers': np.float64(2.1269209601583134)}}\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.set_bounds(new_bounds={\"learning_rate\": (0.0001, 0.01), \"epoch\": (1, 60), \"batch_size\": (5, 64), \"num_layers\": (1, 8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "logger = JSONLogger(path=\"./logs.log\")\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |   epoch   | learni... | num_la... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[39m62       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m33.12    \u001b[39m | \u001b[39m49.11    \u001b[39m | \u001b[39m0.006336 \u001b[39m | \u001b[39m7.38     \u001b[39m |\n",
      "| \u001b[39m63       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m47.49    \u001b[39m | \u001b[39m34.79    \u001b[39m | \u001b[39m0.006623 \u001b[39m | \u001b[39m7.939    \u001b[39m |\n",
      "| \u001b[39m64       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m14.38    \u001b[39m | \u001b[39m29.23    \u001b[39m | \u001b[39m0.005116 \u001b[39m | \u001b[39m1.848    \u001b[39m |\n",
      "| \u001b[39m65       \u001b[39m | \u001b[39m0.5028   \u001b[39m | \u001b[39m62.63    \u001b[39m | \u001b[39m32.79    \u001b[39m | \u001b[39m0.009846 \u001b[39m | \u001b[39m6.543    \u001b[39m |\n",
      "| \u001b[39m66       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m37.97    \u001b[39m | \u001b[39m12.79    \u001b[39m | \u001b[39m0.008052 \u001b[39m | \u001b[39m1.569    \u001b[39m |\n",
      "| \u001b[39m67       \u001b[39m | \u001b[39m0.485    \u001b[39m | \u001b[39m52.05    \u001b[39m | \u001b[39m11.81    \u001b[39m | \u001b[39m0.002247 \u001b[39m | \u001b[39m7.624    \u001b[39m |\n",
      "| \u001b[39m68       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m15.72    \u001b[39m | \u001b[39m53.75    \u001b[39m | \u001b[39m0.005095 \u001b[39m | \u001b[39m7.904    \u001b[39m |\n",
      "| \u001b[39m69       \u001b[39m | \u001b[39m0.4756   \u001b[39m | \u001b[39m45.07    \u001b[39m | \u001b[39m49.91    \u001b[39m | \u001b[39m0.003345 \u001b[39m | \u001b[39m3.658    \u001b[39m |\n",
      "| \u001b[39m70       \u001b[39m | \u001b[39m0.4841   \u001b[39m | \u001b[39m52.16    \u001b[39m | \u001b[39m17.05    \u001b[39m | \u001b[39m0.007017 \u001b[39m | \u001b[39m4.107    \u001b[39m |\n",
      "| \u001b[39m71       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m28.8     \u001b[39m | \u001b[39m59.24    \u001b[39m | \u001b[39m0.006845 \u001b[39m | \u001b[39m7.359    \u001b[39m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points=0,\n",
    "    n_iter=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |   epoch   | learni... | num_la... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[39m72       \u001b[39m | \u001b[39m0.5272   \u001b[39m | \u001b[39m42.96    \u001b[39m | \u001b[39m37.04    \u001b[39m | \u001b[39m0.008657 \u001b[39m | \u001b[39m2.45     \u001b[39m |\n",
      "| \u001b[39m73       \u001b[39m | \u001b[39m0.5047   \u001b[39m | \u001b[39m36.86    \u001b[39m | \u001b[39m19.95    \u001b[39m | \u001b[39m0.008388 \u001b[39m | \u001b[39m7.927    \u001b[39m |\n",
      "| \u001b[39m74       \u001b[39m | \u001b[39m0.4934   \u001b[39m | \u001b[39m52.18    \u001b[39m | \u001b[39m23.63    \u001b[39m | \u001b[39m0.007858 \u001b[39m | \u001b[39m5.999    \u001b[39m |\n",
      "| \u001b[39m75       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m63.94    \u001b[39m | \u001b[39m35.5     \u001b[39m | \u001b[39m0.004804 \u001b[39m | \u001b[39m7.199    \u001b[39m |\n",
      "| \u001b[39m76       \u001b[39m | \u001b[39m0.5516   \u001b[39m | \u001b[39m63.59    \u001b[39m | \u001b[39m16.72    \u001b[39m | \u001b[39m0.0005364\u001b[39m | \u001b[39m4.827    \u001b[39m |\n",
      "| \u001b[39m77       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m38.62    \u001b[39m | \u001b[39m3.055    \u001b[39m | \u001b[39m0.008401 \u001b[39m | \u001b[39m4.782    \u001b[39m |\n",
      "| \u001b[39m78       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m12.55    \u001b[39m | \u001b[39m9.951    \u001b[39m | \u001b[39m0.006469 \u001b[39m | \u001b[39m2.334    \u001b[39m |\n",
      "| \u001b[39m79       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m61.25    \u001b[39m | \u001b[39m46.2     \u001b[39m | \u001b[39m0.009997 \u001b[39m | \u001b[39m3.355    \u001b[39m |\n",
      "| \u001b[39m80       \u001b[39m | \u001b[39m0.5066   \u001b[39m | \u001b[39m7.714    \u001b[39m | \u001b[39m15.33    \u001b[39m | \u001b[39m0.003516 \u001b[39m | \u001b[39m1.604    \u001b[39m |\n",
      "| \u001b[39m81       \u001b[39m | \u001b[39m0.4878   \u001b[39m | \u001b[39m16.89    \u001b[39m | \u001b[39m14.01    \u001b[39m | \u001b[39m0.008163 \u001b[39m | \u001b[39m6.2      \u001b[39m |\n",
      "| \u001b[39m82       \u001b[39m | \u001b[39m0.4981   \u001b[39m | \u001b[39m36.11    \u001b[39m | \u001b[39m48.68    \u001b[39m | \u001b[39m0.007921 \u001b[39m | \u001b[39m5.503    \u001b[39m |\n",
      "| \u001b[39m83       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m58.9     \u001b[39m | \u001b[39m43.39    \u001b[39m | \u001b[39m0.005368 \u001b[39m | \u001b[39m4.232    \u001b[39m |\n",
      "| \u001b[39m84       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m9.08     \u001b[39m | \u001b[39m58.55    \u001b[39m | \u001b[39m0.00938  \u001b[39m | \u001b[39m2.945    \u001b[39m |\n",
      "| \u001b[39m85       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m55.78    \u001b[39m | \u001b[39m19.41    \u001b[39m | \u001b[39m0.006811 \u001b[39m | \u001b[39m7.255    \u001b[39m |\n",
      "| \u001b[39m86       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m16.94    \u001b[39m | \u001b[39m48.3     \u001b[39m | \u001b[39m0.004414 \u001b[39m | \u001b[39m3.21     \u001b[39m |\n",
      "| \u001b[39m87       \u001b[39m | \u001b[39m0.4859   \u001b[39m | \u001b[39m40.64    \u001b[39m | \u001b[39m41.71    \u001b[39m | \u001b[39m0.006557 \u001b[39m | \u001b[39m3.906    \u001b[39m |\n",
      "| \u001b[39m88       \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m16.09    \u001b[39m | \u001b[39m6.764    \u001b[39m | \u001b[39m0.005817 \u001b[39m | \u001b[39m7.31     \u001b[39m |\n",
      "| \u001b[39m89       \u001b[39m | \u001b[39m0.5197   \u001b[39m | \u001b[39m21.26    \u001b[39m | \u001b[39m24.18    \u001b[39m | \u001b[39m0.005725 \u001b[39m | \u001b[39m1.837    \u001b[39m |\n",
      "| \u001b[39m90       \u001b[39m | \u001b[39m0.5094   \u001b[39m | \u001b[39m24.79    \u001b[39m | \u001b[39m23.38    \u001b[39m | \u001b[39m0.002118 \u001b[39m | \u001b[39m5.262    \u001b[39m |\n",
      "| \u001b[39m91       \u001b[39m | \u001b[39m0.5075   \u001b[39m | \u001b[39m50.0     \u001b[39m | \u001b[39m39.84    \u001b[39m | \u001b[39m0.00306  \u001b[39m | \u001b[39m5.804    \u001b[39m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points=0,\n",
    "    n_iter=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': np.float64(0.5637898686679175), 'params': {'batch_size': np.float64(53.26447499168856), 'epoch': np.float64(17.18914449561826), 'learning_rate': np.float64(0.0016018184281454636), 'num_layers': np.float64(2.1269209601583134)}}\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nn.Embeddings \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VanillaRNNWithDropout(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, embedding_matrix_torch=torch.tensor(embedding_matrix_np, dtype=torch.float)):\n",
    "        super(VanillaRNNWithDropout, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix_torch, freeze=True, padding_idx=0)\n",
    "        self.num_layers = num_layers \n",
    "        self.hidden_size = hidden_size \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True) # this is the num rows of the input matrix \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    " \n",
    "    def forward(self, x):\n",
    "        # Pass input through embedding layer\n",
    "        x = self.embedding(x)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=torch.float).to(x.device)\n",
    "        # Pass the embeddings through the RNN layer\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Only take the last output for each sequence\n",
    "        out = out[:, -1, :]\n",
    "        # Dropout\n",
    "        out = self.dropout(out)\n",
    "        # Pass through the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        # Apply sigmoid activation (for binary classification)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box(learning_rate, epoch, batch_size, num_layers): # A list of hyperparameters to optimize\n",
    "    validation_acc = [] \n",
    "    train_acc = []\n",
    "    train_correct, validate_correct = 0, 0\n",
    "\n",
    "    epoch = int(epoch)\n",
    "    batch_size = int(batch_size)\n",
    "    num_layers = int(num_layers)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    RNN_embeddings_model = VanillaRNNWithDropout(input_size=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, num_classes=1)\n",
    "    optim = torch.optim.Adam(RNN_embeddings_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_dataset_ed2 = EmbeddingsDataset2(train_dataset['text'], train_dataset['label'])\n",
    "    validation_dataset_ed2 = EmbeddingsDataset2(validation_dataset['text'], validation_dataset['label'])\n",
    "    # test_dataset_ed2 = EmbeddingsDataset(test_dataset['text'], test_dataset['label'])\n",
    "\n",
    "    train_dataloader2 = DataLoader(train_dataset_ed2, batch_size=batch_size, shuffle=True)\n",
    "    validation_dataloader2 = DataLoader(validation_dataset_ed2, batch_size=batch_size, shuffle=True)\n",
    "    for _ in range(epoch):\n",
    "        train_loss, train_correct = train_loop(train_dataloader2, RNN_embeddings_model, criterion, optim) \n",
    "        validate_loss, validate_correct = test_loop(validation_dataloader2, RNN_embeddings_model, criterion)\n",
    "        #validation_acc.append(validate_correct)\n",
    "        #train_acc.append(train_correct)\n",
    "    return validate_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=black_box,\n",
    "    pbounds={\"learning_rate\": (0.0001, 0.01), \"epoch\": (1, 60), \"batch_size\": (5, 64), \"num_layers\": (1, 8)},\n",
    "    random_state=1,\n",
    "    verbose=2\n",
    ")\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "logger = JSONLogger(path=\"./logs_dropout.log\")\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.probe(\n",
    "    params={\"learning_rate\": 0.0016, \"epoch\": 17, \"batch_size\": 53, \"num_layers\": 2},\n",
    "    lazy = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0.5694183864915572\n",
      "test 0.5450281425891182\n",
      "test 0.5112570356472795\n",
      "test 0.5769230769230769\n",
      "test 0.5\n",
      "test 0.5\n",
      "test 0.5891181988742964\n",
      "test 0.5150093808630394\n",
      "test 0.5\n",
      "test 0.4896810506566604\n",
      "test 0.5234521575984991\n",
      "test 0.549718574108818\n",
      "test 0.5478424015009381\n",
      "test 0.5\n",
      "test 0.5046904315196998\n",
      "test 0.5\n",
      "test 0.49343339587242024\n",
      "test 0.5422138836772983\n",
      "test 0.5075046904315197\n",
      "test 0.5\n",
      "test 0.5\n",
      "test 0.5787992495309568\n",
      "test 0.5647279549718575\n",
      "test 0.5140712945590994\n",
      "test 0.5\n",
      "test 0.5\n",
      "test 0.49343339587242024\n",
      "test 0.5\n",
      "test 0.5797373358348968\n",
      "test 0.5\n",
      "test 0.4906191369606004\n",
      "test 0.5\n",
      "test 0.5103189493433395\n",
      "test 0.5121951219512195\n",
      "test 0.5\n",
      "test 0.5\n",
      "test 0.5553470919324578\n",
      "test 0.5\n",
      "test 0.50093808630394\n",
      "test 0.5\n",
      "test 0.5037523452157598\n",
      "test 0.50093808630394\n",
      "test 0.5\n",
      "test 0.5234521575984991\n",
      "test 0.5478424015009381\n",
      "test 0.5\n",
      "test 0.5\n",
      "test 0.49906191369606\n",
      "test 0.50187617260788\n",
      "test 0.5309568480300187\n",
      "test 0.49624765478424016\n",
      "test 0.5093808630393997\n",
      "test 0.5562851782363978\n",
      "test 0.5684803001876173\n",
      "test 0.5084427767354597\n",
      "test 0.5\n",
      "test 0.5\n",
      "test 0.5\n",
      "test 0.525328330206379\n",
      "test 0.5\n",
      "test 0.50093808630394\n",
      "test 0.5131332082551595\n",
      "test 0.5\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(init_points=2, n_iter=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': np.float64(0.5891181988742964),\n",
       " 'params': {'batch_size': np.float64(55.01782564205619),\n",
       "  'epoch': np.float64(17.216924152295988),\n",
       "  'learning_rate': np.float64(0.0029747238556237883),\n",
       "  'num_layers': np.float64(1.5953275626132635)}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: \n",
      "\t{'target': np.float64(0.5694183864915572), 'params': {'batch_size': np.float64(53.0), 'epoch': np.float64(17.0), 'learning_rate': np.float64(0.0016), 'num_layers': np.float64(2.0)}}\n",
      "Iteration 1: \n",
      "\t{'target': np.float64(0.5450281425891182), 'params': {'batch_size': np.float64(29.604298277451868), 'epoch': np.float64(43.49914511308733), 'learning_rate': np.float64(0.00010113231069171439), 'num_layers': np.float64(3.1163280084228786)}}\n",
      "Iteration 2: \n",
      "\t{'target': np.float64(0.5112570356472795), 'params': {'batch_size': np.float64(13.658597558209669), 'epoch': np.float64(6.44797709135907), 'learning_rate': np.float64(0.0019439760926389421), 'num_layers': np.float64(3.418925089301334)}}\n",
      "Iteration 3: \n",
      "\t{'target': np.float64(0.5769230769230769), 'params': {'batch_size': np.float64(53.865065176555866), 'epoch': np.float64(16.021065076802277), 'learning_rate': np.float64(0.0022729686141519097), 'num_layers': np.float64(2.322985558014845)}}\n",
      "Iteration 4: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(59.38304080761811), 'epoch': np.float64(11.021215297921465), 'learning_rate': np.float64(0.009251637590092995), 'num_layers': np.float64(3.724442788339891)}}\n",
      "Iteration 5: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(51.159192195311036), 'epoch': np.float64(13.528971753093774), 'learning_rate': np.float64(0.0022502328188345705), 'num_layers': np.float64(4.1368048842024665)}}\n",
      "Iteration 6: \n",
      "\t{'target': np.float64(0.5891181988742964), 'params': {'batch_size': np.float64(55.01782564205619), 'epoch': np.float64(17.216924152295988), 'learning_rate': np.float64(0.0029747238556237883), 'num_layers': np.float64(1.5953275626132635)}}\n",
      "Iteration 7: \n",
      "\t{'target': np.float64(0.5150093808630394), 'params': {'batch_size': np.float64(57.28100498593709), 'epoch': np.float64(19.08778956020952), 'learning_rate': np.float64(0.001713709600651785), 'num_layers': np.float64(4.121717495939463)}}\n",
      "Iteration 8: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(56.32119319254185), 'epoch': np.float64(15.001044241283436), 'learning_rate': np.float64(0.005945720922266015), 'num_layers': np.float64(1.5976202858359598)}}\n",
      "Iteration 9: \n",
      "\t{'target': np.float64(0.4896810506566604), 'params': {'batch_size': np.float64(54.510736199928104), 'epoch': np.float64(17.263383732939324), 'learning_rate': np.float64(0.005326955872387043), 'num_layers': np.float64(2.821076942181391)}}\n",
      "Iteration 10: \n",
      "\t{'target': np.float64(0.5234521575984991), 'params': {'batch_size': np.float64(29.502342180516173), 'epoch': np.float64(43.093126104911626), 'learning_rate': np.float64(0.008963139268345402), 'num_layers': np.float64(3.622966064341308)}}\n",
      "Iteration 11: \n",
      "\t{'target': np.float64(0.549718574108818), 'params': {'batch_size': np.float64(53.83447218320983), 'epoch': np.float64(15.901444627141036), 'learning_rate': np.float64(0.0015358829494509507), 'num_layers': np.float64(2.37792621547061)}}\n",
      "Iteration 12: \n",
      "\t{'target': np.float64(0.5478424015009381), 'params': {'batch_size': np.float64(28.43388731841654), 'epoch': np.float64(12.456495888732382), 'learning_rate': np.float64(0.0006232741719578822), 'num_layers': np.float64(3.4146642182805804)}}\n",
      "Iteration 13: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(5.55835547735852), 'epoch': np.float64(33.46204977400653), 'learning_rate': np.float64(0.001703683935436564), 'num_layers': np.float64(4.344594394207118)}}\n",
      "Iteration 14: \n",
      "\t{'target': np.float64(0.5046904315196998), 'params': {'batch_size': np.float64(24.608807250518403), 'epoch': np.float64(29.602757884304054), 'learning_rate': np.float64(0.0042265804560144594), 'num_layers': np.float64(6.74581195410718)}}\n",
      "Iteration 15: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(18.809367377863072), 'epoch': np.float64(27.373109485044917), 'learning_rate': np.float64(0.0055460861591496245), 'num_layers': np.float64(7.644278811982074)}}\n",
      "Iteration 16: \n",
      "\t{'target': np.float64(0.49343339587242024), 'params': {'batch_size': np.float64(11.954392727801258), 'epoch': np.float64(33.481334650824024), 'learning_rate': np.float64(0.00496550489054661), 'num_layers': np.float64(2.0217239258016764)}}\n",
      "Iteration 17: \n",
      "\t{'target': np.float64(0.5422138836772983), 'params': {'batch_size': np.float64(54.050127077011894), 'epoch': np.float64(15.798545167862265), 'learning_rate': np.float64(0.0029554625567605837), 'num_layers': np.float64(2.670898832879527)}}\n",
      "Iteration 18: \n",
      "\t{'target': np.float64(0.5075046904315197), 'params': {'batch_size': np.float64(54.257069824709085), 'epoch': np.float64(15.542376909027555), 'learning_rate': np.float64(0.005851382019516044), 'num_layers': np.float64(2.563383024867282)}}\n",
      "Iteration 19: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(15.666522660985207), 'epoch': np.float64(17.034506375180204), 'learning_rate': np.float64(0.008055052114754305), 'num_layers': np.float64(5.536269805153662)}}\n",
      "Iteration 20: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(29.775444252135625), 'epoch': np.float64(43.6838659420433), 'learning_rate': np.float64(0.008901938788850941), 'num_layers': np.float64(2.996788711429435)}}\n",
      "Iteration 21: \n",
      "\t{'target': np.float64(0.5787992495309568), 'params': {'batch_size': np.float64(55.36505505119515), 'epoch': np.float64(16.98101242301825), 'learning_rate': np.float64(0.0016262741167851558), 'num_layers': np.float64(1.804861594835442)}}\n",
      "Iteration 22: \n",
      "\t{'target': np.float64(0.5647279549718575), 'params': {'batch_size': np.float64(53.26447499168856), 'epoch': np.float64(10.648076012540177), 'learning_rate': np.float64(0.00024882885323964055), 'num_layers': np.float64(2.1269209601583134)}}\n",
      "Iteration 23: \n",
      "\t{'target': np.float64(0.5140712945590994), 'params': {'batch_size': np.float64(63.174571676827135), 'epoch': np.float64(42.79133075399859), 'learning_rate': np.float64(0.00586687940135942), 'num_layers': np.float64(6.222870959423908)}}\n",
      "Iteration 24: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(58.04094296656058), 'epoch': np.float64(27.680947479642406), 'learning_rate': np.float64(0.00405222716050925), 'num_layers': np.float64(3.1806974647086266)}}\n",
      "Iteration 25: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(52.687802910120546), 'epoch': np.float64(16.82894860919011), 'learning_rate': np.float64(0.006493464666399643), 'num_layers': np.float64(1.7151762058313609)}}\n",
      "Iteration 26: \n",
      "\t{'target': np.float64(0.49343339587242024), 'params': {'batch_size': np.float64(53.473687486713146), 'epoch': np.float64(10.573351467453982), 'learning_rate': np.float64(0.004406503906259965), 'num_layers': np.float64(1.6560494574152687)}}\n",
      "Iteration 27: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(28.354787951366834), 'epoch': np.float64(12.238173609544518), 'learning_rate': np.float64(0.009976129504029332), 'num_layers': np.float64(3.1194151747727297)}}\n",
      "Iteration 28: \n",
      "\t{'target': np.float64(0.5797373358348968), 'params': {'batch_size': np.float64(54.41475333779778), 'epoch': np.float64(15.922196251708971), 'learning_rate': np.float64(0.001300766114221012), 'num_layers': np.float64(1.7708123185491411)}}\n",
      "Iteration 29: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(36.81660706756672), 'epoch': np.float64(24.132291614175806), 'learning_rate': np.float64(0.009378754148032577), 'num_layers': np.float64(3.951567491290912)}}\n",
      "Iteration 30: \n",
      "\t{'target': np.float64(0.4906191369606004), 'params': {'batch_size': np.float64(33.82144270224923), 'epoch': np.float64(4.78749560266928), 'learning_rate': np.float64(0.003363403665417363), 'num_layers': np.float64(5.481265768453364)}}\n",
      "Iteration 31: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(54.76259306542409), 'epoch': np.float64(16.88570178606179), 'learning_rate': np.float64(0.005463800135524024), 'num_layers': np.float64(1.827638051916722)}}\n",
      "Iteration 32: \n",
      "\t{'target': np.float64(0.5103189493433395), 'params': {'batch_size': np.float64(43.648735783025685), 'epoch': np.float64(13.847291190546368), 'learning_rate': np.float64(0.007056286014839863), 'num_layers': np.float64(7.348983765907969)}}\n",
      "Iteration 33: \n",
      "\t{'target': np.float64(0.5121951219512195), 'params': {'batch_size': np.float64(28.072618386422423), 'epoch': np.float64(12.537719219240062), 'learning_rate': np.float64(0.003154695163584881), 'num_layers': np.float64(3.5284063988922343)}}\n",
      "Iteration 34: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(54.518164535482406), 'epoch': np.float64(15.961678596424214), 'learning_rate': np.float64(0.00967284600389975), 'num_layers': np.float64(2.070589271859449)}}\n",
      "Iteration 35: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(26.220203476672843), 'epoch': np.float64(30.909631260171434), 'learning_rate': np.float64(0.007275879010741873), 'num_layers': np.float64(4.64651488454857)}}\n",
      "Iteration 36: \n",
      "\t{'target': np.float64(0.5553470919324578), 'params': {'batch_size': np.float64(29.491243836284966), 'epoch': np.float64(43.43227124967311), 'learning_rate': np.float64(0.0018174177669482985), 'num_layers': np.float64(2.7400468134273086)}}\n",
      "Iteration 37: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(59.91142868020695), 'epoch': np.float64(54.836934245553984), 'learning_rate': np.float64(0.007573933074583711), 'num_layers': np.float64(5.825441639687478)}}\n",
      "Iteration 38: \n",
      "\t{'target': np.float64(0.50093808630394), 'params': {'batch_size': np.float64(28.207727522495325), 'epoch': np.float64(56.72344481903019), 'learning_rate': np.float64(0.007672900022050824), 'num_layers': np.float64(6.503638567666743)}}\n",
      "Iteration 39: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(25.658993128262654), 'epoch': np.float64(56.63219204044854), 'learning_rate': np.float64(0.003855537910819301), 'num_layers': np.float64(3.025724920277924)}}\n",
      "Iteration 40: \n",
      "\t{'target': np.float64(0.5037523452157598), 'params': {'batch_size': np.float64(28.752754588834378), 'epoch': np.float64(12.254120056855655), 'learning_rate': np.float64(0.002521905577946622), 'num_layers': np.float64(3.534198961935899)}}\n",
      "Iteration 41: \n",
      "\t{'target': np.float64(0.50093808630394), 'params': {'batch_size': np.float64(29.716373142471813), 'epoch': np.float64(43.455720836597074), 'learning_rate': np.float64(0.008459821982152102), 'num_layers': np.float64(3.2197069275670462)}}\n",
      "Iteration 42: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(29.863303632405174), 'epoch': np.float64(25.66525650383247), 'learning_rate': np.float64(0.00826683239834308), 'num_layers': np.float64(3.5056895212573127)}}\n",
      "Iteration 43: \n",
      "\t{'target': np.float64(0.5234521575984991), 'params': {'batch_size': np.float64(53.93305241019763), 'epoch': np.float64(15.840013416439685), 'learning_rate': np.float64(0.003129862484795453), 'num_layers': np.float64(2.314090646899075)}}\n",
      "Iteration 44: \n",
      "\t{'target': np.float64(0.5478424015009381), 'params': {'batch_size': np.float64(63.428690592207765), 'epoch': np.float64(38.998345839653915), 'learning_rate': np.float64(0.0009693208403092987), 'num_layers': np.float64(1.4943316324673876)}}\n",
      "Iteration 45: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(53.98552905654276), 'epoch': np.float64(16.146887130086398), 'learning_rate': np.float64(0.0075797606791300496), 'num_layers': np.float64(2.778510061203441)}}\n",
      "Iteration 46: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(54.55050103942847), 'epoch': np.float64(15.691746747115712), 'learning_rate': np.float64(0.008347934771067534), 'num_layers': np.float64(1.70456344881278)}}\n",
      "Iteration 47: \n",
      "\t{'target': np.float64(0.49906191369606), 'params': {'batch_size': np.float64(27.429607948826593), 'epoch': np.float64(51.05535410766693), 'learning_rate': np.float64(0.004168285921199728), 'num_layers': np.float64(3.6098658130378727)}}\n",
      "Iteration 48: \n",
      "\t{'target': np.float64(0.50187617260788), 'params': {'batch_size': np.float64(29.28172672807823), 'epoch': np.float64(43.37118910522206), 'learning_rate': np.float64(0.00469213871957369), 'num_layers': np.float64(2.750705126300632)}}\n",
      "Iteration 49: \n",
      "\t{'target': np.float64(0.5309568480300187), 'params': {'batch_size': np.float64(29.67436599897116), 'epoch': np.float64(43.686757492290724), 'learning_rate': np.float64(0.0021300546288068227), 'num_layers': np.float64(2.5312599045587723)}}\n",
      "Iteration 50: \n",
      "\t{'target': np.float64(0.49624765478424016), 'params': {'batch_size': np.float64(63.321528970446785), 'epoch': np.float64(38.62071551483721), 'learning_rate': np.float64(0.007284755559346624), 'num_layers': np.float64(1.7630634822978415)}}\n",
      "Iteration 51: \n",
      "\t{'target': np.float64(0.5093808630393997), 'params': {'batch_size': np.float64(21.907355421248123), 'epoch': np.float64(7.128159552934867), 'learning_rate': np.float64(0.008550307427662612), 'num_layers': np.float64(1.9880678285051365)}}\n",
      "Iteration 52: \n",
      "\t{'target': np.float64(0.5562851782363978), 'params': {'batch_size': np.float64(47.46838147616159), 'epoch': np.float64(17.935208185059892), 'learning_rate': np.float64(0.002535354205965862), 'num_layers': np.float64(2.23000343280743)}}\n",
      "Iteration 53: \n",
      "\t{'target': np.float64(0.5684803001876173), 'params': {'batch_size': np.float64(60.41216426930936), 'epoch': np.float64(58.34160437124727), 'learning_rate': np.float64(0.002556975315957607), 'num_layers': np.float64(1.9692042502554803)}}\n",
      "Iteration 54: \n",
      "\t{'target': np.float64(0.5084427767354597), 'params': {'batch_size': np.float64(29.300156583860684), 'epoch': np.float64(43.27087178116993), 'learning_rate': np.float64(0.002870632448446767), 'num_layers': np.float64(3.109370046794006)}}\n",
      "Iteration 55: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(33.12206266648725), 'epoch': np.float64(49.1116070056182), 'learning_rate': np.float64(0.00633582643485553), 'num_layers': np.float64(7.379959151655335)}}\n",
      "Iteration 56: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(53.756925703625626), 'epoch': np.float64(15.825142997568493), 'learning_rate': np.float64(0.007003038655803392), 'num_layers': np.float64(2.7818105062339558)}}\n",
      "Iteration 57: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(14.382118786113574), 'epoch': np.float64(29.22775059065728), 'learning_rate': np.float64(0.005116244937372004), 'num_layers': np.float64(1.8479687778061822)}}\n",
      "Iteration 58: \n",
      "\t{'target': np.float64(0.525328330206379), 'params': {'batch_size': np.float64(55.37740759401987), 'epoch': np.float64(16.730190982225754), 'learning_rate': np.float64(0.008371839155655349), 'num_layers': np.float64(1.57420015448823)}}\n",
      "Iteration 59: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(53.30329377570177), 'epoch': np.float64(10.98043528184546), 'learning_rate': np.float64(0.006616610552740382), 'num_layers': np.float64(2.6451270815821477)}}\n",
      "Iteration 60: \n",
      "\t{'target': np.float64(0.50093808630394), 'params': {'batch_size': np.float64(60.47117521308193), 'epoch': np.float64(58.517296365420655), 'learning_rate': np.float64(0.0068766716813766495), 'num_layers': np.float64(2.2944149233516735)}}\n",
      "Iteration 61: \n",
      "\t{'target': np.float64(0.5131332082551595), 'params': {'batch_size': np.float64(55.39305694538), 'epoch': np.float64(16.92486020366672), 'learning_rate': np.float64(0.008903260325981438), 'num_layers': np.float64(1.6667159507617118)}}\n",
      "Iteration 62: \n",
      "\t{'target': np.float64(0.5), 'params': {'batch_size': np.float64(45.070464489581916), 'epoch': np.float64(49.907524483573525), 'learning_rate': np.float64(0.003344593947284045), 'num_layers': np.float64(3.6577114541604296)}}\n"
     ]
    }
   ],
   "source": [
    "for i, res in enumerate(optimizer.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with dropout & more token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_with_token(learning_rate, epoch, batch_size, num_layers, num_tokens): # A list of hyperparameters to optimize\n",
    "    validation_acc = [] \n",
    "    train_acc = []\n",
    "    train_correct, validate_correct = 0, 0\n",
    "\n",
    "    # make sure the parameters are integers, since bayesian optimization return float\n",
    "    # refer to: https://colab.research.google.com/github/bayesian-optimization/BayesianOptimization/blob/master/examples/advanced-tour.ipynb#scrollTo=QWqhKqCnvZmn\n",
    "    epoch = int(epoch)\n",
    "    batch_size = int(batch_size)\n",
    "    num_layers = int(num_layers)\n",
    "    num_tokens = int(num_tokens)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    RNN_embeddings_model = VanillaRNNWithDropout(input_size=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, num_classes=1)\n",
    "    optim = torch.optim.Adam(RNN_embeddings_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_dataset_ed2 = EmbeddingsDataset2(train_dataset['text'], train_dataset['label'], num_tokens_per_sentence=num_tokens)\n",
    "    validation_dataset_ed2 = EmbeddingsDataset2(validation_dataset['text'], validation_dataset['label'], num_tokens_per_sentence=num_tokens)\n",
    "    # test_dataset_ed2 = EmbeddingsDataset(test_dataset['text'], test_dataset['label'])\n",
    "\n",
    "    train_dataloader2 = DataLoader(train_dataset_ed2, batch_size=batch_size, shuffle=True)\n",
    "    validation_dataloader2 = DataLoader(validation_dataset_ed2, batch_size=batch_size, shuffle=True)\n",
    "    for _ in range(epoch):\n",
    "        train_loss, train_correct = train_loop(train_dataloader2, RNN_embeddings_model, criterion, optim) \n",
    "        validate_loss, validate_correct = test_loop(validation_dataloader2, RNN_embeddings_model, criterion)\n",
    "        #validation_acc.append(validate_correct)\n",
    "        #train_acc.append(train_correct)\n",
    "    return validate_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=black_box_with_token,\n",
    "    pbounds={\"learning_rate\": (0.0001, 0.01), \"epoch\": (1, 60), \"batch_size\": (5, 64), \"num_layers\": (1, 8), \"num_tokens\": (16, 26)},\n",
    "    random_state=1,\n",
    "    verbose=2\n",
    ")\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "logger = JSONLogger(path=\"./logs_dropout_token.log\")\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.probe(\n",
    "    params={\"learning_rate\": 0.0016, \"epoch\": 17, \"batch_size\": 53, \"num_layers\": 2, \"num_tokens\": 20},\n",
    "    lazy = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.maximize(init_points=5, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': np.float64(0.5600375234521576),\n",
       " 'params': {'batch_size': np.float64(63.02362224905339),\n",
       "  'epoch': np.float64(6.191456753164534),\n",
       "  'learning_rate': np.float64(0.0006502875347645216),\n",
       "  'num_layers': np.float64(3.530788193240186),\n",
       "  'num_tokens': np.float64(24.5764309091781)}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': np.float64(0.5440900562851783),\n",
       "  'params': {'batch_size': np.float64(29.604298277451868),\n",
       "   'epoch': np.float64(43.49914511308733),\n",
       "   'learning_rate': np.float64(0.00010113231069171439),\n",
       "   'num_layers': np.float64(3.1163280084228786),\n",
       "   'num_tokens': np.float64(16.46755890817113)}},\n",
       " {'target': np.float64(0.5487804878048781),\n",
       "  'params': {'batch_size': np.float64(17.895131677247917),\n",
       "   'epoch': np.float64(17.931185536260774),\n",
       "   'learning_rate': np.float64(0.00019660957174913565),\n",
       "   'num_layers': np.float64(3.2833213709768443),\n",
       "   'num_tokens': np.float64(18.976001443018905)}},\n",
       " {'target': np.float64(0.551594746716698),\n",
       "  'params': {'batch_size': np.float64(62.28906779058867),\n",
       "   'epoch': np.float64(19.139926846575833),\n",
       "   'learning_rate': np.float64(0.00010016845106199955),\n",
       "   'num_layers': np.float64(7.370817526373162),\n",
       "   'num_tokens': np.float64(19.92278535746045)}},\n",
       " {'target': np.float64(0.5525328330206379),\n",
       "  'params': {'batch_size': np.float64(27.6912884571598),\n",
       "   'epoch': np.float64(32.40564746517945),\n",
       "   'learning_rate': np.float64(0.00040390272796158146),\n",
       "   'num_layers': np.float64(1.9354739940028254),\n",
       "   'num_tokens': np.float64(15.617791110282242)}},\n",
       " {'target': np.float64(0.5600375234521576),\n",
       "  'params': {'batch_size': np.float64(63.02362224905339),\n",
       "   'epoch': np.float64(6.191456753164534),\n",
       "   'learning_rate': np.float64(0.0006502875347645216),\n",
       "   'num_layers': np.float64(3.530788193240186),\n",
       "   'num_tokens': np.float64(24.5764309091781)}}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(optimizer.res, key=lambda x: x['target'])[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout + learnable hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nn.Embeddings \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DropoutInitialRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, embedding_matrix_torch=torch.tensor(embedding_matrix_np, dtype=torch.float)):\n",
    "        super(DropoutInitialRNN, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix_torch, freeze=True, padding_idx=0)\n",
    "        self.num_layers = num_layers \n",
    "        self.hidden_size = hidden_size \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True) # this is the num rows of the input matrix \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.h0 = nn.Parameter(torch.zeros(self.num_layers, 1, self.hidden_size, dtype=torch.float))\n",
    " \n",
    "    def forward(self, x):\n",
    "        # Pass input through embedding layer\n",
    "        x = self.embedding(x)\n",
    "        h0 = self.h0.expand(-1, x.size(0), -1).contiguous().to(x.device)\n",
    "        # Pass the embeddings through the RNN layer\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Only take the last output for each sequence\n",
    "        out = out[:, -1, :]\n",
    "        # Dropout\n",
    "        out = self.dropout(out)\n",
    "        # Pass through the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        # Apply sigmoid activation (for binary classification)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_with_token(learning_rate, epoch, batch_size, num_layers, num_tokens): # A list of hyperparameters to optimize\n",
    "    validation_acc = [] \n",
    "    train_acc = []\n",
    "    train_correct, validate_correct = 0, 0\n",
    "\n",
    "    # make sure the parameters are integers, since bayesian optimization return float\n",
    "    # refer to: https://colab.research.google.com/github/bayesian-optimization/BayesianOptimization/blob/master/examples/advanced-tour.ipynb#scrollTo=QWqhKqCnvZmn\n",
    "    epoch = int(epoch)\n",
    "    batch_size = int(batch_size)\n",
    "    num_layers = int(num_layers)\n",
    "    num_tokens = int(num_tokens)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    RNN_embeddings_model = DropoutInitialRNN(input_size=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, num_classes=1)\n",
    "    optim = torch.optim.Adam(RNN_embeddings_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_dataset_ed2 = EmbeddingsDataset2(train_dataset['text'], train_dataset['label'], num_tokens_per_sentence=num_tokens)\n",
    "    validation_dataset_ed2 = EmbeddingsDataset2(validation_dataset['text'], validation_dataset['label'], num_tokens_per_sentence=num_tokens)\n",
    "    # test_dataset_ed2 = EmbeddingsDataset(test_dataset['text'], test_dataset['label'])\n",
    "\n",
    "    train_dataloader2 = DataLoader(train_dataset_ed2, batch_size=batch_size, shuffle=True)\n",
    "    validation_dataloader2 = DataLoader(validation_dataset_ed2, batch_size=batch_size, shuffle=True)\n",
    "    for _ in range(epoch):\n",
    "        train_loss, train_correct = train_loop(train_dataloader2, RNN_embeddings_model, criterion, optim) \n",
    "        validate_loss, validate_correct = test_loop(validation_dataloader2, RNN_embeddings_model, criterion)\n",
    "        #validation_acc.append(validate_correct)\n",
    "        #train_acc.append(train_correct)\n",
    "    return validate_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "optimizer_dropout_initial = BayesianOptimization(\n",
    "    f=black_box_with_token,\n",
    "    pbounds={\"learning_rate\": (0.0001, 0.01), \"epoch\": (5, 60), \"batch_size\": (10, 64), \"num_layers\": (1, 4), \"num_tokens\": (16, 26)},\n",
    "    random_state=1,\n",
    "    verbose=2\n",
    ")\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "logger = JSONLogger(path=\"./logs_dropout_token_initial.log\")\n",
    "optimizer_dropout_initial.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_dropout_initial.probe(\n",
    "    params={\"learning_rate\": 0.00019, \"epoch\": 17, \"batch_size\": 17, \"num_layers\": 3, \"num_tokens\": 18},\n",
    "    lazy = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_dropout_initial.maximize(init_points=4, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(optimizer_dropout_initial.res, key=lambda x: x['target'])[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nn.Embeddings \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VarDropoutInitialRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, embedding_matrix_torch=torch.tensor(embedding_matrix_np, dtype=torch.float), drop_out = 0.3):\n",
    "        super(VarDropoutInitialRNN, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix_torch, freeze=True, padding_idx=0)\n",
    "        self.num_layers = num_layers \n",
    "        self.hidden_size = hidden_size \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True) # this is the num rows of the input matrix \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "        self.h0 = nn.Parameter(torch.zeros(self.num_layers, 1, self.hidden_size, dtype=torch.float))\n",
    " \n",
    "    def forward(self, x):\n",
    "        # Pass input through embedding layer\n",
    "        x = self.embedding(x)\n",
    "        h0 = self.h0.expand(-1, x.size(0), -1).contiguous().to(x.device)\n",
    "        # Pass the embeddings through the RNN layer\n",
    "        out, hidden = self.rnn(x, h0)\n",
    "        # Only take the last output for each sequence\n",
    "        res = hidden[-1]\n",
    "        # Dropout\n",
    "        res = self.dropout(res)\n",
    "        # Pass through the fully connected layer\n",
    "        res = self.fc(res)\n",
    "        # Apply sigmoid activation (for binary classification)\n",
    "        res = self.sigmoid(res)\n",
    "        \n",
    "        return res\n",
    "\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "# TODO: change the num_tokens \n",
    "class EmbeddingsDataset3(Dataset):\n",
    "  def __init__(self, X, y, num_tokens_per_sentence=8, word_embeddings=word_embeddings):\n",
    "    self.num_tokens_per_sentence = num_tokens_per_sentence\n",
    "    self.word_embeddings = word_embeddings\n",
    "\n",
    "    sentence_lengths = [len(nltk.word_tokenize(x)) for x in X]\n",
    "    sorted_indices = sorted(range(len(X)), key=lambda i: sentence_lengths[i])\n",
    "    \n",
    "    self.X = [X[i] for i in sorted_indices] # train_dataset['text']\n",
    "    self.y = [y[i] for i in sorted_indices] # train_dataset['label']\n",
    "\n",
    "    self.len = len(self.X)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # tokenize the sentence \n",
    "    tokens = self.tokenize_sentence(self.X[index])\n",
    "    # convert each token to embeddings \n",
    "    sentence_tensor = self.convert_sentence_into_indices(tokens)\n",
    "    label = torch.tensor(self.y[index], dtype=torch.float)\n",
    "    return sentence_tensor, label \n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len \n",
    "\n",
    "  def tokenize_sentence(self, x): \n",
    "    '''\n",
    "    returns a list containing the embeddings of each token \n",
    "    '''\n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    return tokens \n",
    "  \n",
    "  def convert_sentence_into_indices(self, tokens):\n",
    "    indices = []\n",
    "    num_tokens_used = 0 \n",
    "    for token in tokens:\n",
    "      if num_tokens_used == self.num_tokens_per_sentence:\n",
    "        break # we have enough of tokens from the sentence \n",
    "      if token in word2idx:\n",
    "        indices.append(word2idx[token])\n",
    "        num_tokens_used += 1 \n",
    "    # # if not enough tokens in the sentence, use index of ?? \n",
    "    if len(indices) < self.num_tokens_per_sentence:\n",
    "      padding = [0 for _ in range(self.num_tokens_per_sentence - len(indices))]\n",
    "      indices.extend(padding)\n",
    "\n",
    "    indices = torch.tensor(indices, dtype=torch.long)\n",
    "    return indices\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_ed3 = EmbeddingsDataset3(train_dataset['text'], train_dataset['label'])\n",
    "validation_dataset_ed3 = EmbeddingsDataset3(validation_dataset['text'], validation_dataset['label'])\n",
    "# test_dataset_ed2 = EmbeddingsDataset(test_dataset['text'], test_dataset['label'])\n",
    "\n",
    "\n",
    "train_dataloader3 = DataLoader(train_dataset_ed3, batch_size=BATCH_SIZE, shuffle=False)\n",
    "validation_dataloader3 = DataLoader(validation_dataset_ed3, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_with_token(learning_rate, epoch, batch_size, num_layers, num_tokens, drop_out): # A list of hyperparameters to optimize\n",
    "    validation_acc = [] \n",
    "    train_acc = []\n",
    "    train_correct, validate_correct = 0, 0\n",
    "\n",
    "    # make sure the parameters are integers, since bayesian optimization return float\n",
    "    # refer to: https://colab.research.google.com/github/bayesian-optimization/BayesianOptimization/blob/master/examples/advanced-tour.ipynb#scrollTo=QWqhKqCnvZmn\n",
    "    epoch = int(epoch)\n",
    "    batch_size = int(batch_size)\n",
    "    num_layers = int(num_layers)\n",
    "    num_tokens = int(num_tokens)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    RNN_embeddings_model = VarDropoutInitialRNN(input_size=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, num_classes=1, drop_out=drop_out)\n",
    "    optim = torch.optim.Adam(RNN_embeddings_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_dataset_ed = EmbeddingsDataset3(train_dataset['text'], train_dataset['label'], num_tokens_per_sentence=num_tokens)\n",
    "    validation_dataset_ed = EmbeddingsDataset3(validation_dataset['text'], validation_dataset['label'], num_tokens_per_sentence=num_tokens)\n",
    "    # test_dataset_ed2 = EmbeddingsDataset(test_dataset['text'], test_dataset['label'])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset_ed, batch_size=batch_size, shuffle=False)\n",
    "    validation_dataloader = DataLoader(validation_dataset_ed, batch_size=batch_size, shuffle=False)\n",
    "    for _ in range(epoch):\n",
    "        train_loss, train_correct = train_loop(train_dataloader, RNN_embeddings_model, criterion, optim) \n",
    "        validate_loss, validate_correct = test_loop(validation_dataloader, RNN_embeddings_model, criterion)\n",
    "        #validation_acc.append(validate_correct)\n",
    "        #train_acc.append(train_correct)\n",
    "    return validate_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "optimizer_dropout_initial = BayesianOptimization(\n",
    "    f=black_box_with_token,\n",
    "    pbounds={\"learning_rate\": (0.0001, 0.01), \"epoch\": (5, 60), \"batch_size\": (10, 64), \"num_layers\": (1, 4), \"num_tokens\": (16, 26), \"drop_out\": (0.1, 0.5)},\n",
    "    random_state=1,\n",
    "    verbose=2\n",
    ")\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "logger = JSONLogger(path=\"./logs_var_dropout_token_initial_sorted.log\")\n",
    "optimizer_dropout_initial.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moptimizer_dropout_initial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:312\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter)\u001b[0m\n\u001b[0;32m    310\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest()\n\u001b[0;32m    311\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:245\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mappend(params)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\bayes_opt\\target_space.py:418\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    416\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo target function has been provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[1;32m--> 418\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdict_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[1;32mIn[128], line 25\u001b[0m, in \u001b[0;36mblack_box_with_token\u001b[1;34m(learning_rate, epoch, batch_size, num_layers, num_tokens, drop_out)\u001b[0m\n\u001b[0;32m     23\u001b[0m validation_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(validation_dataset_ed, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[1;32m---> 25\u001b[0m     train_loss, train_correct \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRNN_embeddings_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     26\u001b[0m     validate_loss, validate_correct \u001b[38;5;241m=\u001b[39m test_loop(validation_dataloader, RNN_embeddings_model, criterion)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m#validation_acc.append(validate_correct)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m#train_acc.append(train_correct)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[122], line 24\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(train_dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     27\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches \n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Github\\school\\nlp-2\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer_dropout_initial.maximize(init_points=10, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
